{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision ## suport para imagens \n",
    "import torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user torch torchvision torchaudio -f https://download.pytorch.org/whl/cu111/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [3, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "array = [[1,2,3], [3,2,1]]\n",
    "\n",
    "tensor = torch.tensor(array)\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [3 2 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_array = np.array(array)\n",
    "np_tensor = torch.from_numpy(np_array) \n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aprendizado de maquina profundo requer uma GPU que em recursos de computação paralela, tempos mais rapidos e \n",
    "## desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 3],\n",
      "        [5, 5]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,1], [2,2]])\n",
    "b = torch.tensor([[2,2], [3,3]])\n",
    "\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2],\n",
      "        [6, 6]])\n"
     ]
    }
   ],
   "source": [
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "input_tensor = torch.tensor([[0.3471, 0.4547, -0.2356]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(in_features=3, out_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4262, 0.2906]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = linear_layer(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0086,  0.5553,  0.0612],\n",
       "        [ 0.2426,  0.0466, -0.4657]], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.1851, 0.0755], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qual e a operação usada :\n",
    "$$\n",
    "    y_0 = W_0 \\cdot X + b_0\n",
    "$$\n",
    "* X input array\n",
    "* W weight (peso)\n",
    "* b bias (vies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obs \n",
    "* Redes apenas com camadas lineares são chamadas de redes totalmente conectadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 18),\n",
    "    nn.Linear(18,20),\n",
    "    nn.Linear(20, 5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([[-0.014, 0.4038, 1.0305, 0.7521, 0.7489, -0.3968, 0.0113, -1.3844, 0.8705, -0.9743]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1751,  0.0519, -0.2799, -0.4107, -0.4039]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = model(input_tensor)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função sigmoid\n",
    "* Função utilizada para problemas de classificação binária\n",
    "\n",
    "* Suposição: imagine que você quer classificar um animal se é mamifero ou não. Recebemos 3 informações número de membros se põe ovos e se tem pelos.  \n",
    "\n",
    "* A função simgoide transforma um número inteiro em um valor entre zero e um.\n",
    "* Se o valor maior que 0.5 então a resposta sera 1 caso contrario sera 0\n",
    "\n",
    "$$\n",
    "    \\sigma(x) = \\frac{1}{1 + e^{-1}}\n",
    "$$\n",
    "\n",
    "##### Obs:\n",
    "Uma rede neural com camadas lineares é equivalente a uma regressão logística usando aprendizado de maquina tradicional\n",
    "* Para rotulos de varias classes usamos softmax outra função de ativação\n",
    "$$\n",
    "    SoftMax(z)_i = \\frac{e^{z^i}}{\\sum_{j=1}^{K} e^{z_i}}\n",
    "$$\n",
    "$z = (z_1, z_2, ..., z_K) z_i \\text{ \\space um numero real }$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9975]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_tensor = torch.tensor([[6.0]])\n",
    "sigmoid = nn.Sigmoid()\n",
    "output = sigmoid(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4),\n",
    "    nn.Linear(4,1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1392, 0.8420, 0.0188]])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.tensor([[4.3, 6.1, 2.3]])\n",
    "\n",
    "prob = nn.Softmax(dim=-1) ## -1 implica que ele e aplicado a ultima dimensao do input_tensor\n",
    "output = prob(input_tensor)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerações de previsões a partir de modelos. \"Executar uma passagem direta\"\n",
    "* Objetivo e propagar os dados de entrada atraves da rede e produzir predições com base nos parâmentros aprendidos peso e vies\n",
    "* Isso é usado tanto para treinar quanto para gerar novas previsões\n",
    "* Os resultados pode ser classificações binárias, classificações multiclasse ou previsões numéricas (regressões)\n",
    "##### Obs :\n",
    "* retropropagação: é p processo pelo qual os pesos e tendências das camadas são atualizadas durante o treinamento.\n",
    "\n",
    "#### Loop de treinamento.\n",
    "1. Propagate\n",
    "2. Compare\n",
    "3. BackPropagate\n",
    "4. Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_list(num):\n",
    "    import random\n",
    "    list_rm = list()\n",
    "    for i in range(num):\n",
    "        list_rm.append(round(random.uniform(-2, 2), 4))\n",
    "\n",
    "    return list_rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.8169, 1.1215, -0.1375, -1.9714, -0.5152]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_list(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1490, -1.4393, -1.9512, -0.3131,  0.0888,  0.9845],\n",
      "        [-0.8522,  1.3422,  0.8721,  1.5570,  0.8137,  0.7064],\n",
      "        [-1.5312,  0.0150, -0.0925,  1.2424,  1.9555, -0.3276],\n",
      "        [ 0.8161,  0.2965,  1.8279, -1.6662, -1.1412, -0.1060],\n",
      "        [ 1.6988,  0.0210, -1.2614,  1.8759,  1.7935,  0.8096]])\n"
     ]
    }
   ],
   "source": [
    "input_data = torch.tensor(\n",
    "[\n",
    "        generate_list(6),\n",
    "        generate_list(6),\n",
    "        generate_list(6),\n",
    "        generate_list(6),\n",
    "        generate_list(6),\n",
    "]\n",
    ")\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6392],\n",
      "        [0.5419],\n",
      "        [0.4854],\n",
      "        [0.5330],\n",
      "        [0.6357]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(6, 4),\n",
    "    nn.Linear(4, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "output = model(input_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "n_class = 3 ## numero de classes da multi class\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4),\n",
    "    nn.Linear(4, n_class),\n",
    "    nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "output = model(input_data)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1324, 0.4730, 0.3946],\n",
      "        [0.4071, 0.4985, 0.0945],\n",
      "        [0.3864, 0.4408, 0.1727],\n",
      "        [0.4014, 0.4217, 0.1769],\n",
      "        [0.2241, 0.6592, 0.1166]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5454],\n",
      "        [ 0.9959],\n",
      "        [ 1.1305],\n",
      "        [-0.1866],\n",
      "        [ 0.5337]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4),\n",
    "    nn.Linear(4,1)\n",
    "\n",
    ")\n",
    "\n",
    "output = model(input_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliar as predições com os valores reais\n",
    "* Avaliaremos isso com uma função de perda \n",
    "* Ele pega uma as previsões do modelo e um valor verdadeiro e gera um float\n",
    "##### Exemplo:\n",
    "Digamos que vamos prever com o modelo se um animal é um mamifero um pássaro ou outros.\n",
    "\n",
    "$$\n",
    "    loss = F(y, \\hat{y}) \n",
    "$$\n",
    "Usamos a codificação one-hot para transformar o inteiro y em um tensor\n",
    "* Quando $y = 0$ ha três classes ou  seja $\\hat{y} = [1,0,0]$\n",
    "\n",
    "##### Função de perda  entropia cruzada, é a função mais utilizada para problemas de classificação\n",
    "Função para variaveis class binarias\n",
    "$$\n",
    "    CrossEntropyLoss(y, \\hat{y}) = - (y \\cdot log(\\hat{y}) + (1 - y) \\cdot log(1 - \\hat{y}))\n",
    "$$\n",
    "Função para multi class\n",
    "$$\n",
    "    CrossEntropyLoss(y, \\hat{y}) = - \\sum_{i=1}^{C} y_i \\cdot log(\\hat{y_i})\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0])\n",
      "tensor([0, 1, 0])\n",
      "tensor([0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "print(F.one_hot(torch.tensor(0), num_classes=3))\n",
    "print(F.one_hot(torch.tensor(1), num_classes=3))\n",
    "print(F.one_hot(torch.tensor(2), num_classes=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8131, dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "score = torch.tensor([[-0.1211, 0.1059]])\n",
    "one_hot_target = torch.tensor([[1, 0]])\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "criterion(score.double(), one_hot_target.double()) ## valor de perda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resumo \n",
    "* A função de perda toma como entrada o tensor de pontuações que é o modelo\n",
    "* Ele gera um ponto flutuante da perda da amostra $\\newline$\n",
    "Obs: **O objetivo do treinamento é minimizar a perda.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0619, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), scores.shape[1])\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Calculate the cross entropy loss\n",
    "loss = criterion(scores.double(), one_hot_label.double())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Atualizando os parametros do modelo.\n",
    "\n",
    "OBS : pensamos na função de perda como uma função \"Vale\"\n",
    "* por conta pode existir o minimo local e o minimo global\n",
    "* e pode existir o maximo global e o maximo local\n",
    "\n",
    "Deep learning gradient = derivada\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.tensor(\n",
    "[\n",
    "        generate_list(16),\n",
    "        generate_list(16),\n",
    "        generate_list(16),\n",
    "        generate_list(16),\n",
    "        generate_list(16),\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor(\n",
    "[\n",
    "    generate_list(2),\n",
    "    generate_list(2),\n",
    "    generate_list(2),\n",
    "    generate_list(2),\n",
    "    generate_list(2)\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(16, 8),\n",
    "    nn.Linear(8, 4), \n",
    "    nn.Linear(4,2)\n",
    ")\n",
    "\n",
    "prediction = model(sample)\n",
    "\n",
    "criterion = CrossEntropyLoss() ## Essa função de perda e utilizada em classificações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1729, -0.3521],\n",
       "        [ 0.1727,  0.1536],\n",
       "        [ 0.1065, -0.4186],\n",
       "        [ 0.2414, -0.1594],\n",
       "        [ 0.2339, -0.2274]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(prediction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0213, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0178,  0.0204,  0.0315, -0.0173,  0.0223, -0.0066, -0.0128, -0.0151,\n",
       "           0.0086,  0.0134,  0.0243,  0.0077, -0.0177,  0.0079, -0.0116, -0.0027],\n",
       "         [-0.0700, -0.0801, -0.1238,  0.0678, -0.0876,  0.0258,  0.0502,  0.0593,\n",
       "          -0.0338, -0.0526, -0.0954, -0.0301,  0.0694, -0.0310,  0.0456,  0.0106],\n",
       "         [ 0.0022,  0.0025,  0.0039, -0.0022,  0.0028, -0.0008, -0.0016, -0.0019,\n",
       "           0.0011,  0.0017,  0.0030,  0.0010, -0.0022,  0.0010, -0.0014, -0.0003],\n",
       "         [-0.0935, -0.1070, -0.1654,  0.0906, -0.1170,  0.0345,  0.0671,  0.0793,\n",
       "          -0.0452, -0.0703, -0.1275, -0.0403,  0.0927, -0.0415,  0.0609,  0.0142],\n",
       "         [ 0.0716,  0.0819,  0.1266, -0.0694,  0.0896, -0.0264, -0.0514, -0.0607,\n",
       "           0.0346,  0.0538,  0.0976,  0.0308, -0.0710,  0.0317, -0.0466, -0.0109],\n",
       "         [-0.0210, -0.0240, -0.0372,  0.0204, -0.0263,  0.0078,  0.0151,  0.0178,\n",
       "          -0.0102, -0.0158, -0.0286, -0.0090,  0.0208, -0.0093,  0.0137,  0.0032],\n",
       "         [-0.0682, -0.0780, -0.1206,  0.0661, -0.0854,  0.0252,  0.0489,  0.0578,\n",
       "          -0.0330, -0.0513, -0.0930, -0.0294,  0.0676, -0.0302,  0.0444,  0.0104],\n",
       "         [-0.0823, -0.0941, -0.1455,  0.0797, -0.1030,  0.0304,  0.0590,  0.0698,\n",
       "          -0.0398, -0.0619, -0.1122, -0.0354,  0.0816, -0.0365,  0.0536,  0.0125]]),\n",
       " tensor([ 0.0034, -0.0133,  0.0004, -0.0178,  0.0136, -0.0040, -0.0130, -0.0157]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.grad, model[0].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0234, -0.1011,  0.0240, -0.0664, -0.0695,  0.0017, -0.0265,  0.1024],\n",
       "         [ 0.0195,  0.0843, -0.0200,  0.0554,  0.0580, -0.0014,  0.0221, -0.0854],\n",
       "         [ 0.0259,  0.1116, -0.0265,  0.0733,  0.0767, -0.0019,  0.0293, -0.1131],\n",
       "         [-0.0155, -0.0670,  0.0159, -0.0440, -0.0461,  0.0011, -0.0176,  0.0679]]),\n",
       " tensor([ 0.0439, -0.0366, -0.0484,  0.0291]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].weight.grad, model[1].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0474,  0.0096,  0.0282, -0.1064],\n",
       "         [-0.0474, -0.0096, -0.0282,  0.1064]]),\n",
       " tensor([-0.0998,  0.0998]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].weight.grad, model[2].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Atualizando as camadas do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate is typically small taxa de aprendizado\n",
    "lr = 0.001\n",
    "\n",
    "## upadete the weights atualizanfo os pesos\n",
    "weight = model[0].weight\n",
    "weight_grad =model[0].weight.grad\n",
    "weight = weight - lr* weight_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the biases atualizanfo os vies\n",
    "bias = model[0].bias\n",
    "bias_grad = model[0].bias.grad\n",
    "bias = bias - lr * bias_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBS matemáticas ....\n",
    "* Minimizar a função perda o objetivo e encontrar o minimo global.\n",
    "* Quando temos apenas um minimo global sabemos que nossa função e convexa.\n",
    "* Qaundo temos varios minimos locais sabemos que nossa função não e convexa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradiente descendente\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)     ## gradiente estocastico mais conhecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing our first training loop\n",
    "1. Criar o modelo\n",
    "2. Escolher a função perda\n",
    "3. Criar um dataset\n",
    "4. Definir um otimizador\n",
    "5. Percorrer cada elemento do conjunto de dados calcular. (ciclo de treinamento)\n",
    "    * Perda\n",
    "    * Clacular os gradientes locais\n",
    "    * Atualizar os parametros do modelo\n",
    "\n",
    "OBS: Criamos nosso proprio metodo fit em uma deep learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/ds_salaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>80000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>85847</td>\n",
       "      <td>ES</td>\n",
       "      <td>100</td>\n",
       "      <td>ES</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>30000</td>\n",
       "      <td>USD</td>\n",
       "      <td>30000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>25500</td>\n",
       "      <td>USD</td>\n",
       "      <td>25500</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>175000</td>\n",
       "      <td>USD</td>\n",
       "      <td>175000</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>120000</td>\n",
       "      <td>USD</td>\n",
       "      <td>120000</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year experience_level employment_type                 job_title  \\\n",
       "0       2023               SE              FT  Principal Data Scientist   \n",
       "1       2023               MI              CT               ML Engineer   \n",
       "2       2023               MI              CT               ML Engineer   \n",
       "3       2023               SE              FT            Data Scientist   \n",
       "4       2023               SE              FT            Data Scientist   \n",
       "\n",
       "   salary salary_currency  salary_in_usd employee_residence  remote_ratio  \\\n",
       "0   80000             EUR          85847                 ES           100   \n",
       "1   30000             USD          30000                 US           100   \n",
       "2   25500             USD          25500                 US           100   \n",
       "3  175000             USD         175000                 CA           100   \n",
       "4  120000             USD         120000                 CA           100   \n",
       "\n",
       "  company_location company_size  \n",
       "0               ES            L  \n",
       "1               US            S  \n",
       "2               US            S  \n",
       "3               CA            M  \n",
       "4               CA            M  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"experience_level\", \"employment_type\", \"remote_ratio\", \"company_size\", \"salary_in_usd\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_size</th>\n",
       "      <th>salary_in_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>100</td>\n",
       "      <td>L</td>\n",
       "      <td>85847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>100</td>\n",
       "      <td>S</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>100</td>\n",
       "      <td>S</td>\n",
       "      <td>25500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>100</td>\n",
       "      <td>M</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>100</td>\n",
       "      <td>M</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_level employment_type  remote_ratio company_size  salary_in_usd\n",
       "0               SE              FT           100            L          85847\n",
       "1               MI              CT           100            S          30000\n",
       "2               MI              CT           100            S          25500\n",
       "3               SE              FT           100            M         175000\n",
       "4               SE              FT           100            M         120000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "standar_scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "## Transformando as variaveis em categoricas Ok\n",
    "df.experience_level = label_encoder.fit_transform(df[\"employment_type\"])\n",
    "df.employment_type = label_encoder.fit_transform(df[\"employment_type\"])\n",
    "df.company_size = label_encoder.fit_transform(df.company_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"salary_in_usd\", \"remote_ratio\"]] = scaler.fit_transform(\n",
    "    df[[\"salary_in_usd\", \"remote_ratio\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_size</th>\n",
       "      <th>salary_in_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.055900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.045784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.381839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.258207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.914581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.327891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.224489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.213250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.201257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3755 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      experience_level  employment_type  remote_ratio  company_size  \\\n",
       "0                    2                2           1.0             0   \n",
       "1                    0                0           1.0             2   \n",
       "2                    0                0           1.0             2   \n",
       "3                    2                2           1.0             1   \n",
       "4                    2                2           1.0             1   \n",
       "...                ...              ...           ...           ...   \n",
       "3750                 2                2           1.0             0   \n",
       "3751                 2                2           1.0             0   \n",
       "3752                 2                2           1.0             2   \n",
       "3753                 0                0           1.0             0   \n",
       "3754                 2                2           0.5             0   \n",
       "\n",
       "      salary_in_usd  \n",
       "0          0.181436  \n",
       "1          0.055900  \n",
       "2          0.045784  \n",
       "3          0.381839  \n",
       "4          0.258207  \n",
       "...             ...  \n",
       "3750       0.914581  \n",
       "3751       0.327891  \n",
       "3752       0.224489  \n",
       "3753       0.213250  \n",
       "3754       0.201257  \n",
       "\n",
       "[3755 rows x 5 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_loss(prediction, target): ## MSE\n",
    "    from numpy import mean as m\n",
    "    return m((prediction - target)**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ou entao podemos usar\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(prediction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[[\"experience_level\", \"employment_type\", \"remote_ratio\", \"company_size\"]].values\n",
    "target = df[[\"salary_in_usd\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creando o dataset e o dataloader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(\n",
    "    torch.tensor(features).float(), torch.tensor(target).float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criando o modelo\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Linear(2, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Loss: 0.05702848359942436\n",
      "Epoch: 1/5, Loss: 0.09826479852199554\n",
      "Epoch: 1/5, Loss: 0.060111694037914276\n",
      "Epoch: 1/5, Loss: 0.0678747147321701\n",
      "Epoch: 1/5, Loss: 0.06717713922262192\n",
      "Epoch: 1/5, Loss: 0.04333248734474182\n",
      "Epoch: 1/5, Loss: 0.06397487223148346\n",
      "Epoch: 1/5, Loss: 0.019935451447963715\n",
      "Epoch: 1/5, Loss: 0.06492345035076141\n",
      "Epoch: 1/5, Loss: 0.06012555956840515\n",
      "Epoch: 1/5, Loss: 0.013440266251564026\n",
      "Epoch: 1/5, Loss: 0.07140210270881653\n",
      "Epoch: 1/5, Loss: 0.03453478962182999\n",
      "Epoch: 1/5, Loss: 0.057806432247161865\n",
      "Epoch: 1/5, Loss: 0.09641067683696747\n",
      "Epoch: 1/5, Loss: 0.10155430436134338\n",
      "Epoch: 1/5, Loss: 0.02654285728931427\n",
      "Epoch: 1/5, Loss: 0.024312280118465424\n",
      "Epoch: 1/5, Loss: 0.09883097559213638\n",
      "Epoch: 1/5, Loss: 0.02732667699456215\n",
      "Epoch: 1/5, Loss: 0.06023645028471947\n",
      "Epoch: 1/5, Loss: 0.04372798278927803\n",
      "Epoch: 1/5, Loss: 0.061041686683893204\n",
      "Epoch: 1/5, Loss: 0.03502108156681061\n",
      "Epoch: 1/5, Loss: 0.010511609725654125\n",
      "Epoch: 1/5, Loss: 0.03772110491991043\n",
      "Epoch: 1/5, Loss: 0.012196497060358524\n",
      "Epoch: 1/5, Loss: 0.022076966241002083\n",
      "Epoch: 1/5, Loss: 0.05488445609807968\n",
      "Epoch: 1/5, Loss: 0.04992840439081192\n",
      "Epoch: 1/5, Loss: 0.03286217898130417\n",
      "Epoch: 1/5, Loss: 0.054003335535526276\n",
      "Epoch: 1/5, Loss: 0.02397293969988823\n",
      "Epoch: 1/5, Loss: 0.03064161166548729\n",
      "Epoch: 1/5, Loss: 0.048615895211696625\n",
      "Epoch: 1/5, Loss: 0.1134456992149353\n",
      "Epoch: 1/5, Loss: 0.06312087178230286\n",
      "Epoch: 1/5, Loss: 0.009429458528757095\n",
      "Epoch: 1/5, Loss: 0.06842619925737381\n",
      "Epoch: 1/5, Loss: 0.008606329560279846\n",
      "Epoch: 1/5, Loss: 0.02976934239268303\n",
      "Epoch: 1/5, Loss: 0.03761054575443268\n",
      "Epoch: 1/5, Loss: 0.0039038988761603832\n",
      "Epoch: 1/5, Loss: 0.08395829051733017\n",
      "Epoch: 1/5, Loss: 0.04336712509393692\n",
      "Epoch: 1/5, Loss: 0.054597407579422\n",
      "Epoch: 1/5, Loss: 0.060966819524765015\n",
      "Epoch: 1/5, Loss: 0.041974689811468124\n",
      "Epoch: 1/5, Loss: 0.053531281650066376\n",
      "Epoch: 1/5, Loss: 0.09107664227485657\n",
      "Epoch: 1/5, Loss: 0.04316125437617302\n",
      "Epoch: 1/5, Loss: 0.04586941748857498\n",
      "Epoch: 1/5, Loss: 0.051918234676122665\n",
      "Epoch: 1/5, Loss: 0.04848390817642212\n",
      "Epoch: 1/5, Loss: 0.03126275911927223\n",
      "Epoch: 1/5, Loss: 0.12932394444942474\n",
      "Epoch: 1/5, Loss: 0.11181521415710449\n",
      "Epoch: 1/5, Loss: 0.08445385098457336\n",
      "Epoch: 1/5, Loss: 0.044925905764102936\n",
      "Epoch: 1/5, Loss: 0.023852376267313957\n",
      "Epoch: 1/5, Loss: 0.04930300638079643\n",
      "Epoch: 1/5, Loss: 0.07763612270355225\n",
      "Epoch: 1/5, Loss: 0.1089402511715889\n",
      "Epoch: 1/5, Loss: 0.017117846757173538\n",
      "Epoch: 1/5, Loss: 0.06021398678421974\n",
      "Epoch: 1/5, Loss: 0.05994696170091629\n",
      "Epoch: 1/5, Loss: 0.03508972004055977\n",
      "Epoch: 1/5, Loss: 0.028703929856419563\n",
      "Epoch: 1/5, Loss: 0.01596580073237419\n",
      "Epoch: 1/5, Loss: 0.01863304153084755\n",
      "Epoch: 1/5, Loss: 0.002667459426447749\n",
      "Epoch: 1/5, Loss: 0.03283274918794632\n",
      "Epoch: 1/5, Loss: 0.028113767504692078\n",
      "Epoch: 1/5, Loss: 0.053115665912628174\n",
      "Epoch: 1/5, Loss: 0.024167921394109726\n",
      "Epoch: 1/5, Loss: 0.22260193526744843\n",
      "Epoch: 1/5, Loss: 0.07054562121629715\n",
      "Epoch: 1/5, Loss: 0.03551774471998215\n",
      "Epoch: 1/5, Loss: 0.025877486914396286\n",
      "Epoch: 1/5, Loss: 0.01583278551697731\n",
      "Epoch: 1/5, Loss: 0.05150333791971207\n",
      "Epoch: 1/5, Loss: 0.01471218466758728\n",
      "Epoch: 1/5, Loss: 0.049985624849796295\n",
      "Epoch: 1/5, Loss: 0.02827700600028038\n",
      "Epoch: 1/5, Loss: 0.022702744230628014\n",
      "Epoch: 1/5, Loss: 0.04037720710039139\n",
      "Epoch: 1/5, Loss: 0.02008218504488468\n",
      "Epoch: 1/5, Loss: 0.02656879648566246\n",
      "Epoch: 1/5, Loss: 0.021240226924419403\n",
      "Epoch: 1/5, Loss: 0.03439302742481232\n",
      "Epoch: 1/5, Loss: 0.010590162128210068\n",
      "Epoch: 1/5, Loss: 0.056904297322034836\n",
      "Epoch: 1/5, Loss: 0.03584304079413414\n",
      "Epoch: 1/5, Loss: 0.013025011867284775\n",
      "Epoch: 1/5, Loss: 0.01183705497533083\n",
      "Epoch: 1/5, Loss: 0.0100562684237957\n",
      "Epoch: 1/5, Loss: 0.31881824135780334\n",
      "Epoch: 1/5, Loss: 0.04028818756341934\n",
      "Epoch: 1/5, Loss: 0.004940918646752834\n",
      "Epoch: 1/5, Loss: 0.03088073432445526\n",
      "Epoch: 1/5, Loss: 0.059287358075380325\n",
      "Epoch: 1/5, Loss: 0.01613025553524494\n",
      "Epoch: 1/5, Loss: 0.057004086673259735\n",
      "Epoch: 1/5, Loss: 0.020416317507624626\n",
      "Epoch: 1/5, Loss: 0.03530104458332062\n",
      "Epoch: 1/5, Loss: 0.18404100835323334\n",
      "Epoch: 1/5, Loss: 0.0759255439043045\n",
      "Epoch: 1/5, Loss: 0.032131776213645935\n",
      "Epoch: 1/5, Loss: 0.015185557305812836\n",
      "Epoch: 1/5, Loss: 0.02168286219239235\n",
      "Epoch: 1/5, Loss: 0.045928169041872025\n",
      "Epoch: 1/5, Loss: 0.031861562281847\n",
      "Epoch: 1/5, Loss: 0.00867803581058979\n",
      "Epoch: 1/5, Loss: 0.014855100773274899\n",
      "Epoch: 1/5, Loss: 0.03986245021224022\n",
      "Epoch: 1/5, Loss: 0.04666479676961899\n",
      "Epoch: 1/5, Loss: 0.009403922595083714\n",
      "Epoch: 1/5, Loss: 0.08614446967840195\n",
      "Epoch: 1/5, Loss: 0.010111046954989433\n",
      "Epoch: 1/5, Loss: 0.09199942648410797\n",
      "Epoch: 1/5, Loss: 0.02220376580953598\n",
      "Epoch: 1/5, Loss: 0.011146539822220802\n",
      "Epoch: 1/5, Loss: 0.023807760328054428\n",
      "Epoch: 1/5, Loss: 0.027065638452768326\n",
      "Epoch: 1/5, Loss: 0.034143127501010895\n",
      "Epoch: 1/5, Loss: 0.05703073740005493\n",
      "Epoch: 1/5, Loss: 0.03070341795682907\n",
      "Epoch: 1/5, Loss: 0.005761626176536083\n",
      "Epoch: 1/5, Loss: 0.06595205515623093\n",
      "Epoch: 1/5, Loss: 0.04265468567609787\n",
      "Epoch: 1/5, Loss: 0.060919541865587234\n",
      "Epoch: 1/5, Loss: 0.027412783354520798\n",
      "Epoch: 1/5, Loss: 0.05057280883193016\n",
      "Epoch: 1/5, Loss: 0.034356243908405304\n",
      "Epoch: 1/5, Loss: 0.04800622537732124\n",
      "Epoch: 1/5, Loss: 0.03619393706321716\n",
      "Epoch: 1/5, Loss: 0.03768738731741905\n",
      "Epoch: 1/5, Loss: 0.022827334702014923\n",
      "Epoch: 1/5, Loss: 0.04688379541039467\n",
      "Epoch: 1/5, Loss: 0.026681678369641304\n",
      "Epoch: 1/5, Loss: 0.012615647166967392\n",
      "Epoch: 1/5, Loss: 0.010651381686329842\n",
      "Epoch: 1/5, Loss: 0.07695385813713074\n",
      "Epoch: 1/5, Loss: 0.04980592802166939\n",
      "Epoch: 1/5, Loss: 0.02179962955415249\n",
      "Epoch: 1/5, Loss: 0.021587802097201347\n",
      "Epoch: 1/5, Loss: 0.019149983301758766\n",
      "Epoch: 1/5, Loss: 0.013821362517774105\n",
      "Epoch: 1/5, Loss: 0.03440932556986809\n",
      "Epoch: 1/5, Loss: 0.017811205238103867\n",
      "Epoch: 1/5, Loss: 0.05334281176328659\n",
      "Epoch: 1/5, Loss: 0.0322054922580719\n",
      "Epoch: 1/5, Loss: 0.0224275104701519\n",
      "Epoch: 1/5, Loss: 0.06983696669340134\n",
      "Epoch: 1/5, Loss: 0.01697470061480999\n",
      "Epoch: 1/5, Loss: 0.009696649387478828\n",
      "Epoch: 1/5, Loss: 0.034639645367860794\n",
      "Epoch: 1/5, Loss: 0.01123386062681675\n",
      "Epoch: 1/5, Loss: 0.014398658648133278\n",
      "Epoch: 1/5, Loss: 0.06701136380434036\n",
      "Epoch: 1/5, Loss: 0.028928373008966446\n",
      "Epoch: 1/5, Loss: 0.03752468526363373\n",
      "Epoch: 1/5, Loss: 0.024286605417728424\n",
      "Epoch: 1/5, Loss: 0.019377432763576508\n",
      "Epoch: 1/5, Loss: 0.02823066897690296\n",
      "Epoch: 1/5, Loss: 0.00845811516046524\n",
      "Epoch: 1/5, Loss: 0.007715796120464802\n",
      "Epoch: 1/5, Loss: 0.01510529313236475\n",
      "Epoch: 1/5, Loss: 0.0425381064414978\n",
      "Epoch: 1/5, Loss: 0.03274163603782654\n",
      "Epoch: 1/5, Loss: 0.06107594817876816\n",
      "Epoch: 1/5, Loss: 0.03678547218441963\n",
      "Epoch: 1/5, Loss: 0.06429719179868698\n",
      "Epoch: 1/5, Loss: 0.009292012080550194\n",
      "Epoch: 1/5, Loss: 0.02005217969417572\n",
      "Epoch: 1/5, Loss: 0.005752725526690483\n",
      "Epoch: 1/5, Loss: 0.025746915489435196\n",
      "Epoch: 1/5, Loss: 0.012096447870135307\n",
      "Epoch: 1/5, Loss: 0.011022019200026989\n",
      "Epoch: 1/5, Loss: 0.007303016725927591\n",
      "Epoch: 1/5, Loss: 0.03950914740562439\n",
      "Epoch: 1/5, Loss: 0.029198119416832924\n",
      "Epoch: 1/5, Loss: 0.007121687289327383\n",
      "Epoch: 1/5, Loss: 0.054910045117139816\n",
      "Epoch: 1/5, Loss: 0.026851041242480278\n",
      "Epoch: 1/5, Loss: 0.06626276671886444\n",
      "Epoch: 1/5, Loss: 0.045020729303359985\n",
      "Epoch: 1/5, Loss: 0.058347560465335846\n",
      "Epoch: 1/5, Loss: 0.08139827102422714\n",
      "Epoch: 1/5, Loss: 0.038179632276296616\n",
      "Epoch: 1/5, Loss: 0.01322604063898325\n",
      "Epoch: 1/5, Loss: 0.027754968032240868\n",
      "Epoch: 1/5, Loss: 0.03478210046887398\n",
      "Epoch: 1/5, Loss: 0.01735430397093296\n",
      "Epoch: 1/5, Loss: 0.002577925566583872\n",
      "Epoch: 1/5, Loss: 0.013578712940216064\n",
      "Epoch: 1/5, Loss: 0.0804850310087204\n",
      "Epoch: 1/5, Loss: 0.039646245539188385\n",
      "Epoch: 1/5, Loss: 0.016735807061195374\n",
      "Epoch: 1/5, Loss: 0.004943118430674076\n",
      "Epoch: 1/5, Loss: 0.022091669961810112\n",
      "Epoch: 1/5, Loss: 0.008626405149698257\n",
      "Epoch: 1/5, Loss: 0.028469780460000038\n",
      "Epoch: 1/5, Loss: 0.006563790608197451\n",
      "Epoch: 1/5, Loss: 0.03280166536569595\n",
      "Epoch: 1/5, Loss: 0.02535301074385643\n",
      "Epoch: 1/5, Loss: 0.017430467531085014\n",
      "Epoch: 1/5, Loss: 0.05925535038113594\n",
      "Epoch: 1/5, Loss: 0.05346711352467537\n",
      "Epoch: 1/5, Loss: 0.010619675740599632\n",
      "Epoch: 1/5, Loss: 0.0150547344237566\n",
      "Epoch: 1/5, Loss: 0.0232442207634449\n",
      "Epoch: 1/5, Loss: 0.009182929061353207\n",
      "Epoch: 1/5, Loss: 0.006269107572734356\n",
      "Epoch: 1/5, Loss: 0.002595193451270461\n",
      "Epoch: 1/5, Loss: 0.06086169555783272\n",
      "Epoch: 1/5, Loss: 0.03727414086461067\n",
      "Epoch: 1/5, Loss: 0.027840187773108482\n",
      "Epoch: 1/5, Loss: 0.07445070147514343\n",
      "Epoch: 1/5, Loss: 0.012889118865132332\n",
      "Epoch: 1/5, Loss: 0.005564291030168533\n",
      "Epoch: 1/5, Loss: 0.05688308924436569\n",
      "Epoch: 1/5, Loss: 0.011421460658311844\n",
      "Epoch: 1/5, Loss: 0.008646429516375065\n",
      "Epoch: 1/5, Loss: 0.014238983392715454\n",
      "Epoch: 1/5, Loss: 0.018311724066734314\n",
      "Epoch: 1/5, Loss: 0.01956273429095745\n",
      "Epoch: 1/5, Loss: 0.013555692508816719\n",
      "Epoch: 1/5, Loss: 0.15806657075881958\n",
      "Epoch: 1/5, Loss: 0.025544285774230957\n",
      "Epoch: 1/5, Loss: 0.1510016769170761\n",
      "Epoch: 1/5, Loss: 0.019634680822491646\n",
      "Epoch: 1/5, Loss: 0.017685754224658012\n",
      "Epoch: 1/5, Loss: 0.038039371371269226\n",
      "Epoch: 1/5, Loss: 0.019361842423677444\n",
      "Epoch: 1/5, Loss: 0.0037638412322849035\n",
      "Epoch: 1/5, Loss: 0.02004651166498661\n",
      "Epoch: 1/5, Loss: 0.023269956931471825\n",
      "Epoch: 1/5, Loss: 0.02254602126777172\n",
      "Epoch: 1/5, Loss: 0.013924511149525642\n",
      "Epoch: 1/5, Loss: 0.013375898823142052\n",
      "Epoch: 1/5, Loss: 0.017254017293453217\n",
      "Epoch: 1/5, Loss: 0.06519213318824768\n",
      "Epoch: 1/5, Loss: 0.03827228397130966\n",
      "Epoch: 1/5, Loss: 0.06003669276833534\n",
      "Epoch: 1/5, Loss: 0.01569623500108719\n",
      "Epoch: 1/5, Loss: 0.00792020559310913\n",
      "Epoch: 1/5, Loss: 0.026727385818958282\n",
      "Epoch: 1/5, Loss: 0.0557447224855423\n",
      "Epoch: 1/5, Loss: 0.006856230087578297\n",
      "Epoch: 1/5, Loss: 0.003041056916117668\n",
      "Epoch: 1/5, Loss: 0.0060319360345602036\n",
      "Epoch: 1/5, Loss: 0.008403606712818146\n",
      "Epoch: 1/5, Loss: 0.006732781883329153\n",
      "Epoch: 1/5, Loss: 0.007456351071596146\n",
      "Epoch: 1/5, Loss: 0.01750890351831913\n",
      "Epoch: 1/5, Loss: 0.015943046659231186\n",
      "Epoch: 1/5, Loss: 0.01677466556429863\n",
      "Epoch: 1/5, Loss: 0.04123123362660408\n",
      "Epoch: 1/5, Loss: 0.024038897827267647\n",
      "Epoch: 1/5, Loss: 0.030696937814354897\n",
      "Epoch: 1/5, Loss: 0.03303614258766174\n",
      "Epoch: 1/5, Loss: 0.0636356845498085\n",
      "Epoch: 1/5, Loss: 0.04701545089483261\n",
      "Epoch: 1/5, Loss: 0.012693895027041435\n",
      "Epoch: 1/5, Loss: 0.031277693808078766\n",
      "Epoch: 1/5, Loss: 0.055896613746881485\n",
      "Epoch: 1/5, Loss: 0.026192527264356613\n",
      "Epoch: 1/5, Loss: 0.01857951655983925\n",
      "Epoch: 1/5, Loss: 0.015551336109638214\n",
      "Epoch: 1/5, Loss: 0.005983774550259113\n",
      "Epoch: 1/5, Loss: 0.006337914150208235\n",
      "Epoch: 1/5, Loss: 0.06197207793593407\n",
      "Epoch: 1/5, Loss: 0.006700609344989061\n",
      "Epoch: 1/5, Loss: 0.010793039575219154\n",
      "Epoch: 1/5, Loss: 0.038287509232759476\n",
      "Epoch: 1/5, Loss: 0.047566674649715424\n",
      "Epoch: 1/5, Loss: 0.0427103191614151\n",
      "Epoch: 1/5, Loss: 0.028797507286071777\n",
      "Epoch: 1/5, Loss: 0.016955547034740448\n",
      "Epoch: 1/5, Loss: 0.012968286871910095\n",
      "Epoch: 1/5, Loss: 0.008860147558152676\n",
      "Epoch: 1/5, Loss: 0.08472814410924911\n",
      "Epoch: 1/5, Loss: 0.05262485146522522\n",
      "Epoch: 1/5, Loss: 0.0450863391160965\n",
      "Epoch: 1/5, Loss: 0.09804795682430267\n",
      "Epoch: 1/5, Loss: 0.014045079238712788\n",
      "Epoch: 1/5, Loss: 0.005348965525627136\n",
      "Epoch: 1/5, Loss: 0.035986773669719696\n",
      "Epoch: 1/5, Loss: 0.01777246594429016\n",
      "Epoch: 1/5, Loss: 0.005409271456301212\n",
      "Epoch: 1/5, Loss: 0.0013620075769722462\n",
      "Epoch: 1/5, Loss: 0.011815914884209633\n",
      "Epoch: 1/5, Loss: 0.03868116810917854\n",
      "Epoch: 1/5, Loss: 0.025276638567447662\n",
      "Epoch: 1/5, Loss: 0.013454649597406387\n",
      "Epoch: 1/5, Loss: 0.021358482539653778\n",
      "Epoch: 1/5, Loss: 0.009654989466071129\n",
      "Epoch: 1/5, Loss: 0.014977209270000458\n",
      "Epoch: 1/5, Loss: 0.005301786120980978\n",
      "Epoch: 1/5, Loss: 0.020785648375749588\n",
      "Epoch: 1/5, Loss: 0.03298916667699814\n",
      "Epoch: 1/5, Loss: 0.02603539079427719\n",
      "Epoch: 1/5, Loss: 0.01633082889020443\n",
      "Epoch: 1/5, Loss: 0.02293764054775238\n",
      "Epoch: 1/5, Loss: 0.025155387818813324\n",
      "Epoch: 1/5, Loss: 0.030328702181577682\n",
      "Epoch: 1/5, Loss: 0.01989900879561901\n",
      "Epoch: 1/5, Loss: 0.011822053231298923\n",
      "Epoch: 1/5, Loss: 0.02652634307742119\n",
      "Epoch: 1/5, Loss: 0.002854906255379319\n",
      "Epoch: 1/5, Loss: 0.02676614373922348\n",
      "Epoch: 1/5, Loss: 0.007483072578907013\n",
      "Epoch: 1/5, Loss: 0.07770294696092606\n",
      "Epoch: 1/5, Loss: 0.03338025510311127\n",
      "Epoch: 1/5, Loss: 0.016816340386867523\n",
      "Epoch: 1/5, Loss: 0.007873201742768288\n",
      "Epoch: 1/5, Loss: 0.013710595667362213\n",
      "Epoch: 1/5, Loss: 0.01952209882438183\n",
      "Epoch: 1/5, Loss: 0.0810810923576355\n",
      "Epoch: 1/5, Loss: 0.0038277781568467617\n",
      "Epoch: 1/5, Loss: 0.04539666697382927\n",
      "Epoch: 1/5, Loss: 0.010773533955216408\n",
      "Epoch: 1/5, Loss: 0.017560428008437157\n",
      "Epoch: 1/5, Loss: 0.025951102375984192\n",
      "Epoch: 1/5, Loss: 0.005160891450941563\n",
      "Epoch: 1/5, Loss: 0.007817944511771202\n",
      "Epoch: 1/5, Loss: 0.02090049907565117\n",
      "Epoch: 1/5, Loss: 0.002602160908281803\n",
      "Epoch: 1/5, Loss: 0.010132853873074055\n",
      "Epoch: 1/5, Loss: 0.00529665220528841\n",
      "Epoch: 1/5, Loss: 0.005640465300530195\n",
      "Epoch: 1/5, Loss: 0.04645087569952011\n",
      "Epoch: 1/5, Loss: 0.0024137699510902166\n",
      "Epoch: 1/5, Loss: 0.03068658709526062\n",
      "Epoch: 1/5, Loss: 0.006823488976806402\n",
      "Epoch: 1/5, Loss: 0.019795360043644905\n",
      "Epoch: 1/5, Loss: 0.02262183651328087\n",
      "Epoch: 1/5, Loss: 0.011999152600765228\n",
      "Epoch: 1/5, Loss: 0.008069900795817375\n",
      "Epoch: 1/5, Loss: 0.005781478248536587\n",
      "Epoch: 1/5, Loss: 0.018870174884796143\n",
      "Epoch: 1/5, Loss: 0.027352187782526016\n",
      "Epoch: 1/5, Loss: 0.006434560753405094\n",
      "Epoch: 1/5, Loss: 0.010270313359797001\n",
      "Epoch: 1/5, Loss: 0.018163558095693588\n",
      "Epoch: 1/5, Loss: 0.022793198004364967\n",
      "Epoch: 1/5, Loss: 0.0339725986123085\n",
      "Epoch: 1/5, Loss: 0.09171918034553528\n",
      "Epoch: 1/5, Loss: 0.047474756836891174\n",
      "Epoch: 1/5, Loss: 0.027022574096918106\n",
      "Epoch: 1/5, Loss: 0.02534112147986889\n",
      "Epoch: 1/5, Loss: 0.007535165175795555\n",
      "Epoch: 1/5, Loss: 0.0075975265353918076\n",
      "Epoch: 1/5, Loss: 0.0024664797820150852\n",
      "Epoch: 1/5, Loss: 0.022438164800405502\n",
      "Epoch: 1/5, Loss: 0.018212074413895607\n",
      "Epoch: 1/5, Loss: 0.010281313210725784\n",
      "Epoch: 1/5, Loss: 0.059700384736061096\n",
      "Epoch: 1/5, Loss: 0.009555834345519543\n",
      "Epoch: 1/5, Loss: 0.021389318630099297\n",
      "Epoch: 1/5, Loss: 0.01922118291258812\n",
      "Epoch: 1/5, Loss: 0.012871405109763145\n",
      "Epoch: 1/5, Loss: 0.004476246424019337\n",
      "Epoch: 1/5, Loss: 0.0021389727480709553\n",
      "Epoch: 1/5, Loss: 0.006540477741509676\n",
      "Epoch: 1/5, Loss: 0.02408025413751602\n",
      "Epoch: 1/5, Loss: 0.01078568585216999\n",
      "Epoch: 1/5, Loss: 0.017856165766716003\n",
      "Epoch: 1/5, Loss: 0.02575845830142498\n",
      "Epoch: 1/5, Loss: 0.01363536436110735\n",
      "Epoch: 1/5, Loss: 0.012154927477240562\n",
      "Epoch: 1/5, Loss: 0.02433706261217594\n",
      "Epoch: 1/5, Loss: 0.032189980149269104\n",
      "Epoch: 1/5, Loss: 0.007975997403264046\n",
      "Epoch: 1/5, Loss: 0.02570010907948017\n",
      "Epoch: 1/5, Loss: 0.0024355845525860786\n",
      "Epoch: 1/5, Loss: 0.010752849280834198\n",
      "Epoch: 1/5, Loss: 0.010726556181907654\n",
      "Epoch: 1/5, Loss: 0.01320740208029747\n",
      "Epoch: 1/5, Loss: 0.010387584567070007\n",
      "Epoch: 1/5, Loss: 0.010185344144701958\n",
      "Epoch: 1/5, Loss: 0.012976733967661858\n",
      "Epoch: 1/5, Loss: 0.003732134820893407\n",
      "Epoch: 1/5, Loss: 0.03706083446741104\n",
      "Epoch: 1/5, Loss: 0.05075199529528618\n",
      "Epoch: 1/5, Loss: 0.010761117562651634\n",
      "Epoch: 1/5, Loss: 0.013851617462933064\n",
      "Epoch: 1/5, Loss: 0.0245589017868042\n",
      "Epoch: 1/5, Loss: 0.030200734734535217\n",
      "Epoch: 1/5, Loss: 0.03707542270421982\n",
      "Epoch: 1/5, Loss: 0.030522987246513367\n",
      "Epoch: 1/5, Loss: 0.012464569881558418\n",
      "Epoch: 1/5, Loss: 0.045069143176078796\n",
      "Epoch: 1/5, Loss: 0.1023944839835167\n",
      "Epoch: 1/5, Loss: 0.025207310914993286\n",
      "Epoch: 1/5, Loss: 0.02724606730043888\n",
      "Epoch: 1/5, Loss: 0.0347229540348053\n",
      "Epoch: 1/5, Loss: 0.030303893610835075\n",
      "Epoch: 1/5, Loss: 0.022635120898485184\n",
      "Epoch: 1/5, Loss: 0.019794940948486328\n",
      "Epoch: 1/5, Loss: 0.025495897978544235\n",
      "Epoch: 1/5, Loss: 0.008285555988550186\n",
      "Epoch: 1/5, Loss: 0.03488924354314804\n",
      "Epoch: 1/5, Loss: 0.014800275675952435\n",
      "Epoch: 1/5, Loss: 0.03818531706929207\n",
      "Epoch: 1/5, Loss: 0.008127017877995968\n",
      "Epoch: 1/5, Loss: 0.03839476779103279\n",
      "Epoch: 1/5, Loss: 0.010721252299845219\n",
      "Epoch: 1/5, Loss: 0.044150084257125854\n",
      "Epoch: 1/5, Loss: 0.007940433919429779\n",
      "Epoch: 1/5, Loss: 0.16723856329917908\n",
      "Epoch: 1/5, Loss: 0.02636088989675045\n",
      "Epoch: 1/5, Loss: 0.04498441517353058\n",
      "Epoch: 1/5, Loss: 0.009453780949115753\n",
      "Epoch: 1/5, Loss: 0.03481251373887062\n",
      "Epoch: 1/5, Loss: 0.04726962745189667\n",
      "Epoch: 1/5, Loss: 0.018768392503261566\n",
      "Epoch: 1/5, Loss: 0.01693408004939556\n",
      "Epoch: 1/5, Loss: 0.005291671026498079\n",
      "Epoch: 1/5, Loss: 0.05975184589624405\n",
      "Epoch: 1/5, Loss: 0.02085915207862854\n",
      "Epoch: 1/5, Loss: 0.01379397138953209\n",
      "Epoch: 1/5, Loss: 0.020411817356944084\n",
      "Epoch: 1/5, Loss: 0.006305816117674112\n",
      "Epoch: 1/5, Loss: 0.01253508124500513\n",
      "Epoch: 1/5, Loss: 0.04564579576253891\n",
      "Epoch: 1/5, Loss: 0.01821918971836567\n",
      "Epoch: 1/5, Loss: 0.024184539914131165\n",
      "Epoch: 1/5, Loss: 0.0065399352461099625\n",
      "Epoch: 1/5, Loss: 0.034287288784980774\n",
      "Epoch: 1/5, Loss: 0.00880868174135685\n",
      "Epoch: 1/5, Loss: 0.012142468243837357\n",
      "Epoch: 1/5, Loss: 0.034922659397125244\n",
      "Epoch: 1/5, Loss: 0.029228296130895615\n",
      "Epoch: 1/5, Loss: 0.0006331150070764124\n",
      "Epoch: 1/5, Loss: 0.04022372514009476\n",
      "Epoch: 1/5, Loss: 0.0070354752242565155\n",
      "Epoch: 1/5, Loss: 0.07255446910858154\n",
      "Epoch: 1/5, Loss: 0.01701679825782776\n",
      "Epoch: 1/5, Loss: 0.010547967627644539\n",
      "Epoch: 1/5, Loss: 0.10190127789974213\n",
      "Epoch: 1/5, Loss: 0.005450936499983072\n",
      "Epoch: 1/5, Loss: 0.01723671704530716\n",
      "Epoch: 1/5, Loss: 0.013305949047207832\n",
      "Epoch: 1/5, Loss: 0.02264816127717495\n",
      "Epoch: 1/5, Loss: 0.017204301431775093\n",
      "Epoch: 1/5, Loss: 0.007029698695987463\n",
      "Epoch: 1/5, Loss: 0.019880501553416252\n",
      "Epoch: 1/5, Loss: 0.009026661515235901\n",
      "Epoch: 1/5, Loss: 0.05002685263752937\n",
      "Epoch: 1/5, Loss: 0.03062535636126995\n",
      "Epoch: 1/5, Loss: 0.018666865304112434\n",
      "Epoch: 1/5, Loss: 0.009306473657488823\n",
      "Epoch: 1/5, Loss: 0.004177279770374298\n",
      "Epoch: 1/5, Loss: 0.07279989868402481\n",
      "Epoch: 1/5, Loss: 0.005796856712549925\n",
      "Epoch: 1/5, Loss: 0.008623490110039711\n",
      "Epoch: 1/5, Loss: 0.02600979618728161\n",
      "Epoch: 1/5, Loss: 0.04871099814772606\n",
      "Epoch: 1/5, Loss: 0.03577149286866188\n",
      "Epoch: 1/5, Loss: 0.028787314891815186\n",
      "Epoch: 1/5, Loss: 0.0037580819334834814\n",
      "Epoch: 1/5, Loss: 0.02300901710987091\n",
      "Epoch: 1/5, Loss: 0.010439966805279255\n",
      "Epoch: 1/5, Loss: 0.02243015170097351\n",
      "Epoch: 1/5, Loss: 0.000872629985678941\n",
      "Epoch: 1/5, Loss: 0.03524906188249588\n",
      "Epoch: 1/5, Loss: 0.04687489941716194\n",
      "Epoch: 1/5, Loss: 0.02429862506687641\n",
      "Epoch: 1/5, Loss: 0.03950341418385506\n",
      "Epoch: 1/5, Loss: 0.009496470913290977\n",
      "Epoch: 1/5, Loss: 0.020749319344758987\n",
      "Epoch: 1/5, Loss: 0.016868755221366882\n",
      "Epoch: 1/5, Loss: 0.02699161320924759\n",
      "Epoch: 1/5, Loss: 0.008322951383888721\n",
      "Epoch: 1/5, Loss: 0.010432836599647999\n",
      "Epoch: 1/5, Loss: 0.04035777598619461\n",
      "Epoch: 1/5, Loss: 0.0074404459446668625\n",
      "Epoch: 1/5, Loss: 0.016846824437379837\n",
      "Epoch: 1/5, Loss: 0.03452561795711517\n",
      "Epoch: 1/5, Loss: 0.01468497235327959\n",
      "Epoch: 1/5, Loss: 0.006747918203473091\n",
      "Epoch: 1/5, Loss: 0.01722348853945732\n",
      "Epoch: 1/5, Loss: 0.023089125752449036\n",
      "Epoch: 1/5, Loss: 0.019565680995583534\n",
      "Epoch: 1/5, Loss: 0.020135238766670227\n",
      "Epoch: 1/5, Loss: 0.012227969244122505\n",
      "Epoch: 1/5, Loss: 0.008693348616361618\n",
      "Epoch: 1/5, Loss: 0.047730859369039536\n",
      "Epoch: 1/5, Loss: 0.02978895790874958\n",
      "Epoch: 1/5, Loss: 0.08551984280347824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Loss: 0.006749791093170643\n",
      "Epoch: 1/5, Loss: 0.03486727178096771\n",
      "Epoch: 1/5, Loss: 0.01004727091640234\n",
      "Epoch: 1/5, Loss: 0.007355629466474056\n",
      "Epoch: 1/5, Loss: 0.009030179120600224\n",
      "Epoch: 1/5, Loss: 0.02190639264881611\n",
      "Epoch: 1/5, Loss: 0.015180024318397045\n",
      "Epoch: 1/5, Loss: 0.009470746852457523\n",
      "Epoch: 1/5, Loss: 0.019257359206676483\n",
      "Epoch: 1/5, Loss: 0.0463741198182106\n",
      "Epoch: 1/5, Loss: 0.027712959796190262\n",
      "Epoch: 1/5, Loss: 0.013358344323933125\n",
      "Epoch: 1/5, Loss: 0.02393767051398754\n",
      "Epoch: 1/5, Loss: 0.03285139799118042\n",
      "Epoch: 1/5, Loss: 0.02170288935303688\n",
      "Epoch: 1/5, Loss: 0.009831451810896397\n",
      "Epoch: 1/5, Loss: 0.01128952857106924\n",
      "Epoch: 1/5, Loss: 0.04337803274393082\n",
      "Epoch: 1/5, Loss: 0.01503289956599474\n",
      "Epoch: 1/5, Loss: 0.07642859220504761\n",
      "Epoch: 1/5, Loss: 0.01858590357005596\n",
      "Epoch: 1/5, Loss: 0.004729330074042082\n",
      "Epoch: 1/5, Loss: 0.00626685656607151\n",
      "Epoch: 1/5, Loss: 0.013095961883664131\n",
      "Epoch: 1/5, Loss: 0.007404469884932041\n",
      "Epoch: 1/5, Loss: 0.03605971857905388\n",
      "Epoch: 1/5, Loss: 0.0024843791034072638\n",
      "Epoch: 1/5, Loss: 0.0394139438867569\n",
      "Epoch: 1/5, Loss: 0.015634343028068542\n",
      "Epoch: 1/5, Loss: 0.026879169046878815\n",
      "Epoch: 1/5, Loss: 0.006715784315019846\n",
      "Epoch: 1/5, Loss: 0.04561203718185425\n",
      "Epoch: 1/5, Loss: 0.009217527695000172\n",
      "Epoch: 1/5, Loss: 0.023238113150000572\n",
      "Epoch: 1/5, Loss: 0.04127603396773338\n",
      "Epoch: 1/5, Loss: 0.020374322310090065\n",
      "Epoch: 1/5, Loss: 0.02774818241596222\n",
      "Epoch: 1/5, Loss: 0.02154437266290188\n",
      "Epoch: 1/5, Loss: 0.008594793267548084\n",
      "Epoch: 1/5, Loss: 0.00518156448379159\n",
      "Epoch: 1/5, Loss: 0.01590563915669918\n",
      "Epoch: 1/5, Loss: 0.02149241790175438\n",
      "Epoch: 1/5, Loss: 0.0019237762317061424\n",
      "Epoch: 1/5, Loss: 0.020946776494383812\n",
      "Epoch: 1/5, Loss: 0.012661043554544449\n",
      "Epoch: 1/5, Loss: 0.005620882846415043\n",
      "Epoch: 1/5, Loss: 0.015056027099490166\n",
      "Epoch: 1/5, Loss: 0.003942966926842928\n",
      "Epoch: 1/5, Loss: 0.012617887929081917\n",
      "Epoch: 1/5, Loss: 0.036636848002672195\n",
      "Epoch: 1/5, Loss: 0.02476070448756218\n",
      "Epoch: 1/5, Loss: 0.03762378543615341\n",
      "Epoch: 1/5, Loss: 0.02130422368645668\n",
      "Epoch: 1/5, Loss: 0.02326730638742447\n",
      "Epoch: 1/5, Loss: 0.016193140298128128\n",
      "Epoch: 1/5, Loss: 0.013911783695220947\n",
      "Epoch: 1/5, Loss: 0.01317026186734438\n",
      "Epoch: 1/5, Loss: 0.038758404552936554\n",
      "Epoch: 1/5, Loss: 0.02242874540388584\n",
      "Epoch: 1/5, Loss: 0.002182775642722845\n",
      "Epoch: 1/5, Loss: 0.013631009496748447\n",
      "Epoch: 1/5, Loss: 0.014750422909855843\n",
      "Epoch: 1/5, Loss: 0.016227371990680695\n",
      "Epoch: 1/5, Loss: 0.04412548989057541\n",
      "Epoch: 1/5, Loss: 0.03230272978544235\n",
      "Epoch: 1/5, Loss: 0.025088924914598465\n",
      "Epoch: 1/5, Loss: 0.0722377598285675\n",
      "Epoch: 1/5, Loss: 0.027150122448801994\n",
      "Epoch: 1/5, Loss: 0.009119558148086071\n",
      "Epoch: 1/5, Loss: 0.020862603560090065\n",
      "Epoch: 1/5, Loss: 0.018178774043917656\n",
      "Epoch: 1/5, Loss: 0.011695127934217453\n",
      "Epoch: 1/5, Loss: 0.03401961922645569\n",
      "Epoch: 1/5, Loss: 0.01704697497189045\n",
      "Epoch: 1/5, Loss: 0.005729177501052618\n",
      "Epoch: 1/5, Loss: 0.014731641858816147\n",
      "Epoch: 1/5, Loss: 0.026102738454937935\n",
      "Epoch: 1/5, Loss: 0.0130710918456316\n",
      "Epoch: 1/5, Loss: 0.13471637666225433\n",
      "Epoch: 1/5, Loss: 0.03616505488753319\n",
      "Epoch: 1/5, Loss: 0.003113547572866082\n",
      "Epoch: 1/5, Loss: 0.009617209434509277\n",
      "Epoch: 1/5, Loss: 0.02378656342625618\n",
      "Epoch: 1/5, Loss: 0.015514479950070381\n",
      "Epoch: 1/5, Loss: 0.0062226224690675735\n",
      "Epoch: 1/5, Loss: 0.028513506054878235\n",
      "Epoch: 1/5, Loss: 0.03208587318658829\n",
      "Epoch: 1/5, Loss: 0.014425045810639858\n",
      "Epoch: 1/5, Loss: 0.009642213582992554\n",
      "Epoch: 1/5, Loss: 0.006309738382697105\n",
      "Epoch: 1/5, Loss: 0.01277734711766243\n",
      "Epoch: 1/5, Loss: 0.011382972821593285\n",
      "Epoch: 1/5, Loss: 0.04221286624670029\n",
      "Epoch: 1/5, Loss: 0.02207321859896183\n",
      "Epoch: 1/5, Loss: 0.007208016235381365\n",
      "Epoch: 1/5, Loss: 0.026942061260342598\n",
      "Epoch: 1/5, Loss: 0.022535597905516624\n",
      "Epoch: 1/5, Loss: 0.0066388375125825405\n",
      "Epoch: 1/5, Loss: 0.012094908393919468\n",
      "Epoch: 1/5, Loss: 0.021935410797595978\n",
      "Epoch: 1/5, Loss: 0.02863832376897335\n",
      "Epoch: 1/5, Loss: 0.020051440224051476\n",
      "Epoch: 1/5, Loss: 0.013591143302619457\n",
      "Epoch: 1/5, Loss: 0.052576348185539246\n",
      "Epoch: 1/5, Loss: 0.0298328697681427\n",
      "Epoch: 1/5, Loss: 0.008050787262618542\n",
      "Epoch: 1/5, Loss: 0.0289143119007349\n",
      "Epoch: 1/5, Loss: 0.0035245143808424473\n",
      "Epoch: 1/5, Loss: 0.009785069152712822\n",
      "Epoch: 1/5, Loss: 0.003707766765728593\n",
      "Epoch: 1/5, Loss: 0.0218491293489933\n",
      "Epoch: 1/5, Loss: 0.01682051084935665\n",
      "Epoch: 1/5, Loss: 0.016730675473809242\n",
      "Epoch: 1/5, Loss: 0.011405068449676037\n",
      "Epoch: 1/5, Loss: 0.010197480209171772\n",
      "Epoch: 1/5, Loss: 0.052873291075229645\n",
      "Epoch: 1/5, Loss: 0.02258887141942978\n",
      "Epoch: 1/5, Loss: 0.01998015306890011\n",
      "Epoch: 1/5, Loss: 0.02371037006378174\n",
      "Epoch: 1/5, Loss: 0.010163265280425549\n",
      "Epoch: 1/5, Loss: 0.042852260172367096\n",
      "Epoch: 1/5, Loss: 0.020313365384936333\n",
      "Epoch: 1/5, Loss: 0.022981073707342148\n",
      "Epoch: 1/5, Loss: 0.08871180564165115\n",
      "Epoch: 1/5, Loss: 0.04189784452319145\n",
      "Epoch: 1/5, Loss: 0.033243872225284576\n",
      "Epoch: 1/5, Loss: 0.042356912046670914\n",
      "Epoch: 1/5, Loss: 0.02089860290288925\n",
      "Epoch: 1/5, Loss: 0.013536114245653152\n",
      "Epoch: 1/5, Loss: 0.008593740873038769\n",
      "Epoch: 1/5, Loss: 0.015633370727300644\n",
      "Epoch: 1/5, Loss: 0.012720422819256783\n",
      "Epoch: 1/5, Loss: 0.024327578023076057\n",
      "Epoch: 1/5, Loss: 0.006337554194033146\n",
      "Epoch: 1/5, Loss: 0.0606837272644043\n",
      "Epoch: 1/5, Loss: 0.010547757148742676\n",
      "Epoch: 1/5, Loss: 0.03800668194890022\n",
      "Epoch: 1/5, Loss: 0.012999833561480045\n",
      "Epoch: 1/5, Loss: 0.023581817746162415\n",
      "Epoch: 1/5, Loss: 0.03650129213929176\n",
      "Epoch: 1/5, Loss: 0.01153259351849556\n",
      "Epoch: 1/5, Loss: 0.0168704092502594\n",
      "Epoch: 1/5, Loss: 0.0203569196164608\n",
      "Epoch: 1/5, Loss: 0.041650135070085526\n",
      "Epoch: 1/5, Loss: 0.027367493137717247\n",
      "Epoch: 1/5, Loss: 0.01658392883837223\n",
      "Epoch: 1/5, Loss: 0.059169359505176544\n",
      "Epoch: 1/5, Loss: 0.007931423373520374\n",
      "Epoch: 1/5, Loss: 0.011985789984464645\n",
      "Epoch: 1/5, Loss: 0.008802283555269241\n",
      "Epoch: 1/5, Loss: 0.017319781705737114\n",
      "Epoch: 1/5, Loss: 0.028129909187555313\n",
      "Epoch: 1/5, Loss: 0.027003206312656403\n",
      "Epoch: 1/5, Loss: 0.027670729905366898\n",
      "Epoch: 1/5, Loss: 0.028636552393436432\n",
      "Epoch: 1/5, Loss: 0.04445456340909004\n",
      "Epoch: 1/5, Loss: 0.02815340645611286\n",
      "Epoch: 1/5, Loss: 0.009776534512639046\n",
      "Epoch: 1/5, Loss: 0.0065945773385465145\n",
      "Epoch: 1/5, Loss: 0.010679280385375023\n",
      "Epoch: 1/5, Loss: 0.0066442592069506645\n",
      "Epoch: 1/5, Loss: 0.00336829898878932\n",
      "Epoch: 1/5, Loss: 0.010069925338029861\n",
      "Epoch: 1/5, Loss: 0.0281731765717268\n",
      "Epoch: 1/5, Loss: 0.029330827295780182\n",
      "Epoch: 1/5, Loss: 0.08827881515026093\n",
      "Epoch: 1/5, Loss: 0.015880335122346878\n",
      "Epoch: 1/5, Loss: 0.015354171395301819\n",
      "Epoch: 1/5, Loss: 0.09093469381332397\n",
      "Epoch: 1/5, Loss: 0.007566728163510561\n",
      "Epoch: 1/5, Loss: 0.08771878480911255\n",
      "Epoch: 1/5, Loss: 0.007654466666281223\n",
      "Epoch: 1/5, Loss: 0.020858099684119225\n",
      "Epoch: 1/5, Loss: 0.007159208878874779\n",
      "Epoch: 1/5, Loss: 0.0566333569586277\n",
      "Epoch: 1/5, Loss: 0.01631663553416729\n",
      "Epoch: 1/5, Loss: 0.012950090691447258\n",
      "Epoch: 1/5, Loss: 0.037666454911231995\n",
      "Epoch: 1/5, Loss: 0.015690647065639496\n",
      "Epoch: 1/5, Loss: 0.012625433504581451\n",
      "Epoch: 1/5, Loss: 0.008410945534706116\n",
      "Epoch: 1/5, Loss: 0.0204352755099535\n",
      "Epoch: 1/5, Loss: 0.005850787740200758\n",
      "Epoch: 1/5, Loss: 0.057274095714092255\n",
      "Epoch: 1/5, Loss: 0.06295669078826904\n",
      "Epoch: 1/5, Loss: 0.0015019720885902643\n",
      "Epoch: 1/5, Loss: 0.036362454295158386\n",
      "Epoch: 1/5, Loss: 0.0097022894769907\n",
      "Epoch: 1/5, Loss: 0.02751816250383854\n",
      "Epoch: 1/5, Loss: 0.0009249732247553766\n",
      "Epoch: 1/5, Loss: 0.00951438955962658\n",
      "Epoch: 1/5, Loss: 0.0052016605623066425\n",
      "Epoch: 1/5, Loss: 0.020132359117269516\n",
      "Epoch: 1/5, Loss: 0.04959922283887863\n",
      "Epoch: 1/5, Loss: 0.0021750214509665966\n",
      "Epoch: 1/5, Loss: 0.001683605252765119\n",
      "Epoch: 1/5, Loss: 0.00140747195109725\n",
      "Epoch: 1/5, Loss: 0.00874626636505127\n",
      "Epoch: 1/5, Loss: 0.013183321803808212\n",
      "Epoch: 1/5, Loss: 0.003239664249122143\n",
      "Epoch: 1/5, Loss: 0.008989416994154453\n",
      "Epoch: 1/5, Loss: 0.009282106533646584\n",
      "Epoch: 1/5, Loss: 0.01388001162558794\n",
      "Epoch: 1/5, Loss: 0.041891127824783325\n",
      "Epoch: 1/5, Loss: 0.01946525275707245\n",
      "Epoch: 1/5, Loss: 0.0010304152965545654\n",
      "Epoch: 1/5, Loss: 0.004671470262110233\n",
      "Epoch: 1/5, Loss: 0.020090986043214798\n",
      "Epoch: 1/5, Loss: 0.024052996188402176\n",
      "Epoch: 1/5, Loss: 0.014704661443829536\n",
      "Epoch: 1/5, Loss: 0.05210939422249794\n",
      "Epoch: 1/5, Loss: 0.009561066515743732\n",
      "Epoch: 1/5, Loss: 0.03673524037003517\n",
      "Epoch: 1/5, Loss: 0.028911661356687546\n",
      "Epoch: 1/5, Loss: 0.018954336643218994\n",
      "Epoch: 1/5, Loss: 0.009596394374966621\n",
      "Epoch: 1/5, Loss: 0.024713201448321342\n",
      "Epoch: 1/5, Loss: 0.009201263077557087\n",
      "Epoch: 1/5, Loss: 0.10753882676362991\n",
      "Epoch: 1/5, Loss: 0.005116879008710384\n",
      "Epoch: 1/5, Loss: 0.02013852261006832\n",
      "Epoch: 1/5, Loss: 0.03617434576153755\n",
      "Epoch: 1/5, Loss: 0.019355330616235733\n",
      "Epoch: 1/5, Loss: 0.01264106947928667\n",
      "Epoch: 1/5, Loss: 0.025020115077495575\n",
      "Epoch: 1/5, Loss: 0.031165027990937233\n",
      "Epoch: 1/5, Loss: 0.0291092898696661\n",
      "Epoch: 1/5, Loss: 0.017509441822767258\n",
      "Epoch: 1/5, Loss: 0.03034343011677265\n",
      "Epoch: 1/5, Loss: 0.030429139733314514\n",
      "Epoch: 1/5, Loss: 0.0032411455176770687\n",
      "Epoch: 1/5, Loss: 0.023136712610721588\n",
      "Epoch: 1/5, Loss: 0.020766735076904297\n",
      "Epoch: 1/5, Loss: 0.01705009862780571\n",
      "Epoch: 1/5, Loss: 0.01942051574587822\n",
      "Epoch: 1/5, Loss: 0.016742784529924393\n",
      "Epoch: 1/5, Loss: 0.005571655463427305\n",
      "Epoch: 1/5, Loss: 0.012693135999143124\n",
      "Epoch: 1/5, Loss: 0.004355365410447121\n",
      "Epoch: 1/5, Loss: 0.041562195867300034\n",
      "Epoch: 1/5, Loss: 0.012159723788499832\n",
      "Epoch: 1/5, Loss: 0.03372076153755188\n",
      "Epoch: 1/5, Loss: 0.030398491770029068\n",
      "Epoch: 1/5, Loss: 0.0016765904147177935\n",
      "Epoch: 1/5, Loss: 0.024582769721746445\n",
      "Epoch: 1/5, Loss: 0.015158044174313545\n",
      "Epoch: 1/5, Loss: 0.007803691551089287\n",
      "Epoch: 1/5, Loss: 0.013798408210277557\n",
      "Epoch: 1/5, Loss: 0.007353679742664099\n",
      "Epoch: 1/5, Loss: 0.009674690663814545\n",
      "Epoch: 1/5, Loss: 0.005572450812906027\n",
      "Epoch: 1/5, Loss: 0.014019629918038845\n",
      "Epoch: 1/5, Loss: 0.01553419604897499\n",
      "Epoch: 1/5, Loss: 0.014555794186890125\n",
      "Epoch: 1/5, Loss: 0.0038023660890758038\n",
      "Epoch: 1/5, Loss: 0.0449681282043457\n",
      "Epoch: 1/5, Loss: 0.04525762051343918\n",
      "Epoch: 1/5, Loss: 0.00565753597766161\n",
      "Epoch: 1/5, Loss: 0.012758747674524784\n",
      "Epoch: 1/5, Loss: 0.012375961057841778\n",
      "Epoch: 1/5, Loss: 0.005211499519646168\n",
      "Epoch: 1/5, Loss: 0.0285215862095356\n",
      "Epoch: 1/5, Loss: 0.010760508477687836\n",
      "Epoch: 1/5, Loss: 0.007748555392026901\n",
      "Epoch: 1/5, Loss: 0.016016295179724693\n",
      "Epoch: 1/5, Loss: 0.006546259392052889\n",
      "Epoch: 1/5, Loss: 0.016074180603027344\n",
      "Epoch: 1/5, Loss: 0.01699032075703144\n",
      "Epoch: 1/5, Loss: 0.018943186849355698\n",
      "Epoch: 1/5, Loss: 0.018048295751214027\n",
      "Epoch: 1/5, Loss: 0.016275476664304733\n",
      "Epoch: 1/5, Loss: 0.03726167231798172\n",
      "Epoch: 1/5, Loss: 0.014619957655668259\n",
      "Epoch: 1/5, Loss: 0.0033631024416536093\n",
      "Epoch: 1/5, Loss: 0.030828434973955154\n",
      "Epoch: 1/5, Loss: 0.04539645463228226\n",
      "Epoch: 1/5, Loss: 0.022968711331486702\n",
      "Epoch: 1/5, Loss: 0.08163031935691833\n",
      "Epoch: 1/5, Loss: 0.015136301517486572\n",
      "Epoch: 1/5, Loss: 0.004140352830290794\n",
      "Epoch: 1/5, Loss: 0.03118678368628025\n",
      "Epoch: 1/5, Loss: 0.03729521483182907\n",
      "Epoch: 1/5, Loss: 0.019648104906082153\n",
      "Epoch: 1/5, Loss: 0.01899017207324505\n",
      "Epoch: 1/5, Loss: 0.024265144020318985\n",
      "Epoch: 1/5, Loss: 0.00923120230436325\n",
      "Epoch: 1/5, Loss: 0.007352917455136776\n",
      "Epoch: 1/5, Loss: 0.003064086427912116\n",
      "Epoch: 1/5, Loss: 0.026358358561992645\n",
      "Epoch: 1/5, Loss: 0.009174579754471779\n",
      "Epoch: 1/5, Loss: 0.027435462921857834\n",
      "Epoch: 1/5, Loss: 0.029169147834181786\n",
      "Epoch: 1/5, Loss: 0.02687324583530426\n",
      "Epoch: 1/5, Loss: 0.00651228241622448\n",
      "Epoch: 1/5, Loss: 0.048482850193977356\n",
      "Epoch: 1/5, Loss: 0.03352655470371246\n",
      "Epoch: 1/5, Loss: 0.02854832261800766\n",
      "Epoch: 1/5, Loss: 0.03146052733063698\n",
      "Epoch: 1/5, Loss: 0.010934092104434967\n",
      "Epoch: 1/5, Loss: 0.03262441232800484\n",
      "Epoch: 1/5, Loss: 0.004271721467375755\n",
      "Epoch: 1/5, Loss: 0.017624234780669212\n",
      "Epoch: 1/5, Loss: 0.09129512310028076\n",
      "Epoch: 1/5, Loss: 0.010788277722895145\n",
      "Epoch: 1/5, Loss: 0.06152358278632164\n",
      "Epoch: 1/5, Loss: 0.03146239370107651\n",
      "Epoch: 1/5, Loss: 0.05648941174149513\n",
      "Epoch: 1/5, Loss: 0.011333247646689415\n",
      "Epoch: 1/5, Loss: 0.013948867097496986\n",
      "Epoch: 1/5, Loss: 0.022780101746320724\n",
      "Epoch: 1/5, Loss: 0.004355877637863159\n",
      "Epoch: 1/5, Loss: 0.02642803080379963\n",
      "Epoch: 1/5, Loss: 0.008724087849259377\n",
      "Epoch: 1/5, Loss: 0.03891678899526596\n",
      "Epoch: 1/5, Loss: 0.013388111256062984\n",
      "Epoch: 1/5, Loss: 0.007446282543241978\n",
      "Epoch: 1/5, Loss: 0.0030892682261765003\n",
      "Epoch: 1/5, Loss: 0.033636365085840225\n",
      "Epoch: 1/5, Loss: 0.0146647272631526\n",
      "Epoch: 1/5, Loss: 0.04249880835413933\n",
      "Epoch: 1/5, Loss: 0.009827788919210434\n",
      "Epoch: 1/5, Loss: 0.030539320781826973\n",
      "Epoch: 1/5, Loss: 0.017373105511069298\n",
      "Epoch: 1/5, Loss: 0.015749109908938408\n",
      "Epoch: 1/5, Loss: 0.034910522401332855\n",
      "Epoch: 1/5, Loss: 0.026684680953621864\n",
      "Epoch: 1/5, Loss: 0.011756795458495617\n",
      "Epoch: 1/5, Loss: 0.011573245748877525\n",
      "Epoch: 1/5, Loss: 0.020186608657240868\n",
      "Epoch: 1/5, Loss: 0.025004805997014046\n",
      "Epoch: 1/5, Loss: 0.01802431233227253\n",
      "Epoch: 1/5, Loss: 0.021111879497766495\n",
      "Epoch: 1/5, Loss: 0.0062707457691431046\n",
      "Epoch: 1/5, Loss: 0.014088187366724014\n",
      "Epoch: 1/5, Loss: 0.005866425111889839\n",
      "Epoch: 1/5, Loss: 0.02937135472893715\n",
      "Epoch: 1/5, Loss: 0.008782590739428997\n",
      "Epoch: 1/5, Loss: 0.018794234842061996\n",
      "Epoch: 1/5, Loss: 0.012006338685750961\n",
      "Epoch: 1/5, Loss: 0.051962584257125854\n",
      "Epoch: 1/5, Loss: 0.041336581110954285\n",
      "Epoch: 1/5, Loss: 0.039261896163225174\n",
      "Epoch: 1/5, Loss: 0.06652862578630447\n",
      "Epoch: 1/5, Loss: 0.020611019805073738\n",
      "Epoch: 1/5, Loss: 0.018160531297326088\n",
      "Epoch: 1/5, Loss: 0.010628585703670979\n",
      "Epoch: 1/5, Loss: 0.012080512940883636\n",
      "Epoch: 1/5, Loss: 0.04351329430937767\n",
      "Epoch: 1/5, Loss: 0.04849957302212715\n",
      "Epoch: 1/5, Loss: 0.007608880754560232\n",
      "Epoch: 1/5, Loss: 0.0038615455850958824\n",
      "Epoch: 1/5, Loss: 0.022861212491989136\n",
      "Epoch: 1/5, Loss: 0.008439500816166401\n",
      "Epoch: 1/5, Loss: 0.0013743649469688535\n",
      "Epoch: 1/5, Loss: 0.05297547206282616\n",
      "Epoch: 1/5, Loss: 0.005903542973101139\n",
      "Epoch: 1/5, Loss: 0.023549536243081093\n",
      "Epoch: 1/5, Loss: 0.03758871182799339\n",
      "Epoch: 1/5, Loss: 0.005937965586781502\n",
      "Epoch: 1/5, Loss: 0.0031485643703490496\n",
      "Epoch: 1/5, Loss: 0.01588897965848446\n",
      "Epoch: 1/5, Loss: 0.01769356243312359\n",
      "Epoch: 1/5, Loss: 0.014901270158588886\n",
      "Epoch: 1/5, Loss: 0.009497342631220818\n",
      "Epoch: 1/5, Loss: 0.023915249854326248\n",
      "Epoch: 1/5, Loss: 0.039062440395355225\n",
      "Epoch: 1/5, Loss: 0.06452177464962006\n",
      "Epoch: 1/5, Loss: 0.011668459512293339\n",
      "Epoch: 1/5, Loss: 0.025890812277793884\n",
      "Epoch: 1/5, Loss: 0.033804748207330704\n",
      "Epoch: 1/5, Loss: 0.003493578638881445\n",
      "Epoch: 1/5, Loss: 0.04507061839103699\n",
      "Epoch: 1/5, Loss: 0.00839192047715187\n",
      "Epoch: 1/5, Loss: 0.00292496127076447\n",
      "Epoch: 1/5, Loss: 0.027316391468048096\n",
      "Epoch: 1/5, Loss: 0.017506282776594162\n",
      "Epoch: 1/5, Loss: 0.010276669636368752\n",
      "Epoch: 1/5, Loss: 0.01874147355556488\n",
      "Epoch: 1/5, Loss: 0.017415693029761314\n",
      "Epoch: 1/5, Loss: 0.011474636383354664\n",
      "Epoch: 1/5, Loss: 0.006048216018825769\n",
      "Epoch: 1/5, Loss: 0.02252223901450634\n",
      "Epoch: 1/5, Loss: 0.04964447766542435\n",
      "Epoch: 1/5, Loss: 0.008029406890273094\n",
      "Epoch: 1/5, Loss: 0.024163631722331047\n",
      "Epoch: 1/5, Loss: 0.004517932888120413\n",
      "Epoch: 1/5, Loss: 0.022828109562397003\n",
      "Epoch: 1/5, Loss: 0.04276743158698082\n",
      "Epoch: 1/5, Loss: 0.008801118470728397\n",
      "Epoch: 1/5, Loss: 0.04430730268359184\n",
      "Epoch: 1/5, Loss: 0.015854187309741974\n",
      "Epoch: 1/5, Loss: 0.03373697027564049\n",
      "Epoch: 1/5, Loss: 0.02427648939192295\n",
      "Epoch: 1/5, Loss: 0.006086380686610937\n",
      "Epoch: 1/5, Loss: 0.018763378262519836\n",
      "Epoch: 1/5, Loss: 0.0043172286823391914\n",
      "Epoch: 1/5, Loss: 0.0056870258413255215\n",
      "Epoch: 1/5, Loss: 0.025242259725928307\n",
      "Epoch: 1/5, Loss: 0.013346307910978794\n",
      "Epoch: 1/5, Loss: 0.005183047149330378\n",
      "Epoch: 1/5, Loss: 0.011402752250432968\n",
      "Epoch: 1/5, Loss: 0.009946616366505623\n",
      "Epoch: 1/5, Loss: 0.02038392424583435\n",
      "Epoch: 1/5, Loss: 0.019365964457392693\n",
      "Epoch: 1/5, Loss: 0.05049412325024605\n",
      "Epoch: 1/5, Loss: 0.0008297712774947286\n",
      "Epoch: 1/5, Loss: 0.025463514029979706\n",
      "Epoch: 1/5, Loss: 0.01445485558360815\n",
      "Epoch: 1/5, Loss: 0.014879759401082993\n",
      "Epoch: 1/5, Loss: 0.006492449436336756\n",
      "Epoch: 1/5, Loss: 0.004632281605154276\n",
      "Epoch: 1/5, Loss: 0.045025672763586044\n",
      "Epoch: 1/5, Loss: 0.02219647914171219\n",
      "Epoch: 1/5, Loss: 0.004139060154557228\n",
      "Epoch: 1/5, Loss: 0.009310499764978886\n",
      "Epoch: 1/5, Loss: 0.02457308955490589\n",
      "Epoch: 1/5, Loss: 0.00649873074144125\n",
      "Epoch: 1/5, Loss: 0.02982526645064354\n",
      "Epoch: 1/5, Loss: 0.01810307987034321\n",
      "Epoch: 1/5, Loss: 0.0048004924319684505\n",
      "Epoch: 1/5, Loss: 0.02849476970732212\n",
      "Epoch: 1/5, Loss: 0.031656503677368164\n",
      "Epoch: 1/5, Loss: 0.009536062367260456\n",
      "Epoch: 1/5, Loss: 0.015262637287378311\n",
      "Epoch: 1/5, Loss: 0.09574876725673676\n",
      "Epoch: 1/5, Loss: 0.008534923195838928\n",
      "Epoch: 1/5, Loss: 0.023192107677459717\n",
      "Epoch: 1/5, Loss: 0.022477250546216965\n",
      "Epoch: 1/5, Loss: 0.002947053639218211\n",
      "Epoch: 1/5, Loss: 0.02332955040037632\n",
      "Epoch: 1/5, Loss: 0.007741693407297134\n",
      "Epoch: 1/5, Loss: 0.01568007655441761\n",
      "Epoch: 1/5, Loss: 0.006030808202922344\n",
      "Epoch: 1/5, Loss: 0.005903034936636686\n",
      "Epoch: 1/5, Loss: 0.012293851003050804\n",
      "Epoch: 1/5, Loss: 0.022721605375409126\n",
      "Epoch: 1/5, Loss: 0.040181417018175125\n",
      "Epoch: 1/5, Loss: 0.012840790674090385\n",
      "Epoch: 1/5, Loss: 0.005595777183771133\n",
      "Epoch: 1/5, Loss: 0.010747870430350304\n",
      "Epoch: 1/5, Loss: 0.018774742260575294\n",
      "Epoch: 1/5, Loss: 0.03153720498085022\n",
      "Epoch: 1/5, Loss: 0.012502707540988922\n",
      "Epoch: 1/5, Loss: 0.006033888086676598\n",
      "Epoch: 1/5, Loss: 0.013109078630805016\n",
      "Epoch: 1/5, Loss: 0.017427846789360046\n",
      "Epoch: 1/5, Loss: 0.02933499962091446\n",
      "Epoch: 2/5, Loss: 0.06624343991279602\n",
      "Epoch: 2/5, Loss: 0.03850657492876053\n",
      "Epoch: 2/5, Loss: 0.010617940686643124\n",
      "Epoch: 2/5, Loss: 0.007420610636472702\n",
      "Epoch: 2/5, Loss: 0.016461575403809547\n",
      "Epoch: 2/5, Loss: 0.030446365475654602\n",
      "Epoch: 2/5, Loss: 0.016584070399403572\n",
      "Epoch: 2/5, Loss: 0.0049804458394646645\n",
      "Epoch: 2/5, Loss: 0.030814437195658684\n",
      "Epoch: 2/5, Loss: 0.03775867819786072\n",
      "Epoch: 2/5, Loss: 0.006898023188114166\n",
      "Epoch: 2/5, Loss: 0.004494853317737579\n",
      "Epoch: 2/5, Loss: 0.009851590730249882\n",
      "Epoch: 2/5, Loss: 0.006191697437316179\n",
      "Epoch: 2/5, Loss: 0.021185465157032013\n",
      "Epoch: 2/5, Loss: 0.003910591825842857\n",
      "Epoch: 2/5, Loss: 0.015421915799379349\n",
      "Epoch: 2/5, Loss: 0.037628594785928726\n",
      "Epoch: 2/5, Loss: 0.027609283104538918\n",
      "Epoch: 2/5, Loss: 0.0061430130153894424\n",
      "Epoch: 2/5, Loss: 0.027857542037963867\n",
      "Epoch: 2/5, Loss: 0.026138534769415855\n",
      "Epoch: 2/5, Loss: 0.009634283371269703\n",
      "Epoch: 2/5, Loss: 0.02484288066625595\n",
      "Epoch: 2/5, Loss: 0.0068049198016524315\n",
      "Epoch: 2/5, Loss: 0.04706752300262451\n",
      "Epoch: 2/5, Loss: 0.010971124283969402\n",
      "Epoch: 2/5, Loss: 0.03662988543510437\n",
      "Epoch: 2/5, Loss: 0.013146101497113705\n",
      "Epoch: 2/5, Loss: 0.030876105651259422\n",
      "Epoch: 2/5, Loss: 0.05370434746146202\n",
      "Epoch: 2/5, Loss: 0.020066985860466957\n",
      "Epoch: 2/5, Loss: 0.008061636239290237\n",
      "Epoch: 2/5, Loss: 0.0188737940043211\n",
      "Epoch: 2/5, Loss: 0.017183832824230194\n",
      "Epoch: 2/5, Loss: 0.018424175679683685\n",
      "Epoch: 2/5, Loss: 0.0017540386179462075\n",
      "Epoch: 2/5, Loss: 0.03677740320563316\n",
      "Epoch: 2/5, Loss: 0.014865981414914131\n",
      "Epoch: 2/5, Loss: 0.019562046974897385\n",
      "Epoch: 2/5, Loss: 0.010314874351024628\n",
      "Epoch: 2/5, Loss: 0.015610055066645145\n",
      "Epoch: 2/5, Loss: 0.02420688048005104\n",
      "Epoch: 2/5, Loss: 0.015499429777264595\n",
      "Epoch: 2/5, Loss: 0.004042350221425295\n",
      "Epoch: 2/5, Loss: 0.057726506143808365\n",
      "Epoch: 2/5, Loss: 0.008591814897954464\n",
      "Epoch: 2/5, Loss: 0.014245224185287952\n",
      "Epoch: 2/5, Loss: 0.024038024246692657\n",
      "Epoch: 2/5, Loss: 0.010376567021012306\n",
      "Epoch: 2/5, Loss: 0.012979944236576557\n",
      "Epoch: 2/5, Loss: 0.015530522912740707\n",
      "Epoch: 2/5, Loss: 0.007051663473248482\n",
      "Epoch: 2/5, Loss: 0.03728120028972626\n",
      "Epoch: 2/5, Loss: 0.0428747795522213\n",
      "Epoch: 2/5, Loss: 0.008582459762692451\n",
      "Epoch: 2/5, Loss: 0.004173570312559605\n",
      "Epoch: 2/5, Loss: 0.020148875191807747\n",
      "Epoch: 2/5, Loss: 0.007169331889599562\n",
      "Epoch: 2/5, Loss: 0.02960447035729885\n",
      "Epoch: 2/5, Loss: 0.00839136727154255\n",
      "Epoch: 2/5, Loss: 0.011852363124489784\n",
      "Epoch: 2/5, Loss: 0.024296879768371582\n",
      "Epoch: 2/5, Loss: 0.0070377676747739315\n",
      "Epoch: 2/5, Loss: 0.01696966029703617\n",
      "Epoch: 2/5, Loss: 0.029839593917131424\n",
      "Epoch: 2/5, Loss: 0.020398350432515144\n",
      "Epoch: 2/5, Loss: 0.009459291584789753\n",
      "Epoch: 2/5, Loss: 0.0010508912382647395\n",
      "Epoch: 2/5, Loss: 0.020766956731677055\n",
      "Epoch: 2/5, Loss: 0.0051094163209199905\n",
      "Epoch: 2/5, Loss: 0.01928509771823883\n",
      "Epoch: 2/5, Loss: 0.0388866625726223\n",
      "Epoch: 2/5, Loss: 0.017714690417051315\n",
      "Epoch: 2/5, Loss: 0.02134087309241295\n",
      "Epoch: 2/5, Loss: 0.03772987425327301\n",
      "Epoch: 2/5, Loss: 0.010715778917074203\n",
      "Epoch: 2/5, Loss: 0.040198516100645065\n",
      "Epoch: 2/5, Loss: 0.0377044640481472\n",
      "Epoch: 2/5, Loss: 0.015983030200004578\n",
      "Epoch: 2/5, Loss: 0.02687365934252739\n",
      "Epoch: 2/5, Loss: 0.011243895627558231\n",
      "Epoch: 2/5, Loss: 0.006166793406009674\n",
      "Epoch: 2/5, Loss: 0.010050068609416485\n",
      "Epoch: 2/5, Loss: 0.011117830872535706\n",
      "Epoch: 2/5, Loss: 0.006493974477052689\n",
      "Epoch: 2/5, Loss: 0.017263999208807945\n",
      "Epoch: 2/5, Loss: 0.00266844080761075\n",
      "Epoch: 2/5, Loss: 0.014608828350901604\n",
      "Epoch: 2/5, Loss: 0.02403639815747738\n",
      "Epoch: 2/5, Loss: 0.0006845137686468661\n",
      "Epoch: 2/5, Loss: 0.029266301542520523\n",
      "Epoch: 2/5, Loss: 0.008051843382418156\n",
      "Epoch: 2/5, Loss: 0.003357860492542386\n",
      "Epoch: 2/5, Loss: 0.06069670617580414\n",
      "Epoch: 2/5, Loss: 0.019885331392288208\n",
      "Epoch: 2/5, Loss: 0.007706923875957727\n",
      "Epoch: 2/5, Loss: 0.02271696738898754\n",
      "Epoch: 2/5, Loss: 0.028063686564564705\n",
      "Epoch: 2/5, Loss: 0.02332283928990364\n",
      "Epoch: 2/5, Loss: 0.04868227615952492\n",
      "Epoch: 2/5, Loss: 0.01211323868483305\n",
      "Epoch: 2/5, Loss: 0.020996984094381332\n",
      "Epoch: 2/5, Loss: 0.012662354856729507\n",
      "Epoch: 2/5, Loss: 0.006590420845896006\n",
      "Epoch: 2/5, Loss: 0.009489980526268482\n",
      "Epoch: 2/5, Loss: 0.012697411701083183\n",
      "Epoch: 2/5, Loss: 0.008522115647792816\n",
      "Epoch: 2/5, Loss: 0.014059978537261486\n",
      "Epoch: 2/5, Loss: 0.013644982129335403\n",
      "Epoch: 2/5, Loss: 0.022585608065128326\n",
      "Epoch: 2/5, Loss: 0.011546083725988865\n",
      "Epoch: 2/5, Loss: 0.005515457130968571\n",
      "Epoch: 2/5, Loss: 0.01968873105943203\n",
      "Epoch: 2/5, Loss: 0.03106967732310295\n",
      "Epoch: 2/5, Loss: 0.029081376269459724\n",
      "Epoch: 2/5, Loss: 0.04462939128279686\n",
      "Epoch: 2/5, Loss: 0.02453233115375042\n",
      "Epoch: 2/5, Loss: 0.013592449948191643\n",
      "Epoch: 2/5, Loss: 0.0017679654993116856\n",
      "Epoch: 2/5, Loss: 0.020313741639256477\n",
      "Epoch: 2/5, Loss: 0.0030147561337798834\n",
      "Epoch: 2/5, Loss: 0.026181668043136597\n",
      "Epoch: 2/5, Loss: 0.027061475440859795\n",
      "Epoch: 2/5, Loss: 0.012377899140119553\n",
      "Epoch: 2/5, Loss: 0.010215292684733868\n",
      "Epoch: 2/5, Loss: 0.026858773082494736\n",
      "Epoch: 2/5, Loss: 0.019745923578739166\n",
      "Epoch: 2/5, Loss: 0.0197465680539608\n",
      "Epoch: 2/5, Loss: 0.04907672107219696\n",
      "Epoch: 2/5, Loss: 0.0005144620081409812\n",
      "Epoch: 2/5, Loss: 0.005693713668733835\n",
      "Epoch: 2/5, Loss: 0.006027556024491787\n",
      "Epoch: 2/5, Loss: 0.01530135702341795\n",
      "Epoch: 2/5, Loss: 0.008972426876425743\n",
      "Epoch: 2/5, Loss: 0.016330493614077568\n",
      "Epoch: 2/5, Loss: 0.006232096813619137\n",
      "Epoch: 2/5, Loss: 0.012907055206596851\n",
      "Epoch: 2/5, Loss: 0.023998217657208443\n",
      "Epoch: 2/5, Loss: 0.01646122708916664\n",
      "Epoch: 2/5, Loss: 0.006919858977198601\n",
      "Epoch: 2/5, Loss: 0.03116983361542225\n",
      "Epoch: 2/5, Loss: 0.008638051338493824\n",
      "Epoch: 2/5, Loss: 0.005525002721697092\n",
      "Epoch: 2/5, Loss: 0.019846493378281593\n",
      "Epoch: 2/5, Loss: 0.014925035648047924\n",
      "Epoch: 2/5, Loss: 0.0039017810486257076\n",
      "Epoch: 2/5, Loss: 0.011385621502995491\n",
      "Epoch: 2/5, Loss: 0.01914403960108757\n",
      "Epoch: 2/5, Loss: 0.04550106078386307\n",
      "Epoch: 2/5, Loss: 0.025759069249033928\n",
      "Epoch: 2/5, Loss: 0.0023305187933146954\n",
      "Epoch: 2/5, Loss: 0.0061605628579854965\n",
      "Epoch: 2/5, Loss: 0.003111751051619649\n",
      "Epoch: 2/5, Loss: 0.00869685411453247\n",
      "Epoch: 2/5, Loss: 0.005629237275570631\n",
      "Epoch: 2/5, Loss: 0.0465381033718586\n",
      "Epoch: 2/5, Loss: 0.044471923261880875\n",
      "Epoch: 2/5, Loss: 0.011881202459335327\n",
      "Epoch: 2/5, Loss: 0.026905182749032974\n",
      "Epoch: 2/5, Loss: 0.006125486921519041\n",
      "Epoch: 2/5, Loss: 0.01125910971313715\n",
      "Epoch: 2/5, Loss: 0.016285326331853867\n",
      "Epoch: 2/5, Loss: 0.020762275904417038\n",
      "Epoch: 2/5, Loss: 0.02345099486410618\n",
      "Epoch: 2/5, Loss: 0.006514336913824081\n",
      "Epoch: 2/5, Loss: 0.005503366701304913\n",
      "Epoch: 2/5, Loss: 0.0547020323574543\n",
      "Epoch: 2/5, Loss: 0.019652243703603745\n",
      "Epoch: 2/5, Loss: 0.02899947203695774\n",
      "Epoch: 2/5, Loss: 0.008869841694831848\n",
      "Epoch: 2/5, Loss: 0.034660693258047104\n",
      "Epoch: 2/5, Loss: 0.023935262113809586\n",
      "Epoch: 2/5, Loss: 0.009495056234300137\n",
      "Epoch: 2/5, Loss: 0.020794140174984932\n",
      "Epoch: 2/5, Loss: 0.039235904812812805\n",
      "Epoch: 2/5, Loss: 0.014774825423955917\n",
      "Epoch: 2/5, Loss: 0.016088876873254776\n",
      "Epoch: 2/5, Loss: 0.02696595899760723\n",
      "Epoch: 2/5, Loss: 0.02161020040512085\n",
      "Epoch: 2/5, Loss: 0.05335630849003792\n",
      "Epoch: 2/5, Loss: 0.012206627987325191\n",
      "Epoch: 2/5, Loss: 0.058120258152484894\n",
      "Epoch: 2/5, Loss: 0.03602859377861023\n",
      "Epoch: 2/5, Loss: 0.05510595068335533\n",
      "Epoch: 2/5, Loss: 0.019102148711681366\n",
      "Epoch: 2/5, Loss: 0.013702714815735817\n",
      "Epoch: 2/5, Loss: 0.009973809123039246\n",
      "Epoch: 2/5, Loss: 0.0113911097869277\n",
      "Epoch: 2/5, Loss: 0.03612525388598442\n",
      "Epoch: 2/5, Loss: 0.06370791047811508\n",
      "Epoch: 2/5, Loss: 0.03831086307764053\n",
      "Epoch: 2/5, Loss: 0.00546968774870038\n",
      "Epoch: 2/5, Loss: 0.07458482682704926\n",
      "Epoch: 2/5, Loss: 0.015519421547651291\n",
      "Epoch: 2/5, Loss: 0.01418326050043106\n",
      "Epoch: 2/5, Loss: 0.010112341493368149\n",
      "Epoch: 2/5, Loss: 0.006852870807051659\n",
      "Epoch: 2/5, Loss: 0.017935506999492645\n",
      "Epoch: 2/5, Loss: 0.010130931623280048\n",
      "Epoch: 2/5, Loss: 0.0024148509837687016\n",
      "Epoch: 2/5, Loss: 0.01942579261958599\n",
      "Epoch: 2/5, Loss: 0.019574560225009918\n",
      "Epoch: 2/5, Loss: 0.029034171253442764\n",
      "Epoch: 2/5, Loss: 0.003329318482428789\n",
      "Epoch: 2/5, Loss: 0.01538233831524849\n",
      "Epoch: 2/5, Loss: 0.004179275594651699\n",
      "Epoch: 2/5, Loss: 0.04130609706044197\n",
      "Epoch: 2/5, Loss: 0.02532166987657547\n",
      "Epoch: 2/5, Loss: 0.01658504642546177\n",
      "Epoch: 2/5, Loss: 0.011009871028363705\n",
      "Epoch: 2/5, Loss: 0.009553012438118458\n",
      "Epoch: 2/5, Loss: 0.015163827687501907\n",
      "Epoch: 2/5, Loss: 0.03806804120540619\n",
      "Epoch: 2/5, Loss: 0.02014314942061901\n",
      "Epoch: 2/5, Loss: 0.0440283939242363\n",
      "Epoch: 2/5, Loss: 0.0207115039229393\n",
      "Epoch: 2/5, Loss: 0.005894188303500414\n",
      "Epoch: 2/5, Loss: 0.016545698046684265\n",
      "Epoch: 2/5, Loss: 0.010159043595194817\n",
      "Epoch: 2/5, Loss: 0.019015653058886528\n",
      "Epoch: 2/5, Loss: 0.01199263148009777\n",
      "Epoch: 2/5, Loss: 0.008925861679017544\n",
      "Epoch: 2/5, Loss: 0.02688741311430931\n",
      "Epoch: 2/5, Loss: 0.009269378148019314\n",
      "Epoch: 2/5, Loss: 0.002249254612252116\n",
      "Epoch: 2/5, Loss: 0.0026574195362627506\n",
      "Epoch: 2/5, Loss: 0.010904515162110329\n",
      "Epoch: 2/5, Loss: 0.006808011792600155\n",
      "Epoch: 2/5, Loss: 0.04638122394680977\n",
      "Epoch: 2/5, Loss: 0.009821133688092232\n",
      "Epoch: 2/5, Loss: 0.009333622641861439\n",
      "Epoch: 2/5, Loss: 0.005325533915311098\n",
      "Epoch: 2/5, Loss: 0.0033858169335871935\n",
      "Epoch: 2/5, Loss: 0.00471024215221405\n",
      "Epoch: 2/5, Loss: 0.003454123856499791\n",
      "Epoch: 2/5, Loss: 0.01577366143465042\n",
      "Epoch: 2/5, Loss: 0.013499247841536999\n",
      "Epoch: 2/5, Loss: 0.01039363443851471\n",
      "Epoch: 2/5, Loss: 0.017815422266721725\n",
      "Epoch: 2/5, Loss: 0.006561397109180689\n",
      "Epoch: 2/5, Loss: 0.0060634003020823\n",
      "Epoch: 2/5, Loss: 0.016136381775140762\n",
      "Epoch: 2/5, Loss: 0.02856353670358658\n",
      "Epoch: 2/5, Loss: 0.0024535595439374447\n",
      "Epoch: 2/5, Loss: 0.02934412844479084\n",
      "Epoch: 2/5, Loss: 0.00947172474116087\n",
      "Epoch: 2/5, Loss: 0.006486931815743446\n",
      "Epoch: 2/5, Loss: 0.008339217863976955\n",
      "Epoch: 2/5, Loss: 0.005865866784006357\n",
      "Epoch: 2/5, Loss: 0.030985767021775246\n",
      "Epoch: 2/5, Loss: 0.010079528205096722\n",
      "Epoch: 2/5, Loss: 0.005529876332730055\n",
      "Epoch: 2/5, Loss: 0.015822134912014008\n",
      "Epoch: 2/5, Loss: 0.03242470324039459\n",
      "Epoch: 2/5, Loss: 0.026203136891126633\n",
      "Epoch: 2/5, Loss: 0.017295848578214645\n",
      "Epoch: 2/5, Loss: 0.02027859352529049\n",
      "Epoch: 2/5, Loss: 0.03339996188879013\n",
      "Epoch: 2/5, Loss: 0.03115871548652649\n",
      "Epoch: 2/5, Loss: 0.02357802353799343\n",
      "Epoch: 2/5, Loss: 0.02446029707789421\n",
      "Epoch: 2/5, Loss: 0.009675167500972748\n",
      "Epoch: 2/5, Loss: 0.0048988149501383305\n",
      "Epoch: 2/5, Loss: 0.013303868472576141\n",
      "Epoch: 2/5, Loss: 0.02676912397146225\n",
      "Epoch: 2/5, Loss: 0.0059892539866268635\n",
      "Epoch: 2/5, Loss: 0.012474052608013153\n",
      "Epoch: 2/5, Loss: 0.014834588393568993\n",
      "Epoch: 2/5, Loss: 0.0020705792121589184\n",
      "Epoch: 2/5, Loss: 0.004953552037477493\n",
      "Epoch: 2/5, Loss: 0.042444635182619095\n",
      "Epoch: 2/5, Loss: 0.014808776788413525\n",
      "Epoch: 2/5, Loss: 0.04298912733793259\n",
      "Epoch: 2/5, Loss: 0.003863208694383502\n",
      "Epoch: 2/5, Loss: 0.014176405966281891\n",
      "Epoch: 2/5, Loss: 0.03220851719379425\n",
      "Epoch: 2/5, Loss: 0.0178902056068182\n",
      "Epoch: 2/5, Loss: 0.043259285390377045\n",
      "Epoch: 2/5, Loss: 0.022158855572342873\n",
      "Epoch: 2/5, Loss: 0.02435982972383499\n",
      "Epoch: 2/5, Loss: 0.018023181706666946\n",
      "Epoch: 2/5, Loss: 0.004145391285419464\n",
      "Epoch: 2/5, Loss: 0.009802662767469883\n",
      "Epoch: 2/5, Loss: 0.03987295925617218\n",
      "Epoch: 2/5, Loss: 0.011123554781079292\n",
      "Epoch: 2/5, Loss: 0.015061210840940475\n",
      "Epoch: 2/5, Loss: 0.023504100739955902\n",
      "Epoch: 2/5, Loss: 0.019499799236655235\n",
      "Epoch: 2/5, Loss: 0.052059657871723175\n",
      "Epoch: 2/5, Loss: 0.0395306758582592\n",
      "Epoch: 2/5, Loss: 0.07062491029500961\n",
      "Epoch: 2/5, Loss: 0.008856501430273056\n",
      "Epoch: 2/5, Loss: 0.011844202876091003\n",
      "Epoch: 2/5, Loss: 0.014680824242532253\n",
      "Epoch: 2/5, Loss: 0.014729214832186699\n",
      "Epoch: 2/5, Loss: 0.011843622662127018\n",
      "Epoch: 2/5, Loss: 0.026751665398478508\n",
      "Epoch: 2/5, Loss: 0.03468824923038483\n",
      "Epoch: 2/5, Loss: 0.03745339810848236\n",
      "Epoch: 2/5, Loss: 0.03376393020153046\n",
      "Epoch: 2/5, Loss: 0.03868936002254486\n",
      "Epoch: 2/5, Loss: 0.015307679772377014\n",
      "Epoch: 2/5, Loss: 0.027309909462928772\n",
      "Epoch: 2/5, Loss: 0.016076762229204178\n",
      "Epoch: 2/5, Loss: 0.003756668884307146\n",
      "Epoch: 2/5, Loss: 0.023762883618474007\n",
      "Epoch: 2/5, Loss: 0.015313644893467426\n",
      "Epoch: 2/5, Loss: 0.005525502841919661\n",
      "Epoch: 2/5, Loss: 0.0016143287066370249\n",
      "Epoch: 2/5, Loss: 0.003442921210080385\n",
      "Epoch: 2/5, Loss: 0.00467275595292449\n",
      "Epoch: 2/5, Loss: 0.01901189796626568\n",
      "Epoch: 2/5, Loss: 0.07051046192646027\n",
      "Epoch: 2/5, Loss: 0.007331050466746092\n",
      "Epoch: 2/5, Loss: 0.044784121215343475\n",
      "Epoch: 2/5, Loss: 0.011995337903499603\n",
      "Epoch: 2/5, Loss: 0.01284341886639595\n",
      "Epoch: 2/5, Loss: 0.012236397713422775\n",
      "Epoch: 2/5, Loss: 0.002115382580086589\n",
      "Epoch: 2/5, Loss: 0.04101990535855293\n",
      "Epoch: 2/5, Loss: 0.01804240420460701\n",
      "Epoch: 2/5, Loss: 0.010724348947405815\n",
      "Epoch: 2/5, Loss: 0.038711030036211014\n",
      "Epoch: 2/5, Loss: 0.012624379247426987\n",
      "Epoch: 2/5, Loss: 0.016764119267463684\n",
      "Epoch: 2/5, Loss: 0.00832151249051094\n",
      "Epoch: 2/5, Loss: 0.03719358518719673\n",
      "Epoch: 2/5, Loss: 0.010625367052853107\n",
      "Epoch: 2/5, Loss: 0.01005092728883028\n",
      "Epoch: 2/5, Loss: 0.009671341627836227\n",
      "Epoch: 2/5, Loss: 0.00807688757777214\n",
      "Epoch: 2/5, Loss: 0.11293178796768188\n",
      "Epoch: 2/5, Loss: 0.01935294084250927\n",
      "Epoch: 2/5, Loss: 0.007820691913366318\n",
      "Epoch: 2/5, Loss: 0.013637429103255272\n",
      "Epoch: 2/5, Loss: 0.019093569368124008\n",
      "Epoch: 2/5, Loss: 0.025358952581882477\n",
      "Epoch: 2/5, Loss: 0.023437002673745155\n",
      "Epoch: 2/5, Loss: 0.021324671804904938\n",
      "Epoch: 2/5, Loss: 0.02686174213886261\n",
      "Epoch: 2/5, Loss: 0.013336790725588799\n",
      "Epoch: 2/5, Loss: 0.028642749413847923\n",
      "Epoch: 2/5, Loss: 0.027555469423532486\n",
      "Epoch: 2/5, Loss: 0.026101797819137573\n",
      "Epoch: 2/5, Loss: 0.006370449438691139\n",
      "Epoch: 2/5, Loss: 0.01054951548576355\n",
      "Epoch: 2/5, Loss: 0.010921120643615723\n",
      "Epoch: 2/5, Loss: 0.034048259258270264\n",
      "Epoch: 2/5, Loss: 0.0034674641210585833\n",
      "Epoch: 2/5, Loss: 0.016381220892071724\n",
      "Epoch: 2/5, Loss: 0.0071067167446017265\n",
      "Epoch: 2/5, Loss: 0.018497036769986153\n",
      "Epoch: 2/5, Loss: 0.020596684888005257\n",
      "Epoch: 2/5, Loss: 0.006322935223579407\n",
      "Epoch: 2/5, Loss: 0.017469221726059914\n",
      "Epoch: 2/5, Loss: 0.04610905051231384\n",
      "Epoch: 2/5, Loss: 0.026689795777201653\n",
      "Epoch: 2/5, Loss: 0.025331055745482445\n",
      "Epoch: 2/5, Loss: 0.05279538780450821\n",
      "Epoch: 2/5, Loss: 0.04646589234471321\n",
      "Epoch: 2/5, Loss: 0.02024100534617901\n",
      "Epoch: 2/5, Loss: 0.013097604736685753\n",
      "Epoch: 2/5, Loss: 0.018647190183401108\n",
      "Epoch: 2/5, Loss: 0.018125411123037338\n",
      "Epoch: 2/5, Loss: 0.0166043508797884\n",
      "Epoch: 2/5, Loss: 0.015920573845505714\n",
      "Epoch: 2/5, Loss: 0.015965256839990616\n",
      "Epoch: 2/5, Loss: 0.016325922682881355\n",
      "Epoch: 2/5, Loss: 0.015433872118592262\n",
      "Epoch: 2/5, Loss: 0.02485404536128044\n",
      "Epoch: 2/5, Loss: 0.010661914013326168\n",
      "Epoch: 2/5, Loss: 0.02669280767440796\n",
      "Epoch: 2/5, Loss: 0.002243835013359785\n",
      "Epoch: 2/5, Loss: 0.006621586158871651\n",
      "Epoch: 2/5, Loss: 0.004736724775284529\n",
      "Epoch: 2/5, Loss: 0.0034813678357750177\n",
      "Epoch: 2/5, Loss: 0.007633037865161896\n",
      "Epoch: 2/5, Loss: 0.0077004143968224525\n",
      "Epoch: 2/5, Loss: 0.03781267628073692\n",
      "Epoch: 2/5, Loss: 0.025267191231250763\n",
      "Epoch: 2/5, Loss: 0.0020942608825862408\n",
      "Epoch: 2/5, Loss: 0.010155430994927883\n",
      "Epoch: 2/5, Loss: 0.0010812594555318356\n",
      "Epoch: 2/5, Loss: 0.010808171704411507\n",
      "Epoch: 2/5, Loss: 0.008508505299687386\n",
      "Epoch: 2/5, Loss: 0.022344833239912987\n",
      "Epoch: 2/5, Loss: 0.05394967645406723\n",
      "Epoch: 2/5, Loss: 0.01142584066838026\n",
      "Epoch: 2/5, Loss: 0.013950557447969913\n",
      "Epoch: 2/5, Loss: 0.030213788151741028\n",
      "Epoch: 2/5, Loss: 0.0032450854778289795\n",
      "Epoch: 2/5, Loss: 0.01622438244521618\n",
      "Epoch: 2/5, Loss: 0.0059693013317883015\n",
      "Epoch: 2/5, Loss: 0.02453220635652542\n",
      "Epoch: 2/5, Loss: 0.01140596903860569\n",
      "Epoch: 2/5, Loss: 0.02471766620874405\n",
      "Epoch: 2/5, Loss: 0.029367830604314804\n",
      "Epoch: 2/5, Loss: 0.01939372904598713\n",
      "Epoch: 2/5, Loss: 0.07229971140623093\n",
      "Epoch: 2/5, Loss: 0.025269417092204094\n",
      "Epoch: 2/5, Loss: 0.009754329919815063\n",
      "Epoch: 2/5, Loss: 0.00876249372959137\n",
      "Epoch: 2/5, Loss: 0.07502776384353638\n",
      "Epoch: 2/5, Loss: 0.005664664786309004\n",
      "Epoch: 2/5, Loss: 0.011416026391088963\n",
      "Epoch: 2/5, Loss: 0.005688798613846302\n",
      "Epoch: 2/5, Loss: 0.026899905875325203\n",
      "Epoch: 2/5, Loss: 0.013988371007144451\n",
      "Epoch: 2/5, Loss: 0.021085433661937714\n",
      "Epoch: 2/5, Loss: 0.03976160287857056\n",
      "Epoch: 2/5, Loss: 0.015800295397639275\n",
      "Epoch: 2/5, Loss: 0.02113090641796589\n",
      "Epoch: 2/5, Loss: 0.017685191705822945\n",
      "Epoch: 2/5, Loss: 0.033232204616069794\n",
      "Epoch: 2/5, Loss: 0.009474925696849823\n",
      "Epoch: 2/5, Loss: 0.017171895131468773\n",
      "Epoch: 2/5, Loss: 0.016115162521600723\n",
      "Epoch: 2/5, Loss: 0.014139562845230103\n",
      "Epoch: 2/5, Loss: 0.010598390363156796\n",
      "Epoch: 2/5, Loss: 0.010814991779625416\n",
      "Epoch: 2/5, Loss: 0.010521791875362396\n",
      "Epoch: 2/5, Loss: 0.030814651399850845\n",
      "Epoch: 2/5, Loss: 0.008923811838030815\n",
      "Epoch: 2/5, Loss: 0.030817797407507896\n",
      "Epoch: 2/5, Loss: 0.02545829862356186\n",
      "Epoch: 2/5, Loss: 0.02967306599020958\n",
      "Epoch: 2/5, Loss: 0.0449795201420784\n",
      "Epoch: 2/5, Loss: 0.0030671246349811554\n",
      "Epoch: 2/5, Loss: 0.14320428669452667\n",
      "Epoch: 2/5, Loss: 0.0032369091641157866\n",
      "Epoch: 2/5, Loss: 0.0019014929421246052\n",
      "Epoch: 2/5, Loss: 0.025909574702382088\n",
      "Epoch: 2/5, Loss: 0.004589688032865524\n",
      "Epoch: 2/5, Loss: 0.021522030234336853\n",
      "Epoch: 2/5, Loss: 0.013810476288199425\n",
      "Epoch: 2/5, Loss: 0.007224660832434893\n",
      "Epoch: 2/5, Loss: 0.0017117735696956515\n",
      "Epoch: 2/5, Loss: 0.004897642880678177\n",
      "Epoch: 2/5, Loss: 0.010131778195500374\n",
      "Epoch: 2/5, Loss: 0.01399574801325798\n",
      "Epoch: 2/5, Loss: 0.0177869014441967\n",
      "Epoch: 2/5, Loss: 0.005909785628318787\n",
      "Epoch: 2/5, Loss: 0.018379803746938705\n",
      "Epoch: 2/5, Loss: 0.0002893387572839856\n",
      "Epoch: 2/5, Loss: 0.010731990449130535\n",
      "Epoch: 2/5, Loss: 0.026927907019853592\n",
      "Epoch: 2/5, Loss: 0.05714191123843193\n",
      "Epoch: 2/5, Loss: 0.09160096198320389\n",
      "Epoch: 2/5, Loss: 0.012022178620100021\n",
      "Epoch: 2/5, Loss: 0.015666473656892776\n",
      "Epoch: 2/5, Loss: 0.025104762986302376\n",
      "Epoch: 2/5, Loss: 0.035217784345149994\n",
      "Epoch: 2/5, Loss: 0.029162921011447906\n",
      "Epoch: 2/5, Loss: 0.0010972077725455165\n",
      "Epoch: 2/5, Loss: 0.018217384815216064\n",
      "Epoch: 2/5, Loss: 0.04554523900151253\n",
      "Epoch: 2/5, Loss: 0.015328801237046719\n",
      "Epoch: 2/5, Loss: 0.0076262466609478\n",
      "Epoch: 2/5, Loss: 0.008995790034532547\n",
      "Epoch: 2/5, Loss: 0.010420586913824081\n",
      "Epoch: 2/5, Loss: 0.023482825607061386\n",
      "Epoch: 2/5, Loss: 0.020139817148447037\n",
      "Epoch: 2/5, Loss: 0.014276279136538506\n",
      "Epoch: 2/5, Loss: 0.007562458515167236\n",
      "Epoch: 2/5, Loss: 0.01825086399912834\n",
      "Epoch: 2/5, Loss: 0.0176938995718956\n",
      "Epoch: 2/5, Loss: 0.011996935121715069\n",
      "Epoch: 2/5, Loss: 0.025054946541786194\n",
      "Epoch: 2/5, Loss: 0.016340551897883415\n",
      "Epoch: 2/5, Loss: 0.04959527775645256\n",
      "Epoch: 2/5, Loss: 0.014959161169826984\n",
      "Epoch: 2/5, Loss: 0.020063217729330063\n",
      "Epoch: 2/5, Loss: 0.02165592834353447\n",
      "Epoch: 2/5, Loss: 0.005130141507834196\n",
      "Epoch: 2/5, Loss: 0.0143080810084939\n",
      "Epoch: 2/5, Loss: 0.019227540120482445\n",
      "Epoch: 2/5, Loss: 0.015464141964912415\n",
      "Epoch: 2/5, Loss: 0.04681362956762314\n",
      "Epoch: 2/5, Loss: 0.037293367087841034\n",
      "Epoch: 2/5, Loss: 0.01755911484360695\n",
      "Epoch: 2/5, Loss: 0.027644766494631767\n",
      "Epoch: 2/5, Loss: 0.0009025516337715089\n",
      "Epoch: 2/5, Loss: 0.024846697226166725\n",
      "Epoch: 2/5, Loss: 0.022229397669434547\n",
      "Epoch: 2/5, Loss: 0.013093708083033562\n",
      "Epoch: 2/5, Loss: 0.082011379301548\n",
      "Epoch: 2/5, Loss: 0.012077070772647858\n",
      "Epoch: 2/5, Loss: 0.060114528983831406\n",
      "Epoch: 2/5, Loss: 0.020637674257159233\n",
      "Epoch: 2/5, Loss: 0.051603347063064575\n",
      "Epoch: 2/5, Loss: 0.04384422302246094\n",
      "Epoch: 2/5, Loss: 0.026365535333752632\n",
      "Epoch: 2/5, Loss: 0.031004108488559723\n",
      "Epoch: 2/5, Loss: 0.01610107533633709\n",
      "Epoch: 2/5, Loss: 0.009008836932480335\n",
      "Epoch: 2/5, Loss: 0.0012433056253939867\n",
      "Epoch: 2/5, Loss: 0.052975524216890335\n",
      "Epoch: 2/5, Loss: 0.018349261954426765\n",
      "Epoch: 2/5, Loss: 0.03762145712971687\n",
      "Epoch: 2/5, Loss: 0.007553532253950834\n",
      "Epoch: 2/5, Loss: 0.0039262836799025536\n",
      "Epoch: 2/5, Loss: 0.0490034744143486\n",
      "Epoch: 2/5, Loss: 0.0059571159072220325\n",
      "Epoch: 2/5, Loss: 0.003999071661382914\n",
      "Epoch: 2/5, Loss: 0.04458741098642349\n",
      "Epoch: 2/5, Loss: 0.041108131408691406\n",
      "Epoch: 2/5, Loss: 0.002877091523259878\n",
      "Epoch: 2/5, Loss: 0.01787937618792057\n",
      "Epoch: 2/5, Loss: 0.005815207026898861\n",
      "Epoch: 2/5, Loss: 0.08907720446586609\n",
      "Epoch: 2/5, Loss: 0.006434182170778513\n",
      "Epoch: 2/5, Loss: 0.022512733936309814\n",
      "Epoch: 2/5, Loss: 0.00461443280801177\n",
      "Epoch: 2/5, Loss: 0.014217608608305454\n",
      "Epoch: 2/5, Loss: 0.025034574791789055\n",
      "Epoch: 2/5, Loss: 0.005673838779330254\n",
      "Epoch: 2/5, Loss: 0.02468116395175457\n",
      "Epoch: 2/5, Loss: 0.01424957811832428\n",
      "Epoch: 2/5, Loss: 0.012255686335265636\n",
      "Epoch: 2/5, Loss: 0.011605756357312202\n",
      "Epoch: 2/5, Loss: 0.016750620678067207\n",
      "Epoch: 2/5, Loss: 0.01088037807494402\n",
      "Epoch: 2/5, Loss: 0.01213973481208086\n",
      "Epoch: 2/5, Loss: 0.006915902718901634\n",
      "Epoch: 2/5, Loss: 0.03500887751579285\n",
      "Epoch: 2/5, Loss: 0.11352262645959854\n",
      "Epoch: 2/5, Loss: 0.00915525108575821\n",
      "Epoch: 2/5, Loss: 0.020921552553772926\n",
      "Epoch: 2/5, Loss: 0.02578139305114746\n",
      "Epoch: 2/5, Loss: 0.001636129803955555\n",
      "Epoch: 2/5, Loss: 0.06516792625188828\n",
      "Epoch: 2/5, Loss: 0.013119733892381191\n",
      "Epoch: 2/5, Loss: 0.01857437938451767\n",
      "Epoch: 2/5, Loss: 0.009219050407409668\n",
      "Epoch: 2/5, Loss: 0.00796337891370058\n",
      "Epoch: 2/5, Loss: 0.003358917310833931\n",
      "Epoch: 2/5, Loss: 0.006433697417378426\n",
      "Epoch: 2/5, Loss: 0.14221131801605225\n",
      "Epoch: 2/5, Loss: 0.02497711405158043\n",
      "Epoch: 2/5, Loss: 0.007787439506500959\n",
      "Epoch: 2/5, Loss: 0.018296480178833008\n",
      "Epoch: 2/5, Loss: 0.027000563219189644\n",
      "Epoch: 2/5, Loss: 0.017524437978863716\n",
      "Epoch: 2/5, Loss: 0.010883859358727932\n",
      "Epoch: 2/5, Loss: 0.01281890831887722\n",
      "Epoch: 2/5, Loss: 0.013896318152546883\n",
      "Epoch: 2/5, Loss: 0.03801202401518822\n",
      "Epoch: 2/5, Loss: 0.03408848121762276\n",
      "Epoch: 2/5, Loss: 0.018516764044761658\n",
      "Epoch: 2/5, Loss: 0.009334564208984375\n",
      "Epoch: 2/5, Loss: 0.0328216478228569\n",
      "Epoch: 2/5, Loss: 0.011565417051315308\n",
      "Epoch: 2/5, Loss: 0.03480544313788414\n",
      "Epoch: 2/5, Loss: 0.022202951833605766\n",
      "Epoch: 2/5, Loss: 0.01195377018302679\n",
      "Epoch: 2/5, Loss: 0.006878174375742674\n",
      "Epoch: 2/5, Loss: 0.01425422728061676\n",
      "Epoch: 2/5, Loss: 0.038042303174734116\n",
      "Epoch: 2/5, Loss: 0.017377449199557304\n",
      "Epoch: 2/5, Loss: 0.022255592048168182\n",
      "Epoch: 2/5, Loss: 0.025461817160248756\n",
      "Epoch: 2/5, Loss: 0.014295902103185654\n",
      "Epoch: 2/5, Loss: 0.013681164011359215\n",
      "Epoch: 2/5, Loss: 0.007152891252189875\n",
      "Epoch: 2/5, Loss: 0.013341394253075123\n",
      "Epoch: 2/5, Loss: 0.03021135739982128\n",
      "Epoch: 2/5, Loss: 0.01569705829024315\n",
      "Epoch: 2/5, Loss: 0.009146851487457752\n",
      "Epoch: 2/5, Loss: 0.02482542395591736\n",
      "Epoch: 2/5, Loss: 0.017380783334374428\n",
      "Epoch: 2/5, Loss: 0.0325656495988369\n",
      "Epoch: 2/5, Loss: 0.029862340539693832\n",
      "Epoch: 2/5, Loss: 0.13872641324996948\n",
      "Epoch: 2/5, Loss: 0.008210930041968822\n",
      "Epoch: 2/5, Loss: 0.012378835119307041\n",
      "Epoch: 2/5, Loss: 0.036497920751571655\n",
      "Epoch: 2/5, Loss: 0.007806191220879555\n",
      "Epoch: 2/5, Loss: 0.012521171942353249\n",
      "Epoch: 2/5, Loss: 0.001056441804394126\n",
      "Epoch: 2/5, Loss: 0.01591625064611435\n",
      "Epoch: 2/5, Loss: 0.02396347001194954\n",
      "Epoch: 2/5, Loss: 0.010217346251010895\n",
      "Epoch: 2/5, Loss: 0.0067159151658415794\n",
      "Epoch: 2/5, Loss: 0.00280521297827363\n",
      "Epoch: 2/5, Loss: 0.015980685129761696\n",
      "Epoch: 2/5, Loss: 0.024587810039520264\n",
      "Epoch: 2/5, Loss: 0.03337350860238075\n",
      "Epoch: 2/5, Loss: 0.00932409055531025\n",
      "Epoch: 2/5, Loss: 0.06187593936920166\n",
      "Epoch: 2/5, Loss: 0.01390697993338108\n",
      "Epoch: 2/5, Loss: 0.04137450456619263\n",
      "Epoch: 2/5, Loss: 0.012401044368743896\n",
      "Epoch: 2/5, Loss: 0.01807618886232376\n",
      "Epoch: 2/5, Loss: 0.020763076841831207\n",
      "Epoch: 2/5, Loss: 0.011357060633599758\n",
      "Epoch: 2/5, Loss: 0.0016208274755626917\n",
      "Epoch: 2/5, Loss: 0.005428969860076904\n",
      "Epoch: 2/5, Loss: 0.028389947488904\n",
      "Epoch: 2/5, Loss: 0.01071195863187313\n",
      "Epoch: 2/5, Loss: 0.022920798510313034\n",
      "Epoch: 2/5, Loss: 0.004139509052038193\n",
      "Epoch: 2/5, Loss: 0.020371008664369583\n",
      "Epoch: 2/5, Loss: 0.007794619537889957\n",
      "Epoch: 2/5, Loss: 0.013941766694188118\n",
      "Epoch: 2/5, Loss: 0.011633504182100296\n",
      "Epoch: 2/5, Loss: 0.01174097042530775\n",
      "Epoch: 2/5, Loss: 0.05094059184193611\n",
      "Epoch: 2/5, Loss: 0.027683017775416374\n",
      "Epoch: 2/5, Loss: 0.0030746995471417904\n",
      "Epoch: 2/5, Loss: 0.01394831296056509\n",
      "Epoch: 2/5, Loss: 0.011536314152181149\n",
      "Epoch: 2/5, Loss: 0.007050753105431795\n",
      "Epoch: 2/5, Loss: 0.003886973485350609\n",
      "Epoch: 2/5, Loss: 0.04037569835782051\n",
      "Epoch: 2/5, Loss: 0.03226631507277489\n",
      "Epoch: 2/5, Loss: 0.0055134957656264305\n",
      "Epoch: 2/5, Loss: 0.013864659704267979\n",
      "Epoch: 2/5, Loss: 0.020492536947131157\n",
      "Epoch: 2/5, Loss: 0.0064306920394301414\n",
      "Epoch: 2/5, Loss: 0.01379372924566269\n",
      "Epoch: 2/5, Loss: 0.005210726521909237\n",
      "Epoch: 2/5, Loss: 0.035184577107429504\n",
      "Epoch: 2/5, Loss: 0.02616017311811447\n",
      "Epoch: 2/5, Loss: 0.03617212548851967\n",
      "Epoch: 2/5, Loss: 0.03436605632305145\n",
      "Epoch: 2/5, Loss: 0.005522073712199926\n",
      "Epoch: 2/5, Loss: 0.014558080583810806\n",
      "Epoch: 2/5, Loss: 0.04035528749227524\n",
      "Epoch: 2/5, Loss: 0.01160685159265995\n",
      "Epoch: 2/5, Loss: 0.09778755903244019\n",
      "Epoch: 2/5, Loss: 0.020276952534914017\n",
      "Epoch: 2/5, Loss: 0.027519293129444122\n",
      "Epoch: 2/5, Loss: 0.036476220935583115\n",
      "Epoch: 2/5, Loss: 0.01477381307631731\n",
      "Epoch: 2/5, Loss: 0.009480832144618034\n",
      "Epoch: 2/5, Loss: 0.012208315543830395\n",
      "Epoch: 2/5, Loss: 0.014402175322175026\n",
      "Epoch: 2/5, Loss: 0.01051041204482317\n",
      "Epoch: 2/5, Loss: 0.014226804487407207\n",
      "Epoch: 2/5, Loss: 0.036508023738861084\n",
      "Epoch: 2/5, Loss: 0.01867814175784588\n",
      "Epoch: 2/5, Loss: 0.08703306317329407\n",
      "Epoch: 2/5, Loss: 0.042370595037937164\n",
      "Epoch: 2/5, Loss: 0.009627453982830048\n",
      "Epoch: 2/5, Loss: 0.02003982663154602\n",
      "Epoch: 2/5, Loss: 0.046944960951805115\n",
      "Epoch: 2/5, Loss: 0.038788605481386185\n",
      "Epoch: 2/5, Loss: 0.05273823440074921\n",
      "Epoch: 2/5, Loss: 0.020578132942318916\n",
      "Epoch: 2/5, Loss: 0.054460205137729645\n",
      "Epoch: 2/5, Loss: 0.021556060761213303\n",
      "Epoch: 2/5, Loss: 0.030414599925279617\n",
      "Epoch: 2/5, Loss: 0.026599835604429245\n",
      "Epoch: 2/5, Loss: 0.03390932083129883\n",
      "Epoch: 2/5, Loss: 0.013885991647839546\n",
      "Epoch: 2/5, Loss: 0.06556790322065353\n",
      "Epoch: 2/5, Loss: 0.005021238699555397\n",
      "Epoch: 2/5, Loss: 0.011032297275960445\n",
      "Epoch: 2/5, Loss: 0.0053938813507556915\n",
      "Epoch: 2/5, Loss: 0.007648606318980455\n",
      "Epoch: 2/5, Loss: 0.021899845451116562\n",
      "Epoch: 2/5, Loss: 0.04100823402404785\n",
      "Epoch: 2/5, Loss: 0.015536302700638771\n",
      "Epoch: 2/5, Loss: 0.009353573434054852\n",
      "Epoch: 2/5, Loss: 0.0020118190441280603\n",
      "Epoch: 2/5, Loss: 0.015290914103388786\n",
      "Epoch: 2/5, Loss: 0.006627887487411499\n",
      "Epoch: 2/5, Loss: 0.013879396952688694\n",
      "Epoch: 2/5, Loss: 0.007302003912627697\n",
      "Epoch: 2/5, Loss: 0.003079633926972747\n",
      "Epoch: 2/5, Loss: 0.010471101850271225\n",
      "Epoch: 2/5, Loss: 0.040373750030994415\n",
      "Epoch: 2/5, Loss: 0.020998165011405945\n",
      "Epoch: 2/5, Loss: 0.023234855383634567\n",
      "Epoch: 2/5, Loss: 0.015392813831567764\n",
      "Epoch: 2/5, Loss: 0.009234314784407616\n",
      "Epoch: 2/5, Loss: 0.023014388978481293\n",
      "Epoch: 2/5, Loss: 0.02827375754714012\n",
      "Epoch: 2/5, Loss: 0.01672721654176712\n",
      "Epoch: 2/5, Loss: 0.010314257815480232\n",
      "Epoch: 2/5, Loss: 0.01668868027627468\n",
      "Epoch: 2/5, Loss: 0.016895785927772522\n",
      "Epoch: 2/5, Loss: 0.0036411720793694258\n",
      "Epoch: 2/5, Loss: 0.031656309962272644\n",
      "Epoch: 2/5, Loss: 0.04461823031306267\n",
      "Epoch: 2/5, Loss: 0.00796816311776638\n",
      "Epoch: 2/5, Loss: 0.030070871114730835\n",
      "Epoch: 2/5, Loss: 0.02602752484381199\n",
      "Epoch: 2/5, Loss: 0.008913770318031311\n",
      "Epoch: 2/5, Loss: 0.004219397436827421\n",
      "Epoch: 2/5, Loss: 0.022927969694137573\n",
      "Epoch: 2/5, Loss: 0.014788981527090073\n",
      "Epoch: 2/5, Loss: 0.02099229022860527\n",
      "Epoch: 2/5, Loss: 0.009939797222614288\n",
      "Epoch: 2/5, Loss: 0.004526347387582064\n",
      "Epoch: 2/5, Loss: 0.006002811249345541\n",
      "Epoch: 2/5, Loss: 0.005211159586906433\n",
      "Epoch: 2/5, Loss: 0.015986446291208267\n",
      "Epoch: 2/5, Loss: 0.029738282784819603\n",
      "Epoch: 2/5, Loss: 0.009522593580186367\n",
      "Epoch: 2/5, Loss: 0.06020091474056244\n",
      "Epoch: 2/5, Loss: 0.006716074887663126\n",
      "Epoch: 2/5, Loss: 0.03608245402574539\n",
      "Epoch: 2/5, Loss: 0.02795833721756935\n",
      "Epoch: 2/5, Loss: 0.010489287786185741\n",
      "Epoch: 2/5, Loss: 0.025230860337615013\n",
      "Epoch: 2/5, Loss: 0.022375013679265976\n",
      "Epoch: 2/5, Loss: 0.006319099105894566\n",
      "Epoch: 2/5, Loss: 0.05186709389090538\n",
      "Epoch: 2/5, Loss: 0.013927221298217773\n",
      "Epoch: 2/5, Loss: 0.0116734579205513\n",
      "Epoch: 2/5, Loss: 0.047637101262807846\n",
      "Epoch: 2/5, Loss: 0.039079755544662476\n",
      "Epoch: 2/5, Loss: 0.013637534342706203\n",
      "Epoch: 2/5, Loss: 0.09395767003297806\n",
      "Epoch: 2/5, Loss: 0.011459910310804844\n",
      "Epoch: 2/5, Loss: 0.029155869036912918\n",
      "Epoch: 2/5, Loss: 0.021309208124876022\n",
      "Epoch: 2/5, Loss: 0.020230481401085854\n",
      "Epoch: 2/5, Loss: 0.008460727520287037\n",
      "Epoch: 2/5, Loss: 0.00632986705750227\n",
      "Epoch: 2/5, Loss: 0.03601272776722908\n",
      "Epoch: 2/5, Loss: 0.009676666930317879\n",
      "Epoch: 2/5, Loss: 0.028551992028951645\n",
      "Epoch: 2/5, Loss: 0.028499947860836983\n",
      "Epoch: 2/5, Loss: 0.014636242762207985\n",
      "Epoch: 2/5, Loss: 0.013088432140648365\n",
      "Epoch: 2/5, Loss: 0.018078865483403206\n",
      "Epoch: 2/5, Loss: 0.008166113868355751\n",
      "Epoch: 2/5, Loss: 0.02984689176082611\n",
      "Epoch: 2/5, Loss: 0.01123255118727684\n",
      "Epoch: 2/5, Loss: 0.011514058336615562\n",
      "Epoch: 2/5, Loss: 0.0345161035656929\n",
      "Epoch: 2/5, Loss: 0.026961391791701317\n",
      "Epoch: 2/5, Loss: 0.006512004416435957\n",
      "Epoch: 2/5, Loss: 0.011979348957538605\n",
      "Epoch: 2/5, Loss: 0.015951301902532578\n",
      "Epoch: 2/5, Loss: 0.007652777247130871\n",
      "Epoch: 2/5, Loss: 0.04857002571225166\n",
      "Epoch: 2/5, Loss: 0.007498741615563631\n",
      "Epoch: 2/5, Loss: 0.014417563565075397\n",
      "Epoch: 2/5, Loss: 0.01959080994129181\n",
      "Epoch: 2/5, Loss: 0.015193917788565159\n",
      "Epoch: 2/5, Loss: 0.0017482131952419877\n",
      "Epoch: 2/5, Loss: 0.013094039633870125\n",
      "Epoch: 2/5, Loss: 0.014387408271431923\n",
      "Epoch: 2/5, Loss: 0.032003793865442276\n",
      "Epoch: 2/5, Loss: 0.002412110334262252\n",
      "Epoch: 2/5, Loss: 0.008900001645088196\n",
      "Epoch: 2/5, Loss: 0.003486326662823558\n",
      "Epoch: 2/5, Loss: 0.013202108442783356\n",
      "Epoch: 2/5, Loss: 0.08537398278713226\n",
      "Epoch: 2/5, Loss: 0.00780273275449872\n",
      "Epoch: 2/5, Loss: 0.008917072787880898\n",
      "Epoch: 2/5, Loss: 0.009440666995942593\n",
      "Epoch: 2/5, Loss: 0.034175805747509\n",
      "Epoch: 2/5, Loss: 0.11524435132741928\n",
      "Epoch: 2/5, Loss: 0.02750515379011631\n",
      "Epoch: 2/5, Loss: 0.0183698832988739\n",
      "Epoch: 2/5, Loss: 0.029372308403253555\n",
      "Epoch: 2/5, Loss: 0.008838541805744171\n",
      "Epoch: 2/5, Loss: 0.04337142035365105\n",
      "Epoch: 2/5, Loss: 0.012150125578045845\n",
      "Epoch: 2/5, Loss: 0.01837937720119953\n",
      "Epoch: 2/5, Loss: 0.010619775392115116\n",
      "Epoch: 2/5, Loss: 0.007090114057064056\n",
      "Epoch: 2/5, Loss: 0.013346413150429726\n",
      "Epoch: 2/5, Loss: 0.015276065096259117\n",
      "Epoch: 2/5, Loss: 0.041130464524030685\n",
      "Epoch: 2/5, Loss: 0.04500072821974754\n",
      "Epoch: 2/5, Loss: 0.014347228221595287\n",
      "Epoch: 2/5, Loss: 0.027497392147779465\n",
      "Epoch: 2/5, Loss: 0.03625193238258362\n",
      "Epoch: 2/5, Loss: 0.018526161089539528\n",
      "Epoch: 2/5, Loss: 0.018763361498713493\n",
      "Epoch: 2/5, Loss: 0.010952633805572987\n",
      "Epoch: 2/5, Loss: 0.021101512014865875\n",
      "Epoch: 2/5, Loss: 0.013636290095746517\n",
      "Epoch: 2/5, Loss: 0.02633402682840824\n",
      "Epoch: 2/5, Loss: 0.007760820910334587\n",
      "Epoch: 2/5, Loss: 0.01828472875058651\n",
      "Epoch: 2/5, Loss: 0.018539683893322945\n",
      "Epoch: 2/5, Loss: 0.007378852926194668\n",
      "Epoch: 2/5, Loss: 0.02367519587278366\n",
      "Epoch: 2/5, Loss: 0.020357290282845497\n",
      "Epoch: 2/5, Loss: 0.00774361239746213\n",
      "Epoch: 2/5, Loss: 0.010918138548731804\n",
      "Epoch: 2/5, Loss: 0.03871724009513855\n",
      "Epoch: 2/5, Loss: 0.005813355091959238\n",
      "Epoch: 2/5, Loss: 0.033459920436143875\n",
      "Epoch: 2/5, Loss: 0.006343701854348183\n",
      "Epoch: 2/5, Loss: 0.01927894540131092\n",
      "Epoch: 2/5, Loss: 0.039063625037670135\n",
      "Epoch: 2/5, Loss: 0.0075262426398694515\n",
      "Epoch: 2/5, Loss: 0.019944889470934868\n",
      "Epoch: 2/5, Loss: 0.01632445864379406\n",
      "Epoch: 2/5, Loss: 0.02266569808125496\n",
      "Epoch: 2/5, Loss: 0.002226719167083502\n",
      "Epoch: 2/5, Loss: 0.006373651325702667\n",
      "Epoch: 2/5, Loss: 0.010273100808262825\n",
      "Epoch: 2/5, Loss: 0.016267701983451843\n",
      "Epoch: 2/5, Loss: 0.026432959362864494\n",
      "Epoch: 2/5, Loss: 0.025123506784439087\n",
      "Epoch: 2/5, Loss: 0.01076506357640028\n",
      "Epoch: 2/5, Loss: 0.03501560539007187\n",
      "Epoch: 2/5, Loss: 0.02331814169883728\n",
      "Epoch: 2/5, Loss: 0.008377847261726856\n",
      "Epoch: 2/5, Loss: 0.017107393592596054\n",
      "Epoch: 2/5, Loss: 0.04128718376159668\n",
      "Epoch: 2/5, Loss: 0.023586243391036987\n",
      "Epoch: 2/5, Loss: 0.03131396323442459\n",
      "Epoch: 2/5, Loss: 0.03247108682990074\n",
      "Epoch: 2/5, Loss: 0.011954338289797306\n",
      "Epoch: 2/5, Loss: 0.01361920591443777\n",
      "Epoch: 2/5, Loss: 0.05546072870492935\n",
      "Epoch: 2/5, Loss: 0.06278887391090393\n",
      "Epoch: 2/5, Loss: 0.0019864151254296303\n",
      "Epoch: 2/5, Loss: 0.03408116102218628\n",
      "Epoch: 2/5, Loss: 0.017778366804122925\n",
      "Epoch: 2/5, Loss: 0.00447611790150404\n",
      "Epoch: 2/5, Loss: 0.04132372513413429\n",
      "Epoch: 2/5, Loss: 0.01178493071347475\n",
      "Epoch: 2/5, Loss: 0.03645757585763931\n",
      "Epoch: 2/5, Loss: 0.025034280493855476\n",
      "Epoch: 2/5, Loss: 0.031036773696541786\n",
      "Epoch: 2/5, Loss: 0.034473828971385956\n",
      "Epoch: 2/5, Loss: 0.023002075031399727\n",
      "Epoch: 2/5, Loss: 0.052840620279312134\n",
      "Epoch: 2/5, Loss: 0.014077027328312397\n",
      "Epoch: 2/5, Loss: 0.00224840035662055\n",
      "Epoch: 2/5, Loss: 0.006415604613721371\n",
      "Epoch: 2/5, Loss: 0.052790869027376175\n",
      "Epoch: 2/5, Loss: 0.020367201417684555\n",
      "Epoch: 2/5, Loss: 0.027641408145427704\n",
      "Epoch: 2/5, Loss: 0.044935327023267746\n",
      "Epoch: 2/5, Loss: 0.01682976633310318\n",
      "Epoch: 2/5, Loss: 0.0136888287961483\n",
      "Epoch: 2/5, Loss: 0.014630388468503952\n",
      "Epoch: 2/5, Loss: 0.0043448954820632935\n",
      "Epoch: 2/5, Loss: 0.002772335195913911\n",
      "Epoch: 2/5, Loss: 0.0467190183699131\n",
      "Epoch: 2/5, Loss: 0.01689395308494568\n",
      "Epoch: 2/5, Loss: 0.024704772979021072\n",
      "Epoch: 2/5, Loss: 0.012057784013450146\n",
      "Epoch: 2/5, Loss: 0.03407016023993492\n",
      "Epoch: 2/5, Loss: 0.00948805920779705\n",
      "Epoch: 2/5, Loss: 0.022025996819138527\n",
      "Epoch: 2/5, Loss: 0.0035386092495173216\n",
      "Epoch: 2/5, Loss: 0.03521997481584549\n",
      "Epoch: 2/5, Loss: 0.0016285370802506804\n",
      "Epoch: 2/5, Loss: 0.0008611463126726449\n",
      "Epoch: 2/5, Loss: 0.014738430269062519\n",
      "Epoch: 2/5, Loss: 0.026546349748969078\n",
      "Epoch: 2/5, Loss: 0.002314721466973424\n",
      "Epoch: 2/5, Loss: 0.004747833125293255\n",
      "Epoch: 2/5, Loss: 0.023358087986707687\n",
      "Epoch: 2/5, Loss: 0.08256746828556061\n",
      "Epoch: 2/5, Loss: 0.026554223150014877\n",
      "Epoch: 2/5, Loss: 0.03717978671193123\n",
      "Epoch: 2/5, Loss: 0.011768942698836327\n",
      "Epoch: 2/5, Loss: 0.013140233233571053\n",
      "Epoch: 2/5, Loss: 0.016469040885567665\n",
      "Epoch: 2/5, Loss: 0.008497213944792747\n",
      "Epoch: 2/5, Loss: 0.0028141671791672707\n",
      "Epoch: 2/5, Loss: 0.005055415444076061\n",
      "Epoch: 2/5, Loss: 0.006227037403732538\n",
      "Epoch: 2/5, Loss: 0.007196012884378433\n",
      "Epoch: 2/5, Loss: 0.02352100796997547\n",
      "Epoch: 2/5, Loss: 0.011720968410372734\n",
      "Epoch: 2/5, Loss: 0.017692366614937782\n",
      "Epoch: 2/5, Loss: 0.011693181470036507\n",
      "Epoch: 2/5, Loss: 0.006960533559322357\n",
      "Epoch: 2/5, Loss: 0.0016607488505542278\n",
      "Epoch: 2/5, Loss: 0.014022761955857277\n",
      "Epoch: 2/5, Loss: 0.014694579876959324\n",
      "Epoch: 2/5, Loss: 0.019707588478922844\n",
      "Epoch: 2/5, Loss: 0.021200330927968025\n",
      "Epoch: 2/5, Loss: 0.04728681594133377\n",
      "Epoch: 2/5, Loss: 0.0030789030715823174\n",
      "Epoch: 2/5, Loss: 0.010987491346895695\n",
      "Epoch: 2/5, Loss: 0.02973543480038643\n",
      "Epoch: 2/5, Loss: 0.003446877934038639\n",
      "Epoch: 2/5, Loss: 0.008053185418248177\n",
      "Epoch: 2/5, Loss: 0.03661704808473587\n",
      "Epoch: 2/5, Loss: 0.021455727517604828\n",
      "Epoch: 2/5, Loss: 0.013904283754527569\n",
      "Epoch: 2/5, Loss: 0.0021323554683476686\n",
      "Epoch: 2/5, Loss: 0.041897550225257874\n",
      "Epoch: 2/5, Loss: 0.0024186333175748587\n",
      "Epoch: 2/5, Loss: 0.0042660171166062355\n",
      "Epoch: 2/5, Loss: 0.023396451026201248\n",
      "Epoch: 2/5, Loss: 0.01949847675859928\n",
      "Epoch: 2/5, Loss: 0.005570533685386181\n",
      "Epoch: 2/5, Loss: 0.043269507586956024\n",
      "Epoch: 2/5, Loss: 0.027006598189473152\n",
      "Epoch: 2/5, Loss: 0.012257588095963001\n",
      "Epoch: 2/5, Loss: 0.005679033696651459\n",
      "Epoch: 2/5, Loss: 0.04175686836242676\n",
      "Epoch: 2/5, Loss: 0.039771489799022675\n",
      "Epoch: 2/5, Loss: 0.0367276594042778\n",
      "Epoch: 2/5, Loss: 0.005312352906912565\n",
      "Epoch: 2/5, Loss: 0.011699765920639038\n",
      "Epoch: 2/5, Loss: 0.0297546349465847\n",
      "Epoch: 2/5, Loss: 0.023341838270425797\n",
      "Epoch: 2/5, Loss: 0.01355455070734024\n",
      "Epoch: 2/5, Loss: 0.007657605689018965\n",
      "Epoch: 2/5, Loss: 0.0038739261217415333\n",
      "Epoch: 2/5, Loss: 0.019254304468631744\n",
      "Epoch: 2/5, Loss: 0.017949428409337997\n",
      "Epoch: 2/5, Loss: 0.012322869151830673\n",
      "Epoch: 2/5, Loss: 0.013367452658712864\n",
      "Epoch: 2/5, Loss: 0.10222566872835159\n",
      "Epoch: 2/5, Loss: 0.028215553611516953\n",
      "Epoch: 2/5, Loss: 0.009127017110586166\n",
      "Epoch: 2/5, Loss: 0.008783744648098946\n",
      "Epoch: 2/5, Loss: 0.009415331296622753\n",
      "Epoch: 2/5, Loss: 0.016414593905210495\n",
      "Epoch: 2/5, Loss: 0.01181033719331026\n",
      "Epoch: 2/5, Loss: 0.007917938753962517\n",
      "Epoch: 2/5, Loss: 0.0038349421229213476\n",
      "Epoch: 2/5, Loss: 0.013676407746970654\n",
      "Epoch: 2/5, Loss: 0.011633115820586681\n",
      "Epoch: 2/5, Loss: 0.01970500312745571\n",
      "Epoch: 2/5, Loss: 0.008248873986303806\n",
      "Epoch: 2/5, Loss: 0.05404191464185715\n",
      "Epoch: 2/5, Loss: 0.005937367677688599\n",
      "Epoch: 2/5, Loss: 0.02311878651380539\n",
      "Epoch: 2/5, Loss: 0.007689793594181538\n",
      "Epoch: 2/5, Loss: 0.025088563561439514\n",
      "Epoch: 2/5, Loss: 0.0076951985247433186\n",
      "Epoch: 2/5, Loss: 0.01743064634501934\n",
      "Epoch: 2/5, Loss: 0.028025692328810692\n",
      "Epoch: 2/5, Loss: 0.016306480392813683\n",
      "Epoch: 2/5, Loss: 0.017053896561264992\n",
      "Epoch: 2/5, Loss: 0.1054321825504303\n",
      "Epoch: 2/5, Loss: 0.009148659184575081\n",
      "Epoch: 2/5, Loss: 0.06684396415948868\n",
      "Epoch: 2/5, Loss: 0.0067992378026247025\n",
      "Epoch: 3/5, Loss: 0.02487204223871231\n",
      "Epoch: 3/5, Loss: 0.006095597520470619\n",
      "Epoch: 3/5, Loss: 0.01830335147678852\n",
      "Epoch: 3/5, Loss: 0.009299593046307564\n",
      "Epoch: 3/5, Loss: 0.02769743837416172\n",
      "Epoch: 3/5, Loss: 0.015005229040980339\n",
      "Epoch: 3/5, Loss: 0.03387512266635895\n",
      "Epoch: 3/5, Loss: 0.009694640524685383\n",
      "Epoch: 3/5, Loss: 0.014296583831310272\n",
      "Epoch: 3/5, Loss: 0.056840680539608\n",
      "Epoch: 3/5, Loss: 0.0029857270419597626\n",
      "Epoch: 3/5, Loss: 0.0074584586545825005\n",
      "Epoch: 3/5, Loss: 0.010174243710935116\n",
      "Epoch: 3/5, Loss: 0.03804626688361168\n",
      "Epoch: 3/5, Loss: 0.019899839535355568\n",
      "Epoch: 3/5, Loss: 0.027799371629953384\n",
      "Epoch: 3/5, Loss: 0.054577745497226715\n",
      "Epoch: 3/5, Loss: 0.02058809995651245\n",
      "Epoch: 3/5, Loss: 0.01789386384189129\n",
      "Epoch: 3/5, Loss: 0.02202639915049076\n",
      "Epoch: 3/5, Loss: 0.01890898123383522\n",
      "Epoch: 3/5, Loss: 0.004514593631029129\n",
      "Epoch: 3/5, Loss: 0.016280388459563255\n",
      "Epoch: 3/5, Loss: 0.0025166072882711887\n",
      "Epoch: 3/5, Loss: 0.014089575968682766\n",
      "Epoch: 3/5, Loss: 0.012297350913286209\n",
      "Epoch: 3/5, Loss: 0.021162543445825577\n",
      "Epoch: 3/5, Loss: 0.019068017601966858\n",
      "Epoch: 3/5, Loss: 0.004629604984074831\n",
      "Epoch: 3/5, Loss: 0.012960493564605713\n",
      "Epoch: 3/5, Loss: 0.010593662969768047\n",
      "Epoch: 3/5, Loss: 0.023600757122039795\n",
      "Epoch: 3/5, Loss: 0.037223491817712784\n",
      "Epoch: 3/5, Loss: 0.013239528052508831\n",
      "Epoch: 3/5, Loss: 0.0013230884214863181\n",
      "Epoch: 3/5, Loss: 0.006039364729076624\n",
      "Epoch: 3/5, Loss: 0.01217319630086422\n",
      "Epoch: 3/5, Loss: 0.004457204602658749\n",
      "Epoch: 3/5, Loss: 0.018670806661248207\n",
      "Epoch: 3/5, Loss: 0.11333781480789185\n",
      "Epoch: 3/5, Loss: 0.024480026215314865\n",
      "Epoch: 3/5, Loss: 0.02271929755806923\n",
      "Epoch: 3/5, Loss: 0.014688104391098022\n",
      "Epoch: 3/5, Loss: 0.045369312167167664\n",
      "Epoch: 3/5, Loss: 0.01387366559356451\n",
      "Epoch: 3/5, Loss: 0.05260204151272774\n",
      "Epoch: 3/5, Loss: 0.022960156202316284\n",
      "Epoch: 3/5, Loss: 0.013299684971570969\n",
      "Epoch: 3/5, Loss: 0.00975511223077774\n",
      "Epoch: 3/5, Loss: 0.05109548568725586\n",
      "Epoch: 3/5, Loss: 0.006449631415307522\n",
      "Epoch: 3/5, Loss: 0.01982300728559494\n",
      "Epoch: 3/5, Loss: 0.0017531421035528183\n",
      "Epoch: 3/5, Loss: 0.0016442948253825307\n",
      "Epoch: 3/5, Loss: 0.0513959676027298\n",
      "Epoch: 3/5, Loss: 0.012816369533538818\n",
      "Epoch: 3/5, Loss: 0.01811913028359413\n",
      "Epoch: 3/5, Loss: 0.01079549640417099\n",
      "Epoch: 3/5, Loss: 0.01099573913961649\n",
      "Epoch: 3/5, Loss: 0.03321119770407677\n",
      "Epoch: 3/5, Loss: 0.02015559934079647\n",
      "Epoch: 3/5, Loss: 0.014167076908051968\n",
      "Epoch: 3/5, Loss: 0.009788594208657742\n",
      "Epoch: 3/5, Loss: 0.013397959992289543\n",
      "Epoch: 3/5, Loss: 0.011906154453754425\n",
      "Epoch: 3/5, Loss: 0.0010457454482093453\n",
      "Epoch: 3/5, Loss: 0.019387153908610344\n",
      "Epoch: 3/5, Loss: 0.030411679297685623\n",
      "Epoch: 3/5, Loss: 0.009587395936250687\n",
      "Epoch: 3/5, Loss: 0.0462300106883049\n",
      "Epoch: 3/5, Loss: 0.020793406292796135\n",
      "Epoch: 3/5, Loss: 0.0018492062808945775\n",
      "Epoch: 3/5, Loss: 0.0031321211718022823\n",
      "Epoch: 3/5, Loss: 0.018709396943449974\n",
      "Epoch: 3/5, Loss: 0.014510304667055607\n",
      "Epoch: 3/5, Loss: 0.019441599026322365\n",
      "Epoch: 3/5, Loss: 0.028274083510041237\n",
      "Epoch: 3/5, Loss: 0.03022879734635353\n",
      "Epoch: 3/5, Loss: 0.01140117458999157\n",
      "Epoch: 3/5, Loss: 0.013149506412446499\n",
      "Epoch: 3/5, Loss: 0.024572867900133133\n",
      "Epoch: 3/5, Loss: 0.01285006944090128\n",
      "Epoch: 3/5, Loss: 0.03663138300180435\n",
      "Epoch: 3/5, Loss: 0.04831511527299881\n",
      "Epoch: 3/5, Loss: 0.007505990564823151\n",
      "Epoch: 3/5, Loss: 0.013914699666202068\n",
      "Epoch: 3/5, Loss: 0.05947111174464226\n",
      "Epoch: 3/5, Loss: 0.0378405936062336\n",
      "Epoch: 3/5, Loss: 0.021017130464315414\n",
      "Epoch: 3/5, Loss: 0.002448643557727337\n",
      "Epoch: 3/5, Loss: 0.018920471891760826\n",
      "Epoch: 3/5, Loss: 0.002625458175316453\n",
      "Epoch: 3/5, Loss: 0.006499080918729305\n",
      "Epoch: 3/5, Loss: 0.0008846785058267415\n",
      "Epoch: 3/5, Loss: 0.007544784806668758\n",
      "Epoch: 3/5, Loss: 0.017017651349306107\n",
      "Epoch: 3/5, Loss: 0.011998042464256287\n",
      "Epoch: 3/5, Loss: 0.013307240791618824\n",
      "Epoch: 3/5, Loss: 0.003382100025191903\n",
      "Epoch: 3/5, Loss: 0.029948348179459572\n",
      "Epoch: 3/5, Loss: 0.04420407861471176\n",
      "Epoch: 3/5, Loss: 0.007182122673839331\n",
      "Epoch: 3/5, Loss: 0.005695119500160217\n",
      "Epoch: 3/5, Loss: 0.04506457597017288\n",
      "Epoch: 3/5, Loss: 0.005948688369244337\n",
      "Epoch: 3/5, Loss: 0.02529335394501686\n",
      "Epoch: 3/5, Loss: 0.049690090119838715\n",
      "Epoch: 3/5, Loss: 0.023053832352161407\n",
      "Epoch: 3/5, Loss: 0.007504788227379322\n",
      "Epoch: 3/5, Loss: 0.006873046047985554\n",
      "Epoch: 3/5, Loss: 0.013703343458473682\n",
      "Epoch: 3/5, Loss: 0.011185585521161556\n",
      "Epoch: 3/5, Loss: 0.00301530584692955\n",
      "Epoch: 3/5, Loss: 0.013225123286247253\n",
      "Epoch: 3/5, Loss: 0.023581309244036674\n",
      "Epoch: 3/5, Loss: 0.02850332483649254\n",
      "Epoch: 3/5, Loss: 0.004248396027833223\n",
      "Epoch: 3/5, Loss: 0.02029348909854889\n",
      "Epoch: 3/5, Loss: 0.004658515099436045\n",
      "Epoch: 3/5, Loss: 0.008534218184649944\n",
      "Epoch: 3/5, Loss: 0.015484001487493515\n",
      "Epoch: 3/5, Loss: 0.021324364468455315\n",
      "Epoch: 3/5, Loss: 0.017215728759765625\n",
      "Epoch: 3/5, Loss: 0.005897863768041134\n",
      "Epoch: 3/5, Loss: 0.007746990770101547\n",
      "Epoch: 3/5, Loss: 0.012064768001437187\n",
      "Epoch: 3/5, Loss: 0.04219234734773636\n",
      "Epoch: 3/5, Loss: 0.005265136249363422\n",
      "Epoch: 3/5, Loss: 0.012252354994416237\n",
      "Epoch: 3/5, Loss: 0.017738841474056244\n",
      "Epoch: 3/5, Loss: 0.029446687549352646\n",
      "Epoch: 3/5, Loss: 0.0372101292014122\n",
      "Epoch: 3/5, Loss: 0.023352479562163353\n",
      "Epoch: 3/5, Loss: 0.012447785586118698\n",
      "Epoch: 3/5, Loss: 0.030457349494099617\n",
      "Epoch: 3/5, Loss: 0.007140897214412689\n",
      "Epoch: 3/5, Loss: 0.002942844294011593\n",
      "Epoch: 3/5, Loss: 0.013236837461590767\n",
      "Epoch: 3/5, Loss: 0.0012756537180393934\n",
      "Epoch: 3/5, Loss: 0.019526276737451553\n",
      "Epoch: 3/5, Loss: 0.00433082552626729\n",
      "Epoch: 3/5, Loss: 0.03665606677532196\n",
      "Epoch: 3/5, Loss: 0.01581956446170807\n",
      "Epoch: 3/5, Loss: 0.005517918150871992\n",
      "Epoch: 3/5, Loss: 0.007684633135795593\n",
      "Epoch: 3/5, Loss: 0.0316363126039505\n",
      "Epoch: 3/5, Loss: 0.002764575881883502\n",
      "Epoch: 3/5, Loss: 0.00997231900691986\n",
      "Epoch: 3/5, Loss: 0.024260321632027626\n",
      "Epoch: 3/5, Loss: 0.015544340945780277\n",
      "Epoch: 3/5, Loss: 0.003367788391187787\n",
      "Epoch: 3/5, Loss: 0.02677348628640175\n",
      "Epoch: 3/5, Loss: 0.016147103160619736\n",
      "Epoch: 3/5, Loss: 0.012503333389759064\n",
      "Epoch: 3/5, Loss: 0.048403650522232056\n",
      "Epoch: 3/5, Loss: 0.023183710873126984\n",
      "Epoch: 3/5, Loss: 0.01098464522510767\n",
      "Epoch: 3/5, Loss: 0.02457784302532673\n",
      "Epoch: 3/5, Loss: 0.01929047517478466\n",
      "Epoch: 3/5, Loss: 0.03567665070295334\n",
      "Epoch: 3/5, Loss: 0.030163384974002838\n",
      "Epoch: 3/5, Loss: 0.10262293368577957\n",
      "Epoch: 3/5, Loss: 0.025836337357759476\n",
      "Epoch: 3/5, Loss: 0.01616618037223816\n",
      "Epoch: 3/5, Loss: 0.007510290946811438\n",
      "Epoch: 3/5, Loss: 0.009286334738135338\n",
      "Epoch: 3/5, Loss: 0.030635036528110504\n",
      "Epoch: 3/5, Loss: 0.003722234396263957\n",
      "Epoch: 3/5, Loss: 0.05205802246928215\n",
      "Epoch: 3/5, Loss: 0.02743464708328247\n",
      "Epoch: 3/5, Loss: 0.012905927374958992\n",
      "Epoch: 3/5, Loss: 0.009453844279050827\n",
      "Epoch: 3/5, Loss: 0.021615613251924515\n",
      "Epoch: 3/5, Loss: 0.043322738260030746\n",
      "Epoch: 3/5, Loss: 0.02473277971148491\n",
      "Epoch: 3/5, Loss: 0.005056288558989763\n",
      "Epoch: 3/5, Loss: 0.006294479127973318\n",
      "Epoch: 3/5, Loss: 0.02086537331342697\n",
      "Epoch: 3/5, Loss: 0.008075724355876446\n",
      "Epoch: 3/5, Loss: 0.03456609696149826\n",
      "Epoch: 3/5, Loss: 0.00544457882642746\n",
      "Epoch: 3/5, Loss: 0.029416969045996666\n",
      "Epoch: 3/5, Loss: 0.008916633203625679\n",
      "Epoch: 3/5, Loss: 0.03921177238225937\n",
      "Epoch: 3/5, Loss: 0.04297173023223877\n",
      "Epoch: 3/5, Loss: 0.023671245202422142\n",
      "Epoch: 3/5, Loss: 0.010504805482923985\n",
      "Epoch: 3/5, Loss: 0.04057086259126663\n",
      "Epoch: 3/5, Loss: 0.011387771926820278\n",
      "Epoch: 3/5, Loss: 0.020309919491410255\n",
      "Epoch: 3/5, Loss: 0.11958009004592896\n",
      "Epoch: 3/5, Loss: 0.039974622428417206\n",
      "Epoch: 3/5, Loss: 0.01379466149955988\n",
      "Epoch: 3/5, Loss: 0.01091864425688982\n",
      "Epoch: 3/5, Loss: 0.00984796043485403\n",
      "Epoch: 3/5, Loss: 0.023347949609160423\n",
      "Epoch: 3/5, Loss: 0.022694610059261322\n",
      "Epoch: 3/5, Loss: 0.04382583871483803\n",
      "Epoch: 3/5, Loss: 0.0058242399245500565\n",
      "Epoch: 3/5, Loss: 0.03755790740251541\n",
      "Epoch: 3/5, Loss: 0.01020081713795662\n",
      "Epoch: 3/5, Loss: 0.008404968306422234\n",
      "Epoch: 3/5, Loss: 0.011754140257835388\n",
      "Epoch: 3/5, Loss: 0.04463746398687363\n",
      "Epoch: 3/5, Loss: 0.09901518374681473\n",
      "Epoch: 3/5, Loss: 0.03683227300643921\n",
      "Epoch: 3/5, Loss: 0.018672119826078415\n",
      "Epoch: 3/5, Loss: 0.04358768090605736\n",
      "Epoch: 3/5, Loss: 0.03720443695783615\n",
      "Epoch: 3/5, Loss: 0.016578637063503265\n",
      "Epoch: 3/5, Loss: 0.02724391594529152\n",
      "Epoch: 3/5, Loss: 0.006044759415090084\n",
      "Epoch: 3/5, Loss: 0.0671948716044426\n",
      "Epoch: 3/5, Loss: 0.03533130884170532\n",
      "Epoch: 3/5, Loss: 0.02261647954583168\n",
      "Epoch: 3/5, Loss: 0.024199333041906357\n",
      "Epoch: 3/5, Loss: 0.025199726223945618\n",
      "Epoch: 3/5, Loss: 0.012543685734272003\n",
      "Epoch: 3/5, Loss: 0.08946327120065689\n",
      "Epoch: 3/5, Loss: 0.12540824711322784\n",
      "Epoch: 3/5, Loss: 0.02114187926054001\n",
      "Epoch: 3/5, Loss: 0.0047879088670015335\n",
      "Epoch: 3/5, Loss: 0.018431134521961212\n",
      "Epoch: 3/5, Loss: 0.014207202009856701\n",
      "Epoch: 3/5, Loss: 0.007273793686181307\n",
      "Epoch: 3/5, Loss: 0.020459184423089027\n",
      "Epoch: 3/5, Loss: 0.0075036585330963135\n",
      "Epoch: 3/5, Loss: 0.025088489055633545\n",
      "Epoch: 3/5, Loss: 0.008426074869930744\n",
      "Epoch: 3/5, Loss: 0.022510454058647156\n",
      "Epoch: 3/5, Loss: 0.030890261754393578\n",
      "Epoch: 3/5, Loss: 0.011247366666793823\n",
      "Epoch: 3/5, Loss: 0.012902744114398956\n",
      "Epoch: 3/5, Loss: 0.013351923786103725\n",
      "Epoch: 3/5, Loss: 0.005412587895989418\n",
      "Epoch: 3/5, Loss: 0.02174936607480049\n",
      "Epoch: 3/5, Loss: 0.01735263131558895\n",
      "Epoch: 3/5, Loss: 0.017752740532159805\n",
      "Epoch: 3/5, Loss: 0.047031205147504807\n",
      "Epoch: 3/5, Loss: 0.009262665174901485\n",
      "Epoch: 3/5, Loss: 0.023873088881373405\n",
      "Epoch: 3/5, Loss: 0.013423044234514236\n",
      "Epoch: 3/5, Loss: 0.00796548929065466\n",
      "Epoch: 3/5, Loss: 0.01964952051639557\n",
      "Epoch: 3/5, Loss: 0.022642923519015312\n",
      "Epoch: 3/5, Loss: 0.03226342424750328\n",
      "Epoch: 3/5, Loss: 0.00821724347770214\n",
      "Epoch: 3/5, Loss: 0.004261152818799019\n",
      "Epoch: 3/5, Loss: 0.010786386206746101\n",
      "Epoch: 3/5, Loss: 0.003534168703481555\n",
      "Epoch: 3/5, Loss: 0.00979592278599739\n",
      "Epoch: 3/5, Loss: 0.018414758145809174\n",
      "Epoch: 3/5, Loss: 0.020848890766501427\n",
      "Epoch: 3/5, Loss: 0.027462050318717957\n",
      "Epoch: 3/5, Loss: 0.03925742208957672\n",
      "Epoch: 3/5, Loss: 0.029698055237531662\n",
      "Epoch: 3/5, Loss: 0.011663776822388172\n",
      "Epoch: 3/5, Loss: 0.008071385324001312\n",
      "Epoch: 3/5, Loss: 0.0018155878642573953\n",
      "Epoch: 3/5, Loss: 0.008749610744416714\n",
      "Epoch: 3/5, Loss: 0.0026197326369583607\n",
      "Epoch: 3/5, Loss: 0.01172532606869936\n",
      "Epoch: 3/5, Loss: 0.02663026936352253\n",
      "Epoch: 3/5, Loss: 0.012697946280241013\n",
      "Epoch: 3/5, Loss: 0.024143585935235023\n",
      "Epoch: 3/5, Loss: 0.00333884684368968\n",
      "Epoch: 3/5, Loss: 0.008587035350501537\n",
      "Epoch: 3/5, Loss: 0.02175171487033367\n",
      "Epoch: 3/5, Loss: 0.024544481188058853\n",
      "Epoch: 3/5, Loss: 0.019032305106520653\n",
      "Epoch: 3/5, Loss: 0.02376815862953663\n",
      "Epoch: 3/5, Loss: 0.0027389151509851217\n",
      "Epoch: 3/5, Loss: 0.0018437855178490281\n",
      "Epoch: 3/5, Loss: 0.006614395882934332\n",
      "Epoch: 3/5, Loss: 0.009452760219573975\n",
      "Epoch: 3/5, Loss: 0.01165454275906086\n",
      "Epoch: 3/5, Loss: 0.02005387656390667\n",
      "Epoch: 3/5, Loss: 0.012033093720674515\n",
      "Epoch: 3/5, Loss: 0.02239927090704441\n",
      "Epoch: 3/5, Loss: 0.023088663816452026\n",
      "Epoch: 3/5, Loss: 0.0018789541209116578\n",
      "Epoch: 3/5, Loss: 0.005384140647947788\n",
      "Epoch: 3/5, Loss: 0.01864781230688095\n",
      "Epoch: 3/5, Loss: 0.024596907198429108\n",
      "Epoch: 3/5, Loss: 0.014910370111465454\n",
      "Epoch: 3/5, Loss: 0.005951799917966127\n",
      "Epoch: 3/5, Loss: 0.002246835036203265\n",
      "Epoch: 3/5, Loss: 0.0008558869012631476\n",
      "Epoch: 3/5, Loss: 0.019341547042131424\n",
      "Epoch: 3/5, Loss: 0.016694003716111183\n",
      "Epoch: 3/5, Loss: 0.044671643525362015\n",
      "Epoch: 3/5, Loss: 0.00896904431283474\n",
      "Epoch: 3/5, Loss: 0.027106154710054398\n",
      "Epoch: 3/5, Loss: 0.042450517416000366\n",
      "Epoch: 3/5, Loss: 0.004385017324239016\n",
      "Epoch: 3/5, Loss: 0.00873587280511856\n",
      "Epoch: 3/5, Loss: 0.009345293045043945\n",
      "Epoch: 3/5, Loss: 0.005249334964901209\n",
      "Epoch: 3/5, Loss: 0.009555347263813019\n",
      "Epoch: 3/5, Loss: 0.011508777737617493\n",
      "Epoch: 3/5, Loss: 0.03208748623728752\n",
      "Epoch: 3/5, Loss: 0.014343439601361752\n",
      "Epoch: 3/5, Loss: 0.014785460196435452\n",
      "Epoch: 3/5, Loss: 0.005998092237859964\n",
      "Epoch: 3/5, Loss: 0.011778020299971104\n",
      "Epoch: 3/5, Loss: 0.03894912078976631\n",
      "Epoch: 3/5, Loss: 0.0274933110922575\n",
      "Epoch: 3/5, Loss: 0.009745581075549126\n",
      "Epoch: 3/5, Loss: 0.015365327708423138\n",
      "Epoch: 3/5, Loss: 0.014829644002020359\n",
      "Epoch: 3/5, Loss: 0.016426624730229378\n",
      "Epoch: 3/5, Loss: 0.034492045640945435\n",
      "Epoch: 3/5, Loss: 0.024794824421405792\n",
      "Epoch: 3/5, Loss: 0.006291014142334461\n",
      "Epoch: 3/5, Loss: 0.01602751761674881\n",
      "Epoch: 3/5, Loss: 0.014836259186267853\n",
      "Epoch: 3/5, Loss: 0.019386036321520805\n",
      "Epoch: 3/5, Loss: 0.004680280573666096\n",
      "Epoch: 3/5, Loss: 0.01934758946299553\n",
      "Epoch: 3/5, Loss: 0.019941987469792366\n",
      "Epoch: 3/5, Loss: 0.029054637998342514\n",
      "Epoch: 3/5, Loss: 0.002903265180066228\n",
      "Epoch: 3/5, Loss: 0.017900507897138596\n",
      "Epoch: 3/5, Loss: 0.024666471406817436\n",
      "Epoch: 3/5, Loss: 0.003743767272680998\n",
      "Epoch: 3/5, Loss: 0.026036079972982407\n",
      "Epoch: 3/5, Loss: 0.06258317828178406\n",
      "Epoch: 3/5, Loss: 0.06078575178980827\n",
      "Epoch: 3/5, Loss: 0.006164803169667721\n",
      "Epoch: 3/5, Loss: 0.00975614134222269\n",
      "Epoch: 3/5, Loss: 0.011858907528221607\n",
      "Epoch: 3/5, Loss: 0.05055595189332962\n",
      "Epoch: 3/5, Loss: 0.01601877063512802\n",
      "Epoch: 3/5, Loss: 0.02469385601580143\n",
      "Epoch: 3/5, Loss: 0.034400708973407745\n",
      "Epoch: 3/5, Loss: 0.01096305064857006\n",
      "Epoch: 3/5, Loss: 0.008230463601648808\n",
      "Epoch: 3/5, Loss: 0.013479381799697876\n",
      "Epoch: 3/5, Loss: 0.006300095468759537\n",
      "Epoch: 3/5, Loss: 0.02330135740339756\n",
      "Epoch: 3/5, Loss: 0.02688165381550789\n",
      "Epoch: 3/5, Loss: 0.03235846385359764\n",
      "Epoch: 3/5, Loss: 0.00204349379055202\n",
      "Epoch: 3/5, Loss: 0.03189297765493393\n",
      "Epoch: 3/5, Loss: 0.027735020965337753\n",
      "Epoch: 3/5, Loss: 0.01850493997335434\n",
      "Epoch: 3/5, Loss: 0.05877741798758507\n",
      "Epoch: 3/5, Loss: 0.08323460072278976\n",
      "Epoch: 3/5, Loss: 0.015413078479468822\n",
      "Epoch: 3/5, Loss: 0.0008739964105188847\n",
      "Epoch: 3/5, Loss: 0.008652854710817337\n",
      "Epoch: 3/5, Loss: 0.007533579133450985\n",
      "Epoch: 3/5, Loss: 0.011333095841109753\n",
      "Epoch: 3/5, Loss: 0.03239613026380539\n",
      "Epoch: 3/5, Loss: 0.012960122898221016\n",
      "Epoch: 3/5, Loss: 0.01445266604423523\n",
      "Epoch: 3/5, Loss: 0.07895898073911667\n",
      "Epoch: 3/5, Loss: 0.009532682597637177\n",
      "Epoch: 3/5, Loss: 0.004465037956833839\n",
      "Epoch: 3/5, Loss: 0.05015316233038902\n",
      "Epoch: 3/5, Loss: 0.0007177453953772783\n",
      "Epoch: 3/5, Loss: 0.0013657276285812259\n",
      "Epoch: 3/5, Loss: 0.0026770031545311213\n",
      "Epoch: 3/5, Loss: 0.01485931221395731\n",
      "Epoch: 3/5, Loss: 0.03072861023247242\n",
      "Epoch: 3/5, Loss: 0.015163393691182137\n",
      "Epoch: 3/5, Loss: 0.0031048436649143696\n",
      "Epoch: 3/5, Loss: 0.011666029691696167\n",
      "Epoch: 3/5, Loss: 0.005454949103295803\n",
      "Epoch: 3/5, Loss: 0.005555457901209593\n",
      "Epoch: 3/5, Loss: 0.020422212779521942\n",
      "Epoch: 3/5, Loss: 0.035094477236270905\n",
      "Epoch: 3/5, Loss: 0.05253346264362335\n",
      "Epoch: 3/5, Loss: 0.015524283051490784\n",
      "Epoch: 3/5, Loss: 0.013454116880893707\n",
      "Epoch: 3/5, Loss: 0.04411356896162033\n",
      "Epoch: 3/5, Loss: 0.03170151263475418\n",
      "Epoch: 3/5, Loss: 0.00227734399959445\n",
      "Epoch: 3/5, Loss: 0.012938194908201694\n",
      "Epoch: 3/5, Loss: 0.025920787826180458\n",
      "Epoch: 3/5, Loss: 0.04448595643043518\n",
      "Epoch: 3/5, Loss: 0.051561783999204636\n",
      "Epoch: 3/5, Loss: 0.008956566452980042\n",
      "Epoch: 3/5, Loss: 0.006251635029911995\n",
      "Epoch: 3/5, Loss: 0.009578890167176723\n",
      "Epoch: 3/5, Loss: 0.0240184273570776\n",
      "Epoch: 3/5, Loss: 0.016049522906541824\n",
      "Epoch: 3/5, Loss: 0.025717584416270256\n",
      "Epoch: 3/5, Loss: 0.02119814231991768\n",
      "Epoch: 3/5, Loss: 0.01136484183371067\n",
      "Epoch: 3/5, Loss: 0.1359577775001526\n",
      "Epoch: 3/5, Loss: 0.020633157342672348\n",
      "Epoch: 3/5, Loss: 0.02634739875793457\n",
      "Epoch: 3/5, Loss: 0.008241425268352032\n",
      "Epoch: 3/5, Loss: 0.009711656719446182\n",
      "Epoch: 3/5, Loss: 0.011720124632120132\n",
      "Epoch: 3/5, Loss: 0.020680738613009453\n",
      "Epoch: 3/5, Loss: 0.02853539027273655\n",
      "Epoch: 3/5, Loss: 0.06486734747886658\n",
      "Epoch: 3/5, Loss: 0.040857069194316864\n",
      "Epoch: 3/5, Loss: 0.009949896484613419\n",
      "Epoch: 3/5, Loss: 0.02626699209213257\n",
      "Epoch: 3/5, Loss: 0.06786729395389557\n",
      "Epoch: 3/5, Loss: 0.009817680343985558\n",
      "Epoch: 3/5, Loss: 0.0022695129737257957\n",
      "Epoch: 3/5, Loss: 0.010059221647679806\n",
      "Epoch: 3/5, Loss: 0.03798270970582962\n",
      "Epoch: 3/5, Loss: 0.010661451146006584\n",
      "Epoch: 3/5, Loss: 0.007199612446129322\n",
      "Epoch: 3/5, Loss: 0.021349120885133743\n",
      "Epoch: 3/5, Loss: 0.0336611308157444\n",
      "Epoch: 3/5, Loss: 0.0369420163333416\n",
      "Epoch: 3/5, Loss: 0.012193312868475914\n",
      "Epoch: 3/5, Loss: 0.012177783995866776\n",
      "Epoch: 3/5, Loss: 0.02931816130876541\n",
      "Epoch: 3/5, Loss: 0.0015576285077258945\n",
      "Epoch: 3/5, Loss: 0.006032759323716164\n",
      "Epoch: 3/5, Loss: 0.014892716892063618\n",
      "Epoch: 3/5, Loss: 0.007397676818072796\n",
      "Epoch: 3/5, Loss: 0.020650606602430344\n",
      "Epoch: 3/5, Loss: 0.013175786472856998\n",
      "Epoch: 3/5, Loss: 0.060614921152591705\n",
      "Epoch: 3/5, Loss: 0.005157554522156715\n",
      "Epoch: 3/5, Loss: 0.0074474080465734005\n",
      "Epoch: 3/5, Loss: 0.024023327976465225\n",
      "Epoch: 3/5, Loss: 0.009094570763409138\n",
      "Epoch: 3/5, Loss: 0.009742376394569874\n",
      "Epoch: 3/5, Loss: 0.00684001948684454\n",
      "Epoch: 3/5, Loss: 0.012346616014838219\n",
      "Epoch: 3/5, Loss: 0.05070537328720093\n",
      "Epoch: 3/5, Loss: 0.021917184814810753\n",
      "Epoch: 3/5, Loss: 0.020387711003422737\n",
      "Epoch: 3/5, Loss: 0.004342802334576845\n",
      "Epoch: 3/5, Loss: 0.04414563626050949\n",
      "Epoch: 3/5, Loss: 0.03344128653407097\n",
      "Epoch: 3/5, Loss: 0.018466461449861526\n",
      "Epoch: 3/5, Loss: 0.013228274881839752\n",
      "Epoch: 3/5, Loss: 0.02672659605741501\n",
      "Epoch: 3/5, Loss: 0.017150605097413063\n",
      "Epoch: 3/5, Loss: 0.037183135747909546\n",
      "Epoch: 3/5, Loss: 0.0010732968803495169\n",
      "Epoch: 3/5, Loss: 0.019788330420851707\n",
      "Epoch: 3/5, Loss: 0.0016006610821932554\n",
      "Epoch: 3/5, Loss: 0.022420024499297142\n",
      "Epoch: 3/5, Loss: 0.03449898958206177\n",
      "Epoch: 3/5, Loss: 0.010877401567995548\n",
      "Epoch: 3/5, Loss: 0.02495528943836689\n",
      "Epoch: 3/5, Loss: 0.005563174374401569\n",
      "Epoch: 3/5, Loss: 0.01672654040157795\n",
      "Epoch: 3/5, Loss: 0.02573014795780182\n",
      "Epoch: 3/5, Loss: 0.016346342861652374\n",
      "Epoch: 3/5, Loss: 0.02104741521179676\n",
      "Epoch: 3/5, Loss: 0.03185394033789635\n",
      "Epoch: 3/5, Loss: 0.009376198053359985\n",
      "Epoch: 3/5, Loss: 0.022717729210853577\n",
      "Epoch: 3/5, Loss: 0.03586277365684509\n",
      "Epoch: 3/5, Loss: 0.010326662100851536\n",
      "Epoch: 3/5, Loss: 0.019130883738398552\n",
      "Epoch: 3/5, Loss: 0.006069423630833626\n",
      "Epoch: 3/5, Loss: 0.023952621966600418\n",
      "Epoch: 3/5, Loss: 0.004167772363871336\n",
      "Epoch: 3/5, Loss: 0.021218078210949898\n",
      "Epoch: 3/5, Loss: 0.0027410059701651335\n",
      "Epoch: 3/5, Loss: 0.010257148183882236\n",
      "Epoch: 3/5, Loss: 0.006356414873152971\n",
      "Epoch: 3/5, Loss: 0.006663516163825989\n",
      "Epoch: 3/5, Loss: 0.007841468788683414\n",
      "Epoch: 3/5, Loss: 0.024582359939813614\n",
      "Epoch: 3/5, Loss: 0.017930718138813972\n",
      "Epoch: 3/5, Loss: 0.032528314739465714\n",
      "Epoch: 3/5, Loss: 0.023202763870358467\n",
      "Epoch: 3/5, Loss: 0.01817028969526291\n",
      "Epoch: 3/5, Loss: 0.006870724726468325\n",
      "Epoch: 3/5, Loss: 0.047762494534254074\n",
      "Epoch: 3/5, Loss: 0.05054483190178871\n",
      "Epoch: 3/5, Loss: 0.02973647229373455\n",
      "Epoch: 3/5, Loss: 0.016157180070877075\n",
      "Epoch: 3/5, Loss: 0.024149462580680847\n",
      "Epoch: 3/5, Loss: 0.014054510742425919\n",
      "Epoch: 3/5, Loss: 0.013233300298452377\n",
      "Epoch: 3/5, Loss: 0.07104907929897308\n",
      "Epoch: 3/5, Loss: 0.0331457145512104\n",
      "Epoch: 3/5, Loss: 0.022308820858597755\n",
      "Epoch: 3/5, Loss: 0.002686412539333105\n",
      "Epoch: 3/5, Loss: 0.01661437191069126\n",
      "Epoch: 3/5, Loss: 0.009982476010918617\n",
      "Epoch: 3/5, Loss: 0.014701467007398605\n",
      "Epoch: 3/5, Loss: 0.1054389476776123\n",
      "Epoch: 3/5, Loss: 0.04841918498277664\n",
      "Epoch: 3/5, Loss: 0.002130636014044285\n",
      "Epoch: 3/5, Loss: 0.004947929177433252\n",
      "Epoch: 3/5, Loss: 0.017018822953104973\n",
      "Epoch: 3/5, Loss: 0.030149713158607483\n",
      "Epoch: 3/5, Loss: 0.008248263038694859\n",
      "Epoch: 3/5, Loss: 0.0031724032014608383\n",
      "Epoch: 3/5, Loss: 0.00446259044110775\n",
      "Epoch: 3/5, Loss: 0.04510880261659622\n",
      "Epoch: 3/5, Loss: 0.005896484944969416\n",
      "Epoch: 3/5, Loss: 0.023905010893940926\n",
      "Epoch: 3/5, Loss: 0.012868814170360565\n",
      "Epoch: 3/5, Loss: 0.005287480540573597\n",
      "Epoch: 3/5, Loss: 0.05410457029938698\n",
      "Epoch: 3/5, Loss: 0.035100843757390976\n",
      "Epoch: 3/5, Loss: 0.008967616595327854\n",
      "Epoch: 3/5, Loss: 0.009891309775412083\n",
      "Epoch: 3/5, Loss: 0.004059982020407915\n",
      "Epoch: 3/5, Loss: 0.0030282586812973022\n",
      "Epoch: 3/5, Loss: 0.029744889587163925\n",
      "Epoch: 3/5, Loss: 0.019285552203655243\n",
      "Epoch: 3/5, Loss: 0.0066950321197509766\n",
      "Epoch: 3/5, Loss: 0.02150699496269226\n",
      "Epoch: 3/5, Loss: 0.018624071031808853\n",
      "Epoch: 3/5, Loss: 0.012108477763831615\n",
      "Epoch: 3/5, Loss: 0.01839047111570835\n",
      "Epoch: 3/5, Loss: 0.026001712307333946\n",
      "Epoch: 3/5, Loss: 0.03466126322746277\n",
      "Epoch: 3/5, Loss: 0.025150824338197708\n",
      "Epoch: 3/5, Loss: 0.019264567643404007\n",
      "Epoch: 3/5, Loss: 0.011243273504078388\n",
      "Epoch: 3/5, Loss: 0.005575704853981733\n",
      "Epoch: 3/5, Loss: 0.03269774466753006\n",
      "Epoch: 3/5, Loss: 0.027289021760225296\n",
      "Epoch: 3/5, Loss: 0.03560706973075867\n",
      "Epoch: 3/5, Loss: 0.015156334266066551\n",
      "Epoch: 3/5, Loss: 0.004503010306507349\n",
      "Epoch: 3/5, Loss: 0.009901545941829681\n",
      "Epoch: 3/5, Loss: 0.022602640092372894\n",
      "Epoch: 3/5, Loss: 0.000838623265735805\n",
      "Epoch: 3/5, Loss: 0.010986799374222755\n",
      "Epoch: 3/5, Loss: 0.01726299710571766\n",
      "Epoch: 3/5, Loss: 0.018812570720911026\n",
      "Epoch: 3/5, Loss: 0.00749568035826087\n",
      "Epoch: 3/5, Loss: 0.04758656397461891\n",
      "Epoch: 3/5, Loss: 0.02142161689698696\n",
      "Epoch: 3/5, Loss: 0.012186178006231785\n",
      "Epoch: 3/5, Loss: 0.010204741731286049\n",
      "Epoch: 3/5, Loss: 0.030265921726822853\n",
      "Epoch: 3/5, Loss: 0.02517888695001602\n",
      "Epoch: 3/5, Loss: 0.019361667335033417\n",
      "Epoch: 3/5, Loss: 0.009957116097211838\n",
      "Epoch: 3/5, Loss: 0.039621464908123016\n",
      "Epoch: 3/5, Loss: 0.016634434461593628\n",
      "Epoch: 3/5, Loss: 0.018182165920734406\n",
      "Epoch: 3/5, Loss: 0.013113828375935555\n",
      "Epoch: 3/5, Loss: 0.03188507258892059\n",
      "Epoch: 3/5, Loss: 0.028857003897428513\n",
      "Epoch: 3/5, Loss: 0.005583827383816242\n",
      "Epoch: 3/5, Loss: 0.008481242693960667\n",
      "Epoch: 3/5, Loss: 0.019140327349305153\n",
      "Epoch: 3/5, Loss: 0.005854395218193531\n",
      "Epoch: 3/5, Loss: 0.012043921276926994\n",
      "Epoch: 3/5, Loss: 0.028321966528892517\n",
      "Epoch: 3/5, Loss: 0.023326581344008446\n",
      "Epoch: 3/5, Loss: 0.012046076357364655\n",
      "Epoch: 3/5, Loss: 0.05003276467323303\n",
      "Epoch: 3/5, Loss: 0.015755709260702133\n",
      "Epoch: 3/5, Loss: 0.0379939042031765\n",
      "Epoch: 3/5, Loss: 0.005443914793431759\n",
      "Epoch: 3/5, Loss: 0.02058255858719349\n",
      "Epoch: 3/5, Loss: 0.03575902432203293\n",
      "Epoch: 3/5, Loss: 0.0010342540917918086\n",
      "Epoch: 3/5, Loss: 0.017300792038440704\n",
      "Epoch: 3/5, Loss: 0.016974899917840958\n",
      "Epoch: 3/5, Loss: 0.036987293511629105\n",
      "Epoch: 3/5, Loss: 0.016810879111289978\n",
      "Epoch: 3/5, Loss: 0.007943451404571533\n",
      "Epoch: 3/5, Loss: 0.007592093199491501\n",
      "Epoch: 3/5, Loss: 0.024238456040620804\n",
      "Epoch: 3/5, Loss: 0.0076685817912220955\n",
      "Epoch: 3/5, Loss: 0.029779519885778427\n",
      "Epoch: 3/5, Loss: 0.007131963036954403\n",
      "Epoch: 3/5, Loss: 0.018617702648043633\n",
      "Epoch: 3/5, Loss: 0.08218096196651459\n",
      "Epoch: 3/5, Loss: 0.03906622529029846\n",
      "Epoch: 3/5, Loss: 0.02080143429338932\n",
      "Epoch: 3/5, Loss: 0.010656844824552536\n",
      "Epoch: 3/5, Loss: 0.0022022854536771774\n",
      "Epoch: 3/5, Loss: 0.010162372142076492\n",
      "Epoch: 3/5, Loss: 0.01753285713493824\n",
      "Epoch: 3/5, Loss: 0.026217298582196236\n",
      "Epoch: 3/5, Loss: 0.01579161360859871\n",
      "Epoch: 3/5, Loss: 0.02594705857336521\n",
      "Epoch: 3/5, Loss: 0.009802207350730896\n",
      "Epoch: 3/5, Loss: 0.00842339638620615\n",
      "Epoch: 3/5, Loss: 0.04233083873987198\n",
      "Epoch: 3/5, Loss: 0.07074002176523209\n",
      "Epoch: 3/5, Loss: 0.03714561462402344\n",
      "Epoch: 3/5, Loss: 0.013315403833985329\n",
      "Epoch: 3/5, Loss: 0.04355461522936821\n",
      "Epoch: 3/5, Loss: 0.010115247219800949\n",
      "Epoch: 3/5, Loss: 0.03486258164048195\n",
      "Epoch: 3/5, Loss: 0.02516757696866989\n",
      "Epoch: 3/5, Loss: 0.04669969156384468\n",
      "Epoch: 3/5, Loss: 0.015192253515124321\n",
      "Epoch: 3/5, Loss: 0.0299245472997427\n",
      "Epoch: 3/5, Loss: 0.02079833671450615\n",
      "Epoch: 3/5, Loss: 0.06013678014278412\n",
      "Epoch: 3/5, Loss: 0.01921048015356064\n",
      "Epoch: 3/5, Loss: 0.018767373636364937\n",
      "Epoch: 3/5, Loss: 0.025293581187725067\n",
      "Epoch: 3/5, Loss: 0.003953011240810156\n",
      "Epoch: 3/5, Loss: 0.025699516758322716\n",
      "Epoch: 3/5, Loss: 0.02367771789431572\n",
      "Epoch: 3/5, Loss: 0.010603801347315311\n",
      "Epoch: 3/5, Loss: 0.004071257542818785\n",
      "Epoch: 3/5, Loss: 0.015266869217157364\n",
      "Epoch: 3/5, Loss: 0.026459239423274994\n",
      "Epoch: 3/5, Loss: 0.019284121692180634\n",
      "Epoch: 3/5, Loss: 0.005744932685047388\n",
      "Epoch: 3/5, Loss: 0.023972611874341965\n",
      "Epoch: 3/5, Loss: 0.0093165822327137\n",
      "Epoch: 3/5, Loss: 0.0023173936642706394\n",
      "Epoch: 3/5, Loss: 0.013807779178023338\n",
      "Epoch: 3/5, Loss: 0.01931925117969513\n",
      "Epoch: 3/5, Loss: 0.014432879164814949\n",
      "Epoch: 3/5, Loss: 0.002261397195979953\n",
      "Epoch: 3/5, Loss: 0.04209653288125992\n",
      "Epoch: 3/5, Loss: 0.018237508833408356\n",
      "Epoch: 3/5, Loss: 0.016855701804161072\n",
      "Epoch: 3/5, Loss: 0.019632425159215927\n",
      "Epoch: 3/5, Loss: 0.03081422671675682\n",
      "Epoch: 3/5, Loss: 0.014008878730237484\n",
      "Epoch: 3/5, Loss: 0.023391753435134888\n",
      "Epoch: 3/5, Loss: 0.04020749405026436\n",
      "Epoch: 3/5, Loss: 0.003654323285445571\n",
      "Epoch: 3/5, Loss: 0.025647522881627083\n",
      "Epoch: 3/5, Loss: 0.012028945609927177\n",
      "Epoch: 3/5, Loss: 0.02888445556163788\n",
      "Epoch: 3/5, Loss: 0.00494164414703846\n",
      "Epoch: 3/5, Loss: 0.02610582672059536\n",
      "Epoch: 3/5, Loss: 0.019808445125818253\n",
      "Epoch: 3/5, Loss: 0.007966907694935799\n",
      "Epoch: 3/5, Loss: 0.015302150510251522\n",
      "Epoch: 3/5, Loss: 0.006563331000506878\n",
      "Epoch: 3/5, Loss: 0.019138816744089127\n",
      "Epoch: 3/5, Loss: 0.025057567283511162\n",
      "Epoch: 3/5, Loss: 0.025350049138069153\n",
      "Epoch: 3/5, Loss: 0.01795222796499729\n",
      "Epoch: 3/5, Loss: 0.07275094836950302\n",
      "Epoch: 3/5, Loss: 0.01997504010796547\n",
      "Epoch: 3/5, Loss: 0.0391598679125309\n",
      "Epoch: 3/5, Loss: 0.009780188091099262\n",
      "Epoch: 3/5, Loss: 0.008884974755346775\n",
      "Epoch: 3/5, Loss: 0.03751842677593231\n",
      "Epoch: 3/5, Loss: 0.02632073685526848\n",
      "Epoch: 3/5, Loss: 0.0037730548065155745\n",
      "Epoch: 3/5, Loss: 0.009543766267597675\n",
      "Epoch: 3/5, Loss: 0.006189383566379547\n",
      "Epoch: 3/5, Loss: 0.03254956007003784\n",
      "Epoch: 3/5, Loss: 0.025295982137322426\n",
      "Epoch: 3/5, Loss: 0.010908683761954308\n",
      "Epoch: 3/5, Loss: 0.06402646750211716\n",
      "Epoch: 3/5, Loss: 0.038309574127197266\n",
      "Epoch: 3/5, Loss: 0.035205941647291183\n",
      "Epoch: 3/5, Loss: 0.013018228113651276\n",
      "Epoch: 3/5, Loss: 0.003429530654102564\n",
      "Epoch: 3/5, Loss: 0.056792207062244415\n",
      "Epoch: 3/5, Loss: 0.019076034426689148\n",
      "Epoch: 3/5, Loss: 0.024909550324082375\n",
      "Epoch: 3/5, Loss: 0.015518462285399437\n",
      "Epoch: 3/5, Loss: 0.0341048464179039\n",
      "Epoch: 3/5, Loss: 0.017883937805891037\n",
      "Epoch: 3/5, Loss: 0.028469005599617958\n",
      "Epoch: 3/5, Loss: 0.11650262773036957\n",
      "Epoch: 3/5, Loss: 0.021006494760513306\n",
      "Epoch: 3/5, Loss: 0.00565868616104126\n",
      "Epoch: 3/5, Loss: 0.02262522280216217\n",
      "Epoch: 3/5, Loss: 0.014409409835934639\n",
      "Epoch: 3/5, Loss: 0.01780853234231472\n",
      "Epoch: 3/5, Loss: 0.017808256670832634\n",
      "Epoch: 3/5, Loss: 0.004368786700069904\n",
      "Epoch: 3/5, Loss: 0.0070901610888540745\n",
      "Epoch: 3/5, Loss: 0.024091117084026337\n",
      "Epoch: 3/5, Loss: 0.03212463855743408\n",
      "Epoch: 3/5, Loss: 0.026232335716485977\n",
      "Epoch: 3/5, Loss: 0.010987840592861176\n",
      "Epoch: 3/5, Loss: 0.01874007284641266\n",
      "Epoch: 3/5, Loss: 0.02337181754410267\n",
      "Epoch: 3/5, Loss: 0.018541701138019562\n",
      "Epoch: 3/5, Loss: 0.011600406840443611\n",
      "Epoch: 3/5, Loss: 0.012383254244923592\n",
      "Epoch: 3/5, Loss: 0.02186841517686844\n",
      "Epoch: 3/5, Loss: 0.012794913724064827\n",
      "Epoch: 3/5, Loss: 0.02970239147543907\n",
      "Epoch: 3/5, Loss: 0.049054499715566635\n",
      "Epoch: 3/5, Loss: 0.023404086008667946\n",
      "Epoch: 3/5, Loss: 0.002503692638128996\n",
      "Epoch: 3/5, Loss: 0.0211307555437088\n",
      "Epoch: 3/5, Loss: 0.006984105333685875\n",
      "Epoch: 3/5, Loss: 0.0116813313215971\n",
      "Epoch: 3/5, Loss: 0.021757587790489197\n",
      "Epoch: 3/5, Loss: 0.012309843674302101\n",
      "Epoch: 3/5, Loss: 0.013231243938207626\n",
      "Epoch: 3/5, Loss: 0.0038560619577765465\n",
      "Epoch: 3/5, Loss: 0.030797040089964867\n",
      "Epoch: 3/5, Loss: 0.015244483947753906\n",
      "Epoch: 3/5, Loss: 0.031313978135585785\n",
      "Epoch: 3/5, Loss: 0.0029191288631409407\n",
      "Epoch: 3/5, Loss: 0.02307254448533058\n",
      "Epoch: 3/5, Loss: 0.011143030598759651\n",
      "Epoch: 3/5, Loss: 0.03133000433444977\n",
      "Epoch: 3/5, Loss: 0.022525951266288757\n",
      "Epoch: 3/5, Loss: 0.026547959074378014\n",
      "Epoch: 3/5, Loss: 0.012803390622138977\n",
      "Epoch: 3/5, Loss: 0.005925857927650213\n",
      "Epoch: 3/5, Loss: 0.011640078388154507\n",
      "Epoch: 3/5, Loss: 0.0066416896879673\n",
      "Epoch: 3/5, Loss: 0.02300398424267769\n",
      "Epoch: 3/5, Loss: 0.0029924733098596334\n",
      "Epoch: 3/5, Loss: 0.036071453243494034\n",
      "Epoch: 3/5, Loss: 0.015856020152568817\n",
      "Epoch: 3/5, Loss: 0.004990465007722378\n",
      "Epoch: 3/5, Loss: 0.00976816937327385\n",
      "Epoch: 3/5, Loss: 0.034529414027929306\n",
      "Epoch: 3/5, Loss: 0.0038413903675973415\n",
      "Epoch: 3/5, Loss: 0.006145927589386702\n",
      "Epoch: 3/5, Loss: 0.005154183134436607\n",
      "Epoch: 3/5, Loss: 0.00299253361299634\n",
      "Epoch: 3/5, Loss: 0.004050306044518948\n",
      "Epoch: 3/5, Loss: 0.012838253751397133\n",
      "Epoch: 3/5, Loss: 0.00815514475107193\n",
      "Epoch: 3/5, Loss: 0.0400996133685112\n",
      "Epoch: 3/5, Loss: 0.0014865195844322443\n",
      "Epoch: 3/5, Loss: 0.03193577751517296\n",
      "Epoch: 3/5, Loss: 0.035523608326911926\n",
      "Epoch: 3/5, Loss: 0.033210184425115585\n",
      "Epoch: 3/5, Loss: 0.01848553493618965\n",
      "Epoch: 3/5, Loss: 0.008755235001444817\n",
      "Epoch: 3/5, Loss: 0.013340633362531662\n",
      "Epoch: 3/5, Loss: 0.002702622441574931\n",
      "Epoch: 3/5, Loss: 0.05435153841972351\n",
      "Epoch: 3/5, Loss: 0.05688951164484024\n",
      "Epoch: 3/5, Loss: 0.006813328713178635\n",
      "Epoch: 3/5, Loss: 0.007328292820602655\n",
      "Epoch: 3/5, Loss: 0.0236445814371109\n",
      "Epoch: 3/5, Loss: 0.023712966591119766\n",
      "Epoch: 3/5, Loss: 0.002917245263233781\n",
      "Epoch: 3/5, Loss: 0.006974526681005955\n",
      "Epoch: 3/5, Loss: 0.02932513691484928\n",
      "Epoch: 3/5, Loss: 0.026591593399643898\n",
      "Epoch: 3/5, Loss: 0.003388006240129471\n",
      "Epoch: 3/5, Loss: 0.017015833407640457\n",
      "Epoch: 3/5, Loss: 0.03405427187681198\n",
      "Epoch: 3/5, Loss: 0.008902395144104958\n",
      "Epoch: 3/5, Loss: 0.01610197126865387\n",
      "Epoch: 3/5, Loss: 0.004783598706126213\n",
      "Epoch: 3/5, Loss: 0.026095407083630562\n",
      "Epoch: 3/5, Loss: 0.021532563492655754\n",
      "Epoch: 3/5, Loss: 0.0009078973671421409\n",
      "Epoch: 3/5, Loss: 0.04518008232116699\n",
      "Epoch: 3/5, Loss: 0.027911540120840073\n",
      "Epoch: 3/5, Loss: 0.018964577466249466\n",
      "Epoch: 3/5, Loss: 0.02466515451669693\n",
      "Epoch: 3/5, Loss: 0.0018540206365287304\n",
      "Epoch: 3/5, Loss: 0.010499035939574242\n",
      "Epoch: 3/5, Loss: 0.010753389447927475\n",
      "Epoch: 3/5, Loss: 0.03490149974822998\n",
      "Epoch: 3/5, Loss: 0.0014087855815887451\n",
      "Epoch: 3/5, Loss: 0.014781223610043526\n",
      "Epoch: 3/5, Loss: 0.010985208675265312\n",
      "Epoch: 3/5, Loss: 0.007958524860441685\n",
      "Epoch: 3/5, Loss: 0.01915263757109642\n",
      "Epoch: 3/5, Loss: 0.036205679178237915\n",
      "Epoch: 3/5, Loss: 0.008745366707444191\n",
      "Epoch: 3/5, Loss: 0.0037014400586485863\n",
      "Epoch: 3/5, Loss: 0.008839462883770466\n",
      "Epoch: 3/5, Loss: 0.03376017510890961\n",
      "Epoch: 3/5, Loss: 0.022232098504900932\n",
      "Epoch: 3/5, Loss: 0.004017955623567104\n",
      "Epoch: 3/5, Loss: 0.01592467725276947\n",
      "Epoch: 3/5, Loss: 0.011047948151826859\n",
      "Epoch: 3/5, Loss: 0.013557972386479378\n",
      "Epoch: 3/5, Loss: 0.039300587028265\n",
      "Epoch: 3/5, Loss: 0.008240043185651302\n",
      "Epoch: 3/5, Loss: 0.0027255741879343987\n",
      "Epoch: 3/5, Loss: 0.005803287494927645\n",
      "Epoch: 3/5, Loss: 0.02305857464671135\n",
      "Epoch: 3/5, Loss: 0.011761428788304329\n",
      "Epoch: 3/5, Loss: 0.007873729802668095\n",
      "Epoch: 3/5, Loss: 0.01883688010275364\n",
      "Epoch: 3/5, Loss: 0.014022359624505043\n",
      "Epoch: 3/5, Loss: 0.01704610325396061\n",
      "Epoch: 3/5, Loss: 0.05659475177526474\n",
      "Epoch: 3/5, Loss: 0.006801518611609936\n",
      "Epoch: 3/5, Loss: 0.013231812976300716\n",
      "Epoch: 3/5, Loss: 0.015765786170959473\n",
      "Epoch: 3/5, Loss: 0.009206373244524002\n",
      "Epoch: 3/5, Loss: 0.0070425826124846935\n",
      "Epoch: 3/5, Loss: 0.021585550159215927\n",
      "Epoch: 3/5, Loss: 0.024304736405611038\n",
      "Epoch: 3/5, Loss: 0.012149814516305923\n",
      "Epoch: 3/5, Loss: 0.02050985023379326\n",
      "Epoch: 3/5, Loss: 0.028720656409859657\n",
      "Epoch: 3/5, Loss: 0.019017359241843224\n",
      "Epoch: 3/5, Loss: 0.03546452522277832\n",
      "Epoch: 3/5, Loss: 0.00936880148947239\n",
      "Epoch: 3/5, Loss: 0.01435532234609127\n",
      "Epoch: 3/5, Loss: 0.008814585395157337\n",
      "Epoch: 3/5, Loss: 0.011984691023826599\n",
      "Epoch: 3/5, Loss: 0.013562461361289024\n",
      "Epoch: 3/5, Loss: 0.021491775289177895\n",
      "Epoch: 3/5, Loss: 0.009020534344017506\n",
      "Epoch: 3/5, Loss: 0.054759249091148376\n",
      "Epoch: 3/5, Loss: 0.07589291781187057\n",
      "Epoch: 3/5, Loss: 0.018964461982250214\n",
      "Epoch: 3/5, Loss: 0.011114655993878841\n",
      "Epoch: 3/5, Loss: 0.00859289150685072\n",
      "Epoch: 3/5, Loss: 0.023657215759158134\n",
      "Epoch: 3/5, Loss: 0.04269899055361748\n",
      "Epoch: 3/5, Loss: 0.0475282296538353\n",
      "Epoch: 3/5, Loss: 0.015134112909436226\n",
      "Epoch: 3/5, Loss: 0.01733802817761898\n",
      "Epoch: 3/5, Loss: 0.03812558203935623\n",
      "Epoch: 3/5, Loss: 0.01941913552582264\n",
      "Epoch: 3/5, Loss: 0.019307982176542282\n",
      "Epoch: 3/5, Loss: 0.0068765440955758095\n",
      "Epoch: 3/5, Loss: 0.00682557187974453\n",
      "Epoch: 3/5, Loss: 0.0037139062769711018\n",
      "Epoch: 3/5, Loss: 0.11403767019510269\n",
      "Epoch: 3/5, Loss: 0.02565179392695427\n",
      "Epoch: 3/5, Loss: 0.015097353607416153\n",
      "Epoch: 3/5, Loss: 0.03346503525972366\n",
      "Epoch: 3/5, Loss: 0.029421864077448845\n",
      "Epoch: 3/5, Loss: 0.008726456202566624\n",
      "Epoch: 3/5, Loss: 0.02130945585668087\n",
      "Epoch: 3/5, Loss: 0.016626901924610138\n",
      "Epoch: 3/5, Loss: 0.02577371895313263\n",
      "Epoch: 3/5, Loss: 0.011255525052547455\n",
      "Epoch: 3/5, Loss: 0.03735705837607384\n",
      "Epoch: 3/5, Loss: 0.02425030805170536\n",
      "Epoch: 3/5, Loss: 0.012449568137526512\n",
      "Epoch: 3/5, Loss: 0.008574357256293297\n",
      "Epoch: 3/5, Loss: 0.0342411994934082\n",
      "Epoch: 3/5, Loss: 0.03407801687717438\n",
      "Epoch: 3/5, Loss: 0.011538577266037464\n",
      "Epoch: 3/5, Loss: 0.06942559778690338\n",
      "Epoch: 3/5, Loss: 0.01778808981180191\n",
      "Epoch: 3/5, Loss: 0.011082135140895844\n",
      "Epoch: 3/5, Loss: 0.007037579081952572\n",
      "Epoch: 3/5, Loss: 0.0012582505587488413\n",
      "Epoch: 3/5, Loss: 0.028055675327777863\n",
      "Epoch: 3/5, Loss: 0.03186697140336037\n",
      "Epoch: 3/5, Loss: 0.009075279347598553\n",
      "Epoch: 3/5, Loss: 0.043086156249046326\n",
      "Epoch: 3/5, Loss: 0.019105974584817886\n",
      "Epoch: 3/5, Loss: 0.024311117827892303\n",
      "Epoch: 3/5, Loss: 0.009029580280184746\n",
      "Epoch: 3/5, Loss: 0.03407679498195648\n",
      "Epoch: 3/5, Loss: 0.012970016337931156\n",
      "Epoch: 3/5, Loss: 0.021106943488121033\n",
      "Epoch: 3/5, Loss: 0.0075708189979195595\n",
      "Epoch: 3/5, Loss: 0.021603094413876534\n",
      "Epoch: 3/5, Loss: 0.01718294993042946\n",
      "Epoch: 3/5, Loss: 0.016186412423849106\n",
      "Epoch: 3/5, Loss: 0.03519024699926376\n",
      "Epoch: 3/5, Loss: 0.018745068460702896\n",
      "Epoch: 3/5, Loss: 0.012659349478781223\n",
      "Epoch: 3/5, Loss: 0.0162024088203907\n",
      "Epoch: 3/5, Loss: 0.021120937541127205\n",
      "Epoch: 3/5, Loss: 0.0024102383758872747\n",
      "Epoch: 3/5, Loss: 0.023115724325180054\n",
      "Epoch: 3/5, Loss: 0.017390256747603416\n",
      "Epoch: 3/5, Loss: 0.009815198369324207\n",
      "Epoch: 3/5, Loss: 0.0070677404291927814\n",
      "Epoch: 3/5, Loss: 0.025923345237970352\n",
      "Epoch: 3/5, Loss: 0.01693093404173851\n",
      "Epoch: 3/5, Loss: 0.0172283835709095\n",
      "Epoch: 3/5, Loss: 0.056071825325489044\n",
      "Epoch: 3/5, Loss: 0.008475234732031822\n",
      "Epoch: 3/5, Loss: 0.015441366471350193\n",
      "Epoch: 3/5, Loss: 0.015304895117878914\n",
      "Epoch: 3/5, Loss: 0.04802275821566582\n",
      "Epoch: 3/5, Loss: 0.012478151358664036\n",
      "Epoch: 3/5, Loss: 0.004198063630610704\n",
      "Epoch: 3/5, Loss: 0.014924228191375732\n",
      "Epoch: 3/5, Loss: 0.017118409276008606\n",
      "Epoch: 3/5, Loss: 0.010450266301631927\n",
      "Epoch: 3/5, Loss: 0.061786193400621414\n",
      "Epoch: 3/5, Loss: 0.006440909579396248\n",
      "Epoch: 3/5, Loss: 0.01753372699022293\n",
      "Epoch: 3/5, Loss: 0.030043596401810646\n",
      "Epoch: 3/5, Loss: 0.015817172825336456\n",
      "Epoch: 3/5, Loss: 0.010222665965557098\n",
      "Epoch: 3/5, Loss: 0.04270848631858826\n",
      "Epoch: 3/5, Loss: 0.009543223306536674\n",
      "Epoch: 3/5, Loss: 0.031256429851055145\n",
      "Epoch: 3/5, Loss: 0.009198617190122604\n",
      "Epoch: 3/5, Loss: 0.0015566976508125663\n",
      "Epoch: 3/5, Loss: 0.018909135833382607\n",
      "Epoch: 3/5, Loss: 0.038115426898002625\n",
      "Epoch: 3/5, Loss: 0.018132884055376053\n",
      "Epoch: 3/5, Loss: 0.009382076561450958\n",
      "Epoch: 3/5, Loss: 0.02827388234436512\n",
      "Epoch: 3/5, Loss: 0.01903507485985756\n",
      "Epoch: 3/5, Loss: 0.012340432032942772\n",
      "Epoch: 3/5, Loss: 0.03487744182348251\n",
      "Epoch: 3/5, Loss: 0.006325740832835436\n",
      "Epoch: 3/5, Loss: 0.016442803665995598\n",
      "Epoch: 3/5, Loss: 0.010487787425518036\n",
      "Epoch: 3/5, Loss: 0.003773958422243595\n",
      "Epoch: 3/5, Loss: 0.013413676992058754\n",
      "Epoch: 3/5, Loss: 0.005881907418370247\n",
      "Epoch: 3/5, Loss: 0.021426329389214516\n",
      "Epoch: 3/5, Loss: 0.02895536832511425\n",
      "Epoch: 3/5, Loss: 0.011306562460958958\n",
      "Epoch: 3/5, Loss: 0.0038634464144706726\n",
      "Epoch: 3/5, Loss: 0.017331242561340332\n",
      "Epoch: 3/5, Loss: 0.023939527571201324\n",
      "Epoch: 3/5, Loss: 0.01136080827564001\n",
      "Epoch: 3/5, Loss: 0.0246097631752491\n",
      "Epoch: 3/5, Loss: 0.04832148179411888\n",
      "Epoch: 3/5, Loss: 0.01751912198960781\n",
      "Epoch: 3/5, Loss: 0.006603711284697056\n",
      "Epoch: 3/5, Loss: 0.027547089383006096\n",
      "Epoch: 3/5, Loss: 0.01606258563697338\n",
      "Epoch: 3/5, Loss: 0.034826040267944336\n",
      "Epoch: 3/5, Loss: 0.01910921186208725\n",
      "Epoch: 3/5, Loss: 0.037484992295503616\n",
      "Epoch: 3/5, Loss: 0.035164713859558105\n",
      "Epoch: 3/5, Loss: 0.004834535997360945\n",
      "Epoch: 3/5, Loss: 0.03665311634540558\n",
      "Epoch: 3/5, Loss: 0.05791151896119118\n",
      "Epoch: 3/5, Loss: 0.009953226894140244\n",
      "Epoch: 3/5, Loss: 0.016386745497584343\n",
      "Epoch: 3/5, Loss: 0.011562569066882133\n",
      "Epoch: 3/5, Loss: 0.03586672991514206\n",
      "Epoch: 3/5, Loss: 0.013008705340325832\n",
      "Epoch: 3/5, Loss: 0.011328823864459991\n",
      "Epoch: 3/5, Loss: 0.0176745243370533\n",
      "Epoch: 3/5, Loss: 0.012003010138869286\n",
      "Epoch: 3/5, Loss: 0.005884780082851648\n",
      "Epoch: 3/5, Loss: 0.0876595601439476\n",
      "Epoch: 3/5, Loss: 0.004517101217061281\n",
      "Epoch: 3/5, Loss: 0.028629563748836517\n",
      "Epoch: 3/5, Loss: 0.0016233471687883139\n",
      "Epoch: 3/5, Loss: 0.018380990251898766\n",
      "Epoch: 3/5, Loss: 0.019611256197094917\n",
      "Epoch: 3/5, Loss: 0.0171454269438982\n",
      "Epoch: 3/5, Loss: 0.002344215754419565\n",
      "Epoch: 4/5, Loss: 0.009991765953600407\n",
      "Epoch: 4/5, Loss: 0.007462987210601568\n",
      "Epoch: 4/5, Loss: 0.021015100181102753\n",
      "Epoch: 4/5, Loss: 0.026820486411452293\n",
      "Epoch: 4/5, Loss: 0.014589428901672363\n",
      "Epoch: 4/5, Loss: 0.001693320693448186\n",
      "Epoch: 4/5, Loss: 0.008098755963146687\n",
      "Epoch: 4/5, Loss: 0.0198961291462183\n",
      "Epoch: 4/5, Loss: 0.009119800291955471\n",
      "Epoch: 4/5, Loss: 0.02851700223982334\n",
      "Epoch: 4/5, Loss: 0.01369408331811428\n",
      "Epoch: 4/5, Loss: 0.01877819374203682\n",
      "Epoch: 4/5, Loss: 0.007441999390721321\n",
      "Epoch: 4/5, Loss: 0.02848668023943901\n",
      "Epoch: 4/5, Loss: 0.018724625930190086\n",
      "Epoch: 4/5, Loss: 0.009824031963944435\n",
      "Epoch: 4/5, Loss: 0.03116331808269024\n",
      "Epoch: 4/5, Loss: 0.039639879018068314\n",
      "Epoch: 4/5, Loss: 0.03934391960501671\n",
      "Epoch: 4/5, Loss: 0.0067809997126460075\n",
      "Epoch: 4/5, Loss: 0.033866818994283676\n",
      "Epoch: 4/5, Loss: 0.02413453906774521\n",
      "Epoch: 4/5, Loss: 0.019201770424842834\n",
      "Epoch: 4/5, Loss: 0.035396330058574677\n",
      "Epoch: 4/5, Loss: 0.025691479444503784\n",
      "Epoch: 4/5, Loss: 0.03545646369457245\n",
      "Epoch: 4/5, Loss: 0.022821800783276558\n",
      "Epoch: 4/5, Loss: 0.04369248449802399\n",
      "Epoch: 4/5, Loss: 0.04555773362517357\n",
      "Epoch: 4/5, Loss: 0.010539906099438667\n",
      "Epoch: 4/5, Loss: 0.055829282850027084\n",
      "Epoch: 4/5, Loss: 0.019792109727859497\n",
      "Epoch: 4/5, Loss: 0.015410931780934334\n",
      "Epoch: 4/5, Loss: 0.01707119680941105\n",
      "Epoch: 4/5, Loss: 0.003440926084294915\n",
      "Epoch: 4/5, Loss: 0.002475047018378973\n",
      "Epoch: 4/5, Loss: 0.00023909483570605516\n",
      "Epoch: 4/5, Loss: 0.023440025746822357\n",
      "Epoch: 4/5, Loss: 0.008105921559035778\n",
      "Epoch: 4/5, Loss: 0.012405956164002419\n",
      "Epoch: 4/5, Loss: 0.011741295456886292\n",
      "Epoch: 4/5, Loss: 0.022961124777793884\n",
      "Epoch: 4/5, Loss: 0.02005201391875744\n",
      "Epoch: 4/5, Loss: 0.022168103605508804\n",
      "Epoch: 4/5, Loss: 0.02244688756763935\n",
      "Epoch: 4/5, Loss: 0.017025675624608994\n",
      "Epoch: 4/5, Loss: 0.013243877328932285\n",
      "Epoch: 4/5, Loss: 0.01747458428144455\n",
      "Epoch: 4/5, Loss: 0.015640104189515114\n",
      "Epoch: 4/5, Loss: 0.041180774569511414\n",
      "Epoch: 4/5, Loss: 0.024779628962278366\n",
      "Epoch: 4/5, Loss: 0.012156510725617409\n",
      "Epoch: 4/5, Loss: 0.023546410724520683\n",
      "Epoch: 4/5, Loss: 0.040052320808172226\n",
      "Epoch: 4/5, Loss: 0.02563503198325634\n",
      "Epoch: 4/5, Loss: 0.028799766674637794\n",
      "Epoch: 4/5, Loss: 0.01137039065361023\n",
      "Epoch: 4/5, Loss: 0.009357394650578499\n",
      "Epoch: 4/5, Loss: 0.008070091716945171\n",
      "Epoch: 4/5, Loss: 0.0013125489931553602\n",
      "Epoch: 4/5, Loss: 0.007031072396785021\n",
      "Epoch: 4/5, Loss: 0.020391684025526047\n",
      "Epoch: 4/5, Loss: 0.03701679781079292\n",
      "Epoch: 4/5, Loss: 0.018232418224215508\n",
      "Epoch: 4/5, Loss: 0.01166648417711258\n",
      "Epoch: 4/5, Loss: 0.0329778678715229\n",
      "Epoch: 4/5, Loss: 0.02114218659698963\n",
      "Epoch: 4/5, Loss: 0.009732620790600777\n",
      "Epoch: 4/5, Loss: 0.007510420400649309\n",
      "Epoch: 4/5, Loss: 0.043317653238773346\n",
      "Epoch: 4/5, Loss: 0.009204410947859287\n",
      "Epoch: 4/5, Loss: 0.024699339643120766\n",
      "Epoch: 4/5, Loss: 0.05423799902200699\n",
      "Epoch: 4/5, Loss: 0.006600158754736185\n",
      "Epoch: 4/5, Loss: 0.05184290558099747\n",
      "Epoch: 4/5, Loss: 0.009039238095283508\n",
      "Epoch: 4/5, Loss: 0.0065214503556489944\n",
      "Epoch: 4/5, Loss: 0.014169640839099884\n",
      "Epoch: 4/5, Loss: 0.0041986312717199326\n",
      "Epoch: 4/5, Loss: 0.009774508886039257\n",
      "Epoch: 4/5, Loss: 0.022706570103764534\n",
      "Epoch: 4/5, Loss: 0.013428867794573307\n",
      "Epoch: 4/5, Loss: 0.00419044541195035\n",
      "Epoch: 4/5, Loss: 0.008364134468138218\n",
      "Epoch: 4/5, Loss: 0.002425295999273658\n",
      "Epoch: 4/5, Loss: 0.010886801406741142\n",
      "Epoch: 4/5, Loss: 0.013872267678380013\n",
      "Epoch: 4/5, Loss: 0.024451768025755882\n",
      "Epoch: 4/5, Loss: 0.0169094018638134\n",
      "Epoch: 4/5, Loss: 0.010846735909581184\n",
      "Epoch: 4/5, Loss: 0.03190426155924797\n",
      "Epoch: 4/5, Loss: 0.02485818788409233\n",
      "Epoch: 4/5, Loss: 0.009007730521261692\n",
      "Epoch: 4/5, Loss: 0.031146084889769554\n",
      "Epoch: 4/5, Loss: 0.03398735821247101\n",
      "Epoch: 4/5, Loss: 0.03255871683359146\n",
      "Epoch: 4/5, Loss: 0.002750470768660307\n",
      "Epoch: 4/5, Loss: 0.02279304526746273\n",
      "Epoch: 4/5, Loss: 0.022022152319550514\n",
      "Epoch: 4/5, Loss: 0.02222527377307415\n",
      "Epoch: 4/5, Loss: 0.009345384314656258\n",
      "Epoch: 4/5, Loss: 0.007060968317091465\n",
      "Epoch: 4/5, Loss: 0.010685457848012447\n",
      "Epoch: 4/5, Loss: 0.02177155576646328\n",
      "Epoch: 4/5, Loss: 0.013338552787899971\n",
      "Epoch: 4/5, Loss: 0.011991972103714943\n",
      "Epoch: 4/5, Loss: 0.009485991671681404\n",
      "Epoch: 4/5, Loss: 0.004477926529943943\n",
      "Epoch: 4/5, Loss: 0.030350958928465843\n",
      "Epoch: 4/5, Loss: 0.011132735759019852\n",
      "Epoch: 4/5, Loss: 0.037642352283000946\n",
      "Epoch: 4/5, Loss: 0.022329159080982208\n",
      "Epoch: 4/5, Loss: 0.0061554620042443275\n",
      "Epoch: 4/5, Loss: 0.00865903403609991\n",
      "Epoch: 4/5, Loss: 0.007201375439763069\n",
      "Epoch: 4/5, Loss: 0.022561369463801384\n",
      "Epoch: 4/5, Loss: 0.004541872069239616\n",
      "Epoch: 4/5, Loss: 0.013650746084749699\n",
      "Epoch: 4/5, Loss: 0.04298310726881027\n",
      "Epoch: 4/5, Loss: 0.0080146798864007\n",
      "Epoch: 4/5, Loss: 0.014779516495764256\n",
      "Epoch: 4/5, Loss: 0.03507174178957939\n",
      "Epoch: 4/5, Loss: 0.0748482346534729\n",
      "Epoch: 4/5, Loss: 0.006935925222933292\n",
      "Epoch: 4/5, Loss: 0.0023387963883578777\n",
      "Epoch: 4/5, Loss: 0.00855582021176815\n",
      "Epoch: 4/5, Loss: 0.01685832068324089\n",
      "Epoch: 4/5, Loss: 0.0162538830190897\n",
      "Epoch: 4/5, Loss: 0.037658434361219406\n",
      "Epoch: 4/5, Loss: 0.018126465380191803\n",
      "Epoch: 4/5, Loss: 0.014106059446930885\n",
      "Epoch: 4/5, Loss: 0.002570477547124028\n",
      "Epoch: 4/5, Loss: 0.021891852840781212\n",
      "Epoch: 4/5, Loss: 0.011848613619804382\n",
      "Epoch: 4/5, Loss: 0.006571474485099316\n",
      "Epoch: 4/5, Loss: 0.03635898232460022\n",
      "Epoch: 4/5, Loss: 0.004665947984904051\n",
      "Epoch: 4/5, Loss: 0.058663882315158844\n",
      "Epoch: 4/5, Loss: 0.04265213757753372\n",
      "Epoch: 4/5, Loss: 0.0077360630966722965\n",
      "Epoch: 4/5, Loss: 0.005018991883844137\n",
      "Epoch: 4/5, Loss: 0.0028614606708288193\n",
      "Epoch: 4/5, Loss: 0.02389385551214218\n",
      "Epoch: 4/5, Loss: 0.01183104794472456\n",
      "Epoch: 4/5, Loss: 0.03494144231081009\n",
      "Epoch: 4/5, Loss: 0.005607467144727707\n",
      "Epoch: 4/5, Loss: 0.029031870886683464\n",
      "Epoch: 4/5, Loss: 0.011714182794094086\n",
      "Epoch: 4/5, Loss: 0.018061427399516106\n",
      "Epoch: 4/5, Loss: 0.0030098033603280783\n",
      "Epoch: 4/5, Loss: 0.011825276538729668\n",
      "Epoch: 4/5, Loss: 0.031636908650398254\n",
      "Epoch: 4/5, Loss: 0.060076046735048294\n",
      "Epoch: 4/5, Loss: 0.021762903779745102\n",
      "Epoch: 4/5, Loss: 0.01704150065779686\n",
      "Epoch: 4/5, Loss: 0.0038698327261954546\n",
      "Epoch: 4/5, Loss: 0.011733573861420155\n",
      "Epoch: 4/5, Loss: 0.030023489147424698\n",
      "Epoch: 4/5, Loss: 0.01967550255358219\n",
      "Epoch: 4/5, Loss: 0.004879087209701538\n",
      "Epoch: 4/5, Loss: 0.03826361894607544\n",
      "Epoch: 4/5, Loss: 0.037694331258535385\n",
      "Epoch: 4/5, Loss: 0.038871828466653824\n",
      "Epoch: 4/5, Loss: 0.01573440246284008\n",
      "Epoch: 4/5, Loss: 0.01649228110909462\n",
      "Epoch: 4/5, Loss: 0.005868381354957819\n",
      "Epoch: 4/5, Loss: 0.014283345080912113\n",
      "Epoch: 4/5, Loss: 0.015231846831738949\n",
      "Epoch: 4/5, Loss: 0.00983473751693964\n",
      "Epoch: 4/5, Loss: 0.00934096984565258\n",
      "Epoch: 4/5, Loss: 0.0010720579884946346\n",
      "Epoch: 4/5, Loss: 0.03213154897093773\n",
      "Epoch: 4/5, Loss: 0.0044147246517241\n",
      "Epoch: 4/5, Loss: 0.03717345744371414\n",
      "Epoch: 4/5, Loss: 0.015540782362222672\n",
      "Epoch: 4/5, Loss: 0.017120426520705223\n",
      "Epoch: 4/5, Loss: 0.008405526168644428\n",
      "Epoch: 4/5, Loss: 0.022577792406082153\n",
      "Epoch: 4/5, Loss: 0.02085583284497261\n",
      "Epoch: 4/5, Loss: 0.009895073249936104\n",
      "Epoch: 4/5, Loss: 0.009801283478736877\n",
      "Epoch: 4/5, Loss: 0.04196697473526001\n",
      "Epoch: 4/5, Loss: 0.014879096299409866\n",
      "Epoch: 4/5, Loss: 0.021444393321871758\n",
      "Epoch: 4/5, Loss: 0.013444140553474426\n",
      "Epoch: 4/5, Loss: 0.012502148747444153\n",
      "Epoch: 4/5, Loss: 0.04089897871017456\n",
      "Epoch: 4/5, Loss: 0.045141443610191345\n",
      "Epoch: 4/5, Loss: 0.017390098422765732\n",
      "Epoch: 4/5, Loss: 0.011439809575676918\n",
      "Epoch: 4/5, Loss: 0.01405314914882183\n",
      "Epoch: 4/5, Loss: 0.006933099590241909\n",
      "Epoch: 4/5, Loss: 0.008922062814235687\n",
      "Epoch: 4/5, Loss: 0.033703312277793884\n",
      "Epoch: 4/5, Loss: 0.019962603226304054\n",
      "Epoch: 4/5, Loss: 0.014464130625128746\n",
      "Epoch: 4/5, Loss: 0.07362861186265945\n",
      "Epoch: 4/5, Loss: 0.018873758614063263\n",
      "Epoch: 4/5, Loss: 0.05218683183193207\n",
      "Epoch: 4/5, Loss: 0.04038373380899429\n",
      "Epoch: 4/5, Loss: 0.022150713950395584\n",
      "Epoch: 4/5, Loss: 0.007747297640889883\n",
      "Epoch: 4/5, Loss: 0.021517392247915268\n",
      "Epoch: 4/5, Loss: 0.011086609214544296\n",
      "Epoch: 4/5, Loss: 0.00873095728456974\n",
      "Epoch: 4/5, Loss: 0.00834803655743599\n",
      "Epoch: 4/5, Loss: 0.01595522090792656\n",
      "Epoch: 4/5, Loss: 0.0239810012280941\n",
      "Epoch: 4/5, Loss: 0.016208987683057785\n",
      "Epoch: 4/5, Loss: 0.01882258430123329\n",
      "Epoch: 4/5, Loss: 0.050110843032598495\n",
      "Epoch: 4/5, Loss: 0.018244510516524315\n",
      "Epoch: 4/5, Loss: 0.02547748014330864\n",
      "Epoch: 4/5, Loss: 0.016513491049408913\n",
      "Epoch: 4/5, Loss: 0.009806016460061073\n",
      "Epoch: 4/5, Loss: 0.007736639119684696\n",
      "Epoch: 4/5, Loss: 0.018692636862397194\n",
      "Epoch: 4/5, Loss: 0.01796581596136093\n",
      "Epoch: 4/5, Loss: 0.019979387521743774\n",
      "Epoch: 4/5, Loss: 0.017489979043602943\n",
      "Epoch: 4/5, Loss: 0.024294784292578697\n",
      "Epoch: 4/5, Loss: 0.0053734127432107925\n",
      "Epoch: 4/5, Loss: 0.03702496737241745\n",
      "Epoch: 4/5, Loss: 0.027043603360652924\n",
      "Epoch: 4/5, Loss: 0.002640148624777794\n",
      "Epoch: 4/5, Loss: 0.011187313124537468\n",
      "Epoch: 4/5, Loss: 0.014240016229450703\n",
      "Epoch: 4/5, Loss: 0.016792722046375275\n",
      "Epoch: 4/5, Loss: 0.004219088237732649\n",
      "Epoch: 4/5, Loss: 0.007172225043177605\n",
      "Epoch: 4/5, Loss: 0.012944405898451805\n",
      "Epoch: 4/5, Loss: 0.010139775462448597\n",
      "Epoch: 4/5, Loss: 0.0075796241872012615\n",
      "Epoch: 4/5, Loss: 0.015728630125522614\n",
      "Epoch: 4/5, Loss: 0.0029897913336753845\n",
      "Epoch: 4/5, Loss: 0.005757891107350588\n",
      "Epoch: 4/5, Loss: 0.05042522773146629\n",
      "Epoch: 4/5, Loss: 0.009344610385596752\n",
      "Epoch: 4/5, Loss: 0.022774729877710342\n",
      "Epoch: 4/5, Loss: 0.014586355537176132\n",
      "Epoch: 4/5, Loss: 0.0031119012273848057\n",
      "Epoch: 4/5, Loss: 0.008521124720573425\n",
      "Epoch: 4/5, Loss: 0.009679115377366543\n",
      "Epoch: 4/5, Loss: 0.010883847251534462\n",
      "Epoch: 4/5, Loss: 0.02486441843211651\n",
      "Epoch: 4/5, Loss: 0.08792972564697266\n",
      "Epoch: 4/5, Loss: 0.0178034957498312\n",
      "Epoch: 4/5, Loss: 0.03021899238228798\n",
      "Epoch: 4/5, Loss: 0.015438349917531013\n",
      "Epoch: 4/5, Loss: 0.005459242966026068\n",
      "Epoch: 4/5, Loss: 0.003281674347817898\n",
      "Epoch: 4/5, Loss: 0.007001816760748625\n",
      "Epoch: 4/5, Loss: 0.004250344354659319\n",
      "Epoch: 4/5, Loss: 0.023038022220134735\n",
      "Epoch: 4/5, Loss: 0.05193047225475311\n",
      "Epoch: 4/5, Loss: 0.00265608006156981\n",
      "Epoch: 4/5, Loss: 0.009417915716767311\n",
      "Epoch: 4/5, Loss: 0.011596476659178734\n",
      "Epoch: 4/5, Loss: 0.010958632454276085\n",
      "Epoch: 4/5, Loss: 0.023958221077919006\n",
      "Epoch: 4/5, Loss: 0.017706505954265594\n",
      "Epoch: 4/5, Loss: 0.02759883739054203\n",
      "Epoch: 4/5, Loss: 0.008123231120407581\n",
      "Epoch: 4/5, Loss: 0.05217428132891655\n",
      "Epoch: 4/5, Loss: 0.006657635793089867\n",
      "Epoch: 4/5, Loss: 0.025111619383096695\n",
      "Epoch: 4/5, Loss: 0.002572777681052685\n",
      "Epoch: 4/5, Loss: 0.022770067676901817\n",
      "Epoch: 4/5, Loss: 0.002504294039681554\n",
      "Epoch: 4/5, Loss: 0.013801035471260548\n",
      "Epoch: 4/5, Loss: 0.013930009678006172\n",
      "Epoch: 4/5, Loss: 0.010901032015681267\n",
      "Epoch: 4/5, Loss: 0.02960404008626938\n",
      "Epoch: 4/5, Loss: 0.07611197978258133\n",
      "Epoch: 4/5, Loss: 0.0061812568455934525\n",
      "Epoch: 4/5, Loss: 0.014906036667525768\n",
      "Epoch: 4/5, Loss: 0.010421567596495152\n",
      "Epoch: 4/5, Loss: 0.02220918983221054\n",
      "Epoch: 4/5, Loss: 0.008416250348091125\n",
      "Epoch: 4/5, Loss: 0.01875144988298416\n",
      "Epoch: 4/5, Loss: 0.01732242852449417\n",
      "Epoch: 4/5, Loss: 0.024951905012130737\n",
      "Epoch: 4/5, Loss: 0.008638937026262283\n",
      "Epoch: 4/5, Loss: 0.009059075266122818\n",
      "Epoch: 4/5, Loss: 0.017264097929000854\n",
      "Epoch: 4/5, Loss: 0.015819480642676353\n",
      "Epoch: 4/5, Loss: 0.016706498339772224\n",
      "Epoch: 4/5, Loss: 0.011959373950958252\n",
      "Epoch: 4/5, Loss: 0.02957044541835785\n",
      "Epoch: 4/5, Loss: 0.01034143753349781\n",
      "Epoch: 4/5, Loss: 0.009754355065524578\n",
      "Epoch: 4/5, Loss: 0.027362212538719177\n",
      "Epoch: 4/5, Loss: 0.028885114938020706\n",
      "Epoch: 4/5, Loss: 0.02771122008562088\n",
      "Epoch: 4/5, Loss: 0.013524055480957031\n",
      "Epoch: 4/5, Loss: 0.06457211822271347\n",
      "Epoch: 4/5, Loss: 0.030317937955260277\n",
      "Epoch: 4/5, Loss: 0.020944733172655106\n",
      "Epoch: 4/5, Loss: 0.0038410541601479053\n",
      "Epoch: 4/5, Loss: 0.028922196477651596\n",
      "Epoch: 4/5, Loss: 0.01525594387203455\n",
      "Epoch: 4/5, Loss: 0.019152363762259483\n",
      "Epoch: 4/5, Loss: 0.03252004459500313\n",
      "Epoch: 4/5, Loss: 0.03773288056254387\n",
      "Epoch: 4/5, Loss: 0.038870371878147125\n",
      "Epoch: 4/5, Loss: 0.024785218760371208\n",
      "Epoch: 4/5, Loss: 0.013066600076854229\n",
      "Epoch: 4/5, Loss: 0.009880243800580502\n",
      "Epoch: 4/5, Loss: 0.024330684915184975\n",
      "Epoch: 4/5, Loss: 0.025986474007368088\n",
      "Epoch: 4/5, Loss: 0.008590269833803177\n",
      "Epoch: 4/5, Loss: 0.02002542093396187\n",
      "Epoch: 4/5, Loss: 0.011086104437708855\n",
      "Epoch: 4/5, Loss: 0.018228335306048393\n",
      "Epoch: 4/5, Loss: 0.005745631642639637\n",
      "Epoch: 4/5, Loss: 0.01687147282063961\n",
      "Epoch: 4/5, Loss: 0.021856708452105522\n",
      "Epoch: 4/5, Loss: 0.0006761477561667562\n",
      "Epoch: 4/5, Loss: 0.011069969274103642\n",
      "Epoch: 4/5, Loss: 0.015481345355510712\n",
      "Epoch: 4/5, Loss: 0.013090027496218681\n",
      "Epoch: 4/5, Loss: 0.021764017641544342\n",
      "Epoch: 4/5, Loss: 0.02608034759759903\n",
      "Epoch: 4/5, Loss: 0.023972194641828537\n",
      "Epoch: 4/5, Loss: 0.0290023535490036\n",
      "Epoch: 4/5, Loss: 0.00870867632329464\n",
      "Epoch: 4/5, Loss: 0.027227235957980156\n",
      "Epoch: 4/5, Loss: 0.0024488649796694517\n",
      "Epoch: 4/5, Loss: 0.006530167534947395\n",
      "Epoch: 4/5, Loss: 0.0028051924891769886\n",
      "Epoch: 4/5, Loss: 0.002111993730068207\n",
      "Epoch: 4/5, Loss: 0.016247401013970375\n",
      "Epoch: 4/5, Loss: 0.10218746960163116\n",
      "Epoch: 4/5, Loss: 0.0065778689458966255\n",
      "Epoch: 4/5, Loss: 0.060050830245018005\n",
      "Epoch: 4/5, Loss: 0.010370040312409401\n",
      "Epoch: 4/5, Loss: 0.03074347972869873\n",
      "Epoch: 4/5, Loss: 0.012951811775565147\n",
      "Epoch: 4/5, Loss: 0.02422192320227623\n",
      "Epoch: 4/5, Loss: 0.03901967778801918\n",
      "Epoch: 4/5, Loss: 0.019998393952846527\n",
      "Epoch: 4/5, Loss: 0.0200265534222126\n",
      "Epoch: 4/5, Loss: 0.018487604334950447\n",
      "Epoch: 4/5, Loss: 0.0045756022445857525\n",
      "Epoch: 4/5, Loss: 0.00239754281938076\n",
      "Epoch: 4/5, Loss: 0.0047630928456783295\n",
      "Epoch: 4/5, Loss: 0.030939051881432533\n",
      "Epoch: 4/5, Loss: 0.043510932475328445\n",
      "Epoch: 4/5, Loss: 0.02369655668735504\n",
      "Epoch: 4/5, Loss: 0.03420383483171463\n",
      "Epoch: 4/5, Loss: 0.015971612185239792\n",
      "Epoch: 4/5, Loss: 0.02920689433813095\n",
      "Epoch: 4/5, Loss: 0.07227719575166702\n",
      "Epoch: 4/5, Loss: 0.03247915208339691\n",
      "Epoch: 4/5, Loss: 0.009100876748561859\n",
      "Epoch: 4/5, Loss: 0.055013950914144516\n",
      "Epoch: 4/5, Loss: 0.003303807694464922\n",
      "Epoch: 4/5, Loss: 0.015786755830049515\n",
      "Epoch: 4/5, Loss: 0.010072954930365086\n",
      "Epoch: 4/5, Loss: 0.003133803606033325\n",
      "Epoch: 4/5, Loss: 0.02966388314962387\n",
      "Epoch: 4/5, Loss: 0.033002957701683044\n",
      "Epoch: 4/5, Loss: 0.01989850029349327\n",
      "Epoch: 4/5, Loss: 0.010915778577327728\n",
      "Epoch: 4/5, Loss: 0.09142574667930603\n",
      "Epoch: 4/5, Loss: 0.005257012322545052\n",
      "Epoch: 4/5, Loss: 0.0028564075473695993\n",
      "Epoch: 4/5, Loss: 0.011445598676800728\n",
      "Epoch: 4/5, Loss: 0.0022943667136132717\n",
      "Epoch: 4/5, Loss: 0.01421340275555849\n",
      "Epoch: 4/5, Loss: 0.0236071590334177\n",
      "Epoch: 4/5, Loss: 0.01726377196609974\n",
      "Epoch: 4/5, Loss: 0.035949595272541046\n",
      "Epoch: 4/5, Loss: 0.010174471884965897\n",
      "Epoch: 4/5, Loss: 0.004150701686739922\n",
      "Epoch: 4/5, Loss: 0.005340459290891886\n",
      "Epoch: 4/5, Loss: 0.03991260007023811\n",
      "Epoch: 4/5, Loss: 0.006680537946522236\n",
      "Epoch: 4/5, Loss: 0.0139281265437603\n",
      "Epoch: 4/5, Loss: 0.006275375839322805\n",
      "Epoch: 4/5, Loss: 0.03966095298528671\n",
      "Epoch: 4/5, Loss: 0.0020328862592577934\n",
      "Epoch: 4/5, Loss: 0.03198986500501633\n",
      "Epoch: 4/5, Loss: 0.04509211704134941\n",
      "Epoch: 4/5, Loss: 0.006754576228559017\n",
      "Epoch: 4/5, Loss: 0.010171444155275822\n",
      "Epoch: 4/5, Loss: 0.08703452348709106\n",
      "Epoch: 4/5, Loss: 0.010887479409575462\n",
      "Epoch: 4/5, Loss: 0.04093681648373604\n",
      "Epoch: 4/5, Loss: 0.007590526714920998\n",
      "Epoch: 4/5, Loss: 0.025090912356972694\n",
      "Epoch: 4/5, Loss: 0.006435655057430267\n",
      "Epoch: 4/5, Loss: 0.005525719840079546\n",
      "Epoch: 4/5, Loss: 0.019873779267072678\n",
      "Epoch: 4/5, Loss: 0.006370216608047485\n",
      "Epoch: 4/5, Loss: 0.011061083525419235\n",
      "Epoch: 4/5, Loss: 0.0039047987665981054\n",
      "Epoch: 4/5, Loss: 0.010779174044728279\n",
      "Epoch: 4/5, Loss: 0.01990021951496601\n",
      "Epoch: 4/5, Loss: 0.049513936042785645\n",
      "Epoch: 4/5, Loss: 0.025755491107702255\n",
      "Epoch: 4/5, Loss: 0.011623474769294262\n",
      "Epoch: 4/5, Loss: 0.020481767132878304\n",
      "Epoch: 4/5, Loss: 0.007772632408887148\n",
      "Epoch: 4/5, Loss: 0.01816381886601448\n",
      "Epoch: 4/5, Loss: 0.005869403947144747\n",
      "Epoch: 4/5, Loss: 0.03161066398024559\n",
      "Epoch: 4/5, Loss: 0.018237397074699402\n",
      "Epoch: 4/5, Loss: 0.013265188783407211\n",
      "Epoch: 4/5, Loss: 0.004635336343199015\n",
      "Epoch: 4/5, Loss: 0.06840486079454422\n",
      "Epoch: 4/5, Loss: 0.003960504196584225\n",
      "Epoch: 4/5, Loss: 0.013188770972192287\n",
      "Epoch: 4/5, Loss: 0.0021383517887443304\n",
      "Epoch: 4/5, Loss: 0.005690264515578747\n",
      "Epoch: 4/5, Loss: 0.042643919587135315\n",
      "Epoch: 4/5, Loss: 0.047492336481809616\n",
      "Epoch: 4/5, Loss: 0.019045012071728706\n",
      "Epoch: 4/5, Loss: 0.0327853262424469\n",
      "Epoch: 4/5, Loss: 0.0025989434216171503\n",
      "Epoch: 4/5, Loss: 0.017148904502391815\n",
      "Epoch: 4/5, Loss: 0.03165508806705475\n",
      "Epoch: 4/5, Loss: 0.024827759712934494\n",
      "Epoch: 4/5, Loss: 0.015868496149778366\n",
      "Epoch: 4/5, Loss: 0.06298022717237473\n",
      "Epoch: 4/5, Loss: 0.008341881446540356\n",
      "Epoch: 4/5, Loss: 0.029635487124323845\n",
      "Epoch: 4/5, Loss: 0.0259802658110857\n",
      "Epoch: 4/5, Loss: 0.005856899544596672\n",
      "Epoch: 4/5, Loss: 0.006277450360357761\n",
      "Epoch: 4/5, Loss: 0.09635826200246811\n",
      "Epoch: 4/5, Loss: 0.008050424978137016\n",
      "Epoch: 4/5, Loss: 0.01788119599223137\n",
      "Epoch: 4/5, Loss: 0.024807848036289215\n",
      "Epoch: 4/5, Loss: 0.026761522516608238\n",
      "Epoch: 4/5, Loss: 0.017354995012283325\n",
      "Epoch: 4/5, Loss: 0.010839693248271942\n",
      "Epoch: 4/5, Loss: 0.018150560557842255\n",
      "Epoch: 4/5, Loss: 0.01730533316731453\n",
      "Epoch: 4/5, Loss: 0.012452343478798866\n",
      "Epoch: 4/5, Loss: 0.01842424087226391\n",
      "Epoch: 4/5, Loss: 0.008419793099164963\n",
      "Epoch: 4/5, Loss: 0.0005299028707668185\n",
      "Epoch: 4/5, Loss: 0.006498399190604687\n",
      "Epoch: 4/5, Loss: 0.016727665439248085\n",
      "Epoch: 4/5, Loss: 0.047106970101594925\n",
      "Epoch: 4/5, Loss: 0.010644604451954365\n",
      "Epoch: 4/5, Loss: 0.02342398092150688\n",
      "Epoch: 4/5, Loss: 0.0014931384939700365\n",
      "Epoch: 4/5, Loss: 0.03364461660385132\n",
      "Epoch: 4/5, Loss: 0.009655021131038666\n",
      "Epoch: 4/5, Loss: 0.02779315784573555\n",
      "Epoch: 4/5, Loss: 0.03105354681611061\n",
      "Epoch: 4/5, Loss: 0.018087251111865044\n",
      "Epoch: 4/5, Loss: 0.008610107004642487\n",
      "Epoch: 4/5, Loss: 0.005252010654658079\n",
      "Epoch: 4/5, Loss: 0.01434357464313507\n",
      "Epoch: 4/5, Loss: 0.01017716247588396\n",
      "Epoch: 4/5, Loss: 0.01280093751847744\n",
      "Epoch: 4/5, Loss: 0.01960853859782219\n",
      "Epoch: 4/5, Loss: 0.0061235977336764336\n",
      "Epoch: 4/5, Loss: 0.003921733237802982\n",
      "Epoch: 4/5, Loss: 0.016290627419948578\n",
      "Epoch: 4/5, Loss: 0.03730907291173935\n",
      "Epoch: 4/5, Loss: 0.03642136976122856\n",
      "Epoch: 4/5, Loss: 0.03082980401813984\n",
      "Epoch: 4/5, Loss: 0.008939986117184162\n",
      "Epoch: 4/5, Loss: 0.013299049809575081\n",
      "Epoch: 4/5, Loss: 0.011941595003008842\n",
      "Epoch: 4/5, Loss: 0.01025024801492691\n",
      "Epoch: 4/5, Loss: 0.04508095607161522\n",
      "Epoch: 4/5, Loss: 0.011722568422555923\n",
      "Epoch: 4/5, Loss: 0.014932407066226006\n",
      "Epoch: 4/5, Loss: 0.03527684882283211\n",
      "Epoch: 4/5, Loss: 0.01945069432258606\n",
      "Epoch: 4/5, Loss: 0.030477697029709816\n",
      "Epoch: 4/5, Loss: 0.05659744516015053\n",
      "Epoch: 4/5, Loss: 0.009312381967902184\n",
      "Epoch: 4/5, Loss: 0.015541661530733109\n",
      "Epoch: 4/5, Loss: 0.005853881128132343\n",
      "Epoch: 4/5, Loss: 0.03359965980052948\n",
      "Epoch: 4/5, Loss: 0.009731321595609188\n",
      "Epoch: 4/5, Loss: 0.018314965069293976\n",
      "Epoch: 4/5, Loss: 0.03687034547328949\n",
      "Epoch: 4/5, Loss: 0.02851700223982334\n",
      "Epoch: 4/5, Loss: 0.010720204561948776\n",
      "Epoch: 4/5, Loss: 0.007799593266099691\n",
      "Epoch: 4/5, Loss: 0.05907248705625534\n",
      "Epoch: 4/5, Loss: 0.02787194773554802\n",
      "Epoch: 4/5, Loss: 0.03350553289055824\n",
      "Epoch: 4/5, Loss: 0.006143713369965553\n",
      "Epoch: 4/5, Loss: 0.005303774494677782\n",
      "Epoch: 4/5, Loss: 0.015496493317186832\n",
      "Epoch: 4/5, Loss: 0.02806471846997738\n",
      "Epoch: 4/5, Loss: 0.011026711203157902\n",
      "Epoch: 4/5, Loss: 0.030055006965994835\n",
      "Epoch: 4/5, Loss: 0.0159568190574646\n",
      "Epoch: 4/5, Loss: 0.018137158825993538\n",
      "Epoch: 4/5, Loss: 0.005514049436897039\n",
      "Epoch: 4/5, Loss: 0.018392786383628845\n",
      "Epoch: 4/5, Loss: 0.007251296192407608\n",
      "Epoch: 4/5, Loss: 0.02428702637553215\n",
      "Epoch: 4/5, Loss: 0.09884284436702728\n",
      "Epoch: 4/5, Loss: 0.03479869291186333\n",
      "Epoch: 4/5, Loss: 0.02189779281616211\n",
      "Epoch: 4/5, Loss: 0.011488093063235283\n",
      "Epoch: 4/5, Loss: 0.006946486420929432\n",
      "Epoch: 4/5, Loss: 0.010055160149931908\n",
      "Epoch: 4/5, Loss: 0.00223494041711092\n",
      "Epoch: 4/5, Loss: 0.013774918392300606\n",
      "Epoch: 4/5, Loss: 0.012240451760590076\n",
      "Epoch: 4/5, Loss: 0.0010052528232336044\n",
      "Epoch: 4/5, Loss: 0.01157014723867178\n",
      "Epoch: 4/5, Loss: 0.017857516184449196\n",
      "Epoch: 4/5, Loss: 0.007818964309990406\n",
      "Epoch: 4/5, Loss: 0.008546756580471992\n",
      "Epoch: 4/5, Loss: 0.0003416971012484282\n",
      "Epoch: 4/5, Loss: 0.042982976883649826\n",
      "Epoch: 4/5, Loss: 0.026316720992326736\n",
      "Epoch: 4/5, Loss: 0.024067213758826256\n",
      "Epoch: 4/5, Loss: 0.09746097028255463\n",
      "Epoch: 4/5, Loss: 0.02625499852001667\n",
      "Epoch: 4/5, Loss: 0.048225030303001404\n",
      "Epoch: 4/5, Loss: 0.008713400922715664\n",
      "Epoch: 4/5, Loss: 0.0067322649993002415\n",
      "Epoch: 4/5, Loss: 0.016411691904067993\n",
      "Epoch: 4/5, Loss: 0.018707720562815666\n",
      "Epoch: 4/5, Loss: 0.03578977659344673\n",
      "Epoch: 4/5, Loss: 0.013932975940406322\n",
      "Epoch: 4/5, Loss: 0.0032647675834596157\n",
      "Epoch: 4/5, Loss: 0.02235499769449234\n",
      "Epoch: 4/5, Loss: 0.022820014506578445\n",
      "Epoch: 4/5, Loss: 0.03445732221007347\n",
      "Epoch: 4/5, Loss: 0.012212099507451057\n",
      "Epoch: 4/5, Loss: 0.0025361489970237017\n",
      "Epoch: 4/5, Loss: 0.0174397025257349\n",
      "Epoch: 4/5, Loss: 0.0039508156478405\n",
      "Epoch: 4/5, Loss: 0.005759817082434893\n",
      "Epoch: 4/5, Loss: 0.007552037946879864\n",
      "Epoch: 4/5, Loss: 0.007920445874333382\n",
      "Epoch: 4/5, Loss: 0.011450733989477158\n",
      "Epoch: 4/5, Loss: 0.005887966603040695\n",
      "Epoch: 4/5, Loss: 0.002465929603204131\n",
      "Epoch: 4/5, Loss: 0.018779322504997253\n",
      "Epoch: 4/5, Loss: 0.013740730471909046\n",
      "Epoch: 4/5, Loss: 0.1349867433309555\n",
      "Epoch: 4/5, Loss: 0.02509186416864395\n",
      "Epoch: 4/5, Loss: 0.011775491759181023\n",
      "Epoch: 4/5, Loss: 0.009153224527835846\n",
      "Epoch: 4/5, Loss: 0.0030849622562527657\n",
      "Epoch: 4/5, Loss: 0.09765634685754776\n",
      "Epoch: 4/5, Loss: 0.017759714275598526\n",
      "Epoch: 4/5, Loss: 0.020991342142224312\n",
      "Epoch: 4/5, Loss: 0.016054369509220123\n",
      "Epoch: 4/5, Loss: 0.01983780972659588\n",
      "Epoch: 4/5, Loss: 0.01144569180905819\n",
      "Epoch: 4/5, Loss: 0.0072953891940414906\n",
      "Epoch: 4/5, Loss: 0.017251256853342056\n",
      "Epoch: 4/5, Loss: 0.018841788172721863\n",
      "Epoch: 4/5, Loss: 0.013978483155369759\n",
      "Epoch: 4/5, Loss: 0.022890087217092514\n",
      "Epoch: 4/5, Loss: 0.03534224256873131\n",
      "Epoch: 4/5, Loss: 0.005854347720742226\n",
      "Epoch: 4/5, Loss: 0.020691674202680588\n",
      "Epoch: 4/5, Loss: 0.019820205867290497\n",
      "Epoch: 4/5, Loss: 0.03064260631799698\n",
      "Epoch: 4/5, Loss: 0.007608872838318348\n",
      "Epoch: 4/5, Loss: 0.03874894976615906\n",
      "Epoch: 4/5, Loss: 0.03155150264501572\n",
      "Epoch: 4/5, Loss: 0.05006103590130806\n",
      "Epoch: 4/5, Loss: 0.015908965840935707\n",
      "Epoch: 4/5, Loss: 0.013491073623299599\n",
      "Epoch: 4/5, Loss: 0.00826559029519558\n",
      "Epoch: 4/5, Loss: 0.01861537992954254\n",
      "Epoch: 4/5, Loss: 0.010206853039562702\n",
      "Epoch: 4/5, Loss: 0.004428291693329811\n",
      "Epoch: 4/5, Loss: 0.013523811474442482\n",
      "Epoch: 4/5, Loss: 0.0071747517213225365\n",
      "Epoch: 4/5, Loss: 0.03151698783040047\n",
      "Epoch: 4/5, Loss: 0.012995888479053974\n",
      "Epoch: 4/5, Loss: 0.039513710886240005\n",
      "Epoch: 4/5, Loss: 0.012541383504867554\n",
      "Epoch: 4/5, Loss: 0.02378864958882332\n",
      "Epoch: 4/5, Loss: 0.0026726750656962395\n",
      "Epoch: 4/5, Loss: 0.014108442701399326\n",
      "Epoch: 4/5, Loss: 0.014069861732423306\n",
      "Epoch: 4/5, Loss: 0.01756284199655056\n",
      "Epoch: 4/5, Loss: 0.0071235597133636475\n",
      "Epoch: 4/5, Loss: 0.014878622256219387\n",
      "Epoch: 4/5, Loss: 0.018621671944856644\n",
      "Epoch: 4/5, Loss: 0.03188658133149147\n",
      "Epoch: 4/5, Loss: 0.012394496239721775\n",
      "Epoch: 4/5, Loss: 0.010695491917431355\n",
      "Epoch: 4/5, Loss: 0.01961163990199566\n",
      "Epoch: 4/5, Loss: 0.0260985866189003\n",
      "Epoch: 4/5, Loss: 0.016878759488463402\n",
      "Epoch: 4/5, Loss: 0.0019597546197474003\n",
      "Epoch: 4/5, Loss: 0.018543357029557228\n",
      "Epoch: 4/5, Loss: 0.006845393218100071\n",
      "Epoch: 4/5, Loss: 0.003403610549867153\n",
      "Epoch: 4/5, Loss: 0.015166068449616432\n",
      "Epoch: 4/5, Loss: 0.01026295218616724\n",
      "Epoch: 4/5, Loss: 0.032334018498659134\n",
      "Epoch: 4/5, Loss: 0.008227282203733921\n",
      "Epoch: 4/5, Loss: 0.014345040544867516\n",
      "Epoch: 4/5, Loss: 0.021556656807661057\n",
      "Epoch: 4/5, Loss: 0.010206112638115883\n",
      "Epoch: 4/5, Loss: 0.012640628032386303\n",
      "Epoch: 4/5, Loss: 0.012335170060396194\n",
      "Epoch: 4/5, Loss: 0.050736259669065475\n",
      "Epoch: 4/5, Loss: 0.0011299696052446961\n",
      "Epoch: 4/5, Loss: 0.03182768076658249\n",
      "Epoch: 4/5, Loss: 0.1562850922346115\n",
      "Epoch: 4/5, Loss: 0.030934887006878853\n",
      "Epoch: 4/5, Loss: 0.03349998593330383\n",
      "Epoch: 4/5, Loss: 0.015039116144180298\n",
      "Epoch: 4/5, Loss: 0.05934067815542221\n",
      "Epoch: 4/5, Loss: 0.02365685999393463\n",
      "Epoch: 4/5, Loss: 0.05487292259931564\n",
      "Epoch: 4/5, Loss: 0.031991854310035706\n",
      "Epoch: 4/5, Loss: 0.0028700712136924267\n",
      "Epoch: 4/5, Loss: 0.036506593227386475\n",
      "Epoch: 4/5, Loss: 0.005727280396968126\n",
      "Epoch: 4/5, Loss: 0.028325378894805908\n",
      "Epoch: 4/5, Loss: 0.04169072210788727\n",
      "Epoch: 4/5, Loss: 0.06653500348329544\n",
      "Epoch: 4/5, Loss: 0.008099309168756008\n",
      "Epoch: 4/5, Loss: 0.038802698254585266\n",
      "Epoch: 4/5, Loss: 0.09204387664794922\n",
      "Epoch: 4/5, Loss: 0.0210970938205719\n",
      "Epoch: 4/5, Loss: 0.0018993295961990952\n",
      "Epoch: 4/5, Loss: 0.07897567003965378\n",
      "Epoch: 4/5, Loss: 0.01102011650800705\n",
      "Epoch: 4/5, Loss: 0.038817815482616425\n",
      "Epoch: 4/5, Loss: 0.011174102313816547\n",
      "Epoch: 4/5, Loss: 0.0020641633309423923\n",
      "Epoch: 4/5, Loss: 0.04038519784808159\n",
      "Epoch: 4/5, Loss: 0.007201489061117172\n",
      "Epoch: 4/5, Loss: 0.007017435040324926\n",
      "Epoch: 4/5, Loss: 0.008288728073239326\n",
      "Epoch: 4/5, Loss: 0.009062571451067924\n",
      "Epoch: 4/5, Loss: 0.010894101113080978\n",
      "Epoch: 4/5, Loss: 0.021292036399245262\n",
      "Epoch: 4/5, Loss: 0.01631922647356987\n",
      "Epoch: 4/5, Loss: 0.01679168827831745\n",
      "Epoch: 4/5, Loss: 0.009520523250102997\n",
      "Epoch: 4/5, Loss: 0.0016789439832791686\n",
      "Epoch: 4/5, Loss: 0.014169124886393547\n",
      "Epoch: 4/5, Loss: 0.008812004700303078\n",
      "Epoch: 4/5, Loss: 0.021827632561326027\n",
      "Epoch: 4/5, Loss: 0.004142426885664463\n",
      "Epoch: 4/5, Loss: 0.0063828532584011555\n",
      "Epoch: 4/5, Loss: 0.01737680472433567\n",
      "Epoch: 4/5, Loss: 0.012253227643668652\n",
      "Epoch: 4/5, Loss: 0.027526065707206726\n",
      "Epoch: 4/5, Loss: 0.012566199526190758\n",
      "Epoch: 4/5, Loss: 0.004037289414554834\n",
      "Epoch: 4/5, Loss: 0.007139235734939575\n",
      "Epoch: 4/5, Loss: 0.0190119668841362\n",
      "Epoch: 4/5, Loss: 0.1516241729259491\n",
      "Epoch: 4/5, Loss: 0.006882535759359598\n",
      "Epoch: 4/5, Loss: 0.018936362117528915\n",
      "Epoch: 4/5, Loss: 0.011622987687587738\n",
      "Epoch: 4/5, Loss: 0.01073353923857212\n",
      "Epoch: 4/5, Loss: 0.007641328498721123\n",
      "Epoch: 4/5, Loss: 0.011344634927809238\n",
      "Epoch: 4/5, Loss: 0.0278057549148798\n",
      "Epoch: 4/5, Loss: 0.04607434943318367\n",
      "Epoch: 4/5, Loss: 0.00959764700382948\n",
      "Epoch: 4/5, Loss: 0.022913308814167976\n",
      "Epoch: 4/5, Loss: 0.006929300259798765\n",
      "Epoch: 4/5, Loss: 0.011334389448165894\n",
      "Epoch: 4/5, Loss: 0.008402842096984386\n",
      "Epoch: 4/5, Loss: 0.025730781257152557\n",
      "Epoch: 4/5, Loss: 0.037323638796806335\n",
      "Epoch: 4/5, Loss: 0.0062342132441699505\n",
      "Epoch: 4/5, Loss: 0.04917607828974724\n",
      "Epoch: 4/5, Loss: 0.00804966688156128\n",
      "Epoch: 4/5, Loss: 0.0036648705136030912\n",
      "Epoch: 4/5, Loss: 0.011610833927989006\n",
      "Epoch: 4/5, Loss: 0.030905112624168396\n",
      "Epoch: 4/5, Loss: 0.04195556044578552\n",
      "Epoch: 4/5, Loss: 0.022847451269626617\n",
      "Epoch: 4/5, Loss: 0.006466232240200043\n",
      "Epoch: 4/5, Loss: 0.034953657537698746\n",
      "Epoch: 4/5, Loss: 0.023145737126469612\n",
      "Epoch: 4/5, Loss: 0.03400135040283203\n",
      "Epoch: 4/5, Loss: 0.033770106732845306\n",
      "Epoch: 4/5, Loss: 0.009169545024633408\n",
      "Epoch: 4/5, Loss: 0.03643202781677246\n",
      "Epoch: 4/5, Loss: 0.010439204052090645\n",
      "Epoch: 4/5, Loss: 0.03545336425304413\n",
      "Epoch: 4/5, Loss: 0.04626097157597542\n",
      "Epoch: 4/5, Loss: 0.02377966046333313\n",
      "Epoch: 4/5, Loss: 0.009589369408786297\n",
      "Epoch: 4/5, Loss: 0.053259752690792084\n",
      "Epoch: 4/5, Loss: 0.006364365573972464\n",
      "Epoch: 4/5, Loss: 0.005957782734185457\n",
      "Epoch: 4/5, Loss: 0.007114834152162075\n",
      "Epoch: 4/5, Loss: 0.010910384356975555\n",
      "Epoch: 4/5, Loss: 0.019709525629878044\n",
      "Epoch: 4/5, Loss: 0.01843951642513275\n",
      "Epoch: 4/5, Loss: 0.01362181268632412\n",
      "Epoch: 4/5, Loss: 0.03222326189279556\n",
      "Epoch: 4/5, Loss: 0.010550806298851967\n",
      "Epoch: 4/5, Loss: 0.016773981973528862\n",
      "Epoch: 4/5, Loss: 0.03307069465517998\n",
      "Epoch: 4/5, Loss: 0.032348573207855225\n",
      "Epoch: 4/5, Loss: 0.012541580945253372\n",
      "Epoch: 4/5, Loss: 0.03677622228860855\n",
      "Epoch: 4/5, Loss: 0.02917679026722908\n",
      "Epoch: 4/5, Loss: 0.02446063794195652\n",
      "Epoch: 4/5, Loss: 0.007633005268871784\n",
      "Epoch: 4/5, Loss: 0.013762674294412136\n",
      "Epoch: 4/5, Loss: 0.03290298581123352\n",
      "Epoch: 4/5, Loss: 0.01049149688333273\n",
      "Epoch: 4/5, Loss: 0.02446853369474411\n",
      "Epoch: 4/5, Loss: 0.03295904025435448\n",
      "Epoch: 4/5, Loss: 0.018916379660367966\n",
      "Epoch: 4/5, Loss: 0.01816447824239731\n",
      "Epoch: 4/5, Loss: 0.08003589510917664\n",
      "Epoch: 4/5, Loss: 0.006914190016686916\n",
      "Epoch: 4/5, Loss: 0.008807007223367691\n",
      "Epoch: 4/5, Loss: 0.0329803042113781\n",
      "Epoch: 4/5, Loss: 0.008865674026310444\n",
      "Epoch: 4/5, Loss: 0.0362677276134491\n",
      "Epoch: 4/5, Loss: 0.02788783609867096\n",
      "Epoch: 4/5, Loss: 0.007710897829383612\n",
      "Epoch: 4/5, Loss: 0.011575553566217422\n",
      "Epoch: 4/5, Loss: 0.016193611547350883\n",
      "Epoch: 4/5, Loss: 0.009668556973338127\n",
      "Epoch: 4/5, Loss: 0.007178114727139473\n",
      "Epoch: 4/5, Loss: 0.04331384599208832\n",
      "Epoch: 4/5, Loss: 0.024849044159054756\n",
      "Epoch: 4/5, Loss: 0.03242896497249603\n",
      "Epoch: 4/5, Loss: 0.008853777311742306\n",
      "Epoch: 4/5, Loss: 0.01232242677360773\n",
      "Epoch: 4/5, Loss: 0.025081800296902657\n",
      "Epoch: 4/5, Loss: 0.025496691465377808\n",
      "Epoch: 4/5, Loss: 0.0146300308406353\n",
      "Epoch: 4/5, Loss: 0.026420295238494873\n",
      "Epoch: 4/5, Loss: 0.03624539449810982\n",
      "Epoch: 4/5, Loss: 0.005948290228843689\n",
      "Epoch: 4/5, Loss: 0.016230793669819832\n",
      "Epoch: 4/5, Loss: 0.01475596334785223\n",
      "Epoch: 4/5, Loss: 0.024175280705094337\n",
      "Epoch: 4/5, Loss: 0.008139445446431637\n",
      "Epoch: 4/5, Loss: 0.012700814753770828\n",
      "Epoch: 4/5, Loss: 0.026706188917160034\n",
      "Epoch: 4/5, Loss: 0.005182892084121704\n",
      "Epoch: 4/5, Loss: 0.002212758641690016\n",
      "Epoch: 4/5, Loss: 0.04139462113380432\n",
      "Epoch: 4/5, Loss: 0.009452085010707378\n",
      "Epoch: 4/5, Loss: 0.009184890426695347\n",
      "Epoch: 4/5, Loss: 0.04122180491685867\n",
      "Epoch: 4/5, Loss: 0.029463982209563255\n",
      "Epoch: 4/5, Loss: 0.03381633386015892\n",
      "Epoch: 4/5, Loss: 0.019081462174654007\n",
      "Epoch: 4/5, Loss: 0.019030291587114334\n",
      "Epoch: 4/5, Loss: 0.01235618069767952\n",
      "Epoch: 4/5, Loss: 0.005820623133331537\n",
      "Epoch: 4/5, Loss: 0.006054620258510113\n",
      "Epoch: 4/5, Loss: 0.005635145120322704\n",
      "Epoch: 4/5, Loss: 0.033887192606925964\n",
      "Epoch: 4/5, Loss: 0.005220232531428337\n",
      "Epoch: 4/5, Loss: 0.04392128437757492\n",
      "Epoch: 4/5, Loss: 0.004160732962191105\n",
      "Epoch: 4/5, Loss: 0.05501074716448784\n",
      "Epoch: 4/5, Loss: 0.006168500520288944\n",
      "Epoch: 4/5, Loss: 0.016270950436592102\n",
      "Epoch: 4/5, Loss: 0.03471478819847107\n",
      "Epoch: 4/5, Loss: 0.03851466253399849\n",
      "Epoch: 4/5, Loss: 0.01151750236749649\n",
      "Epoch: 4/5, Loss: 0.02871941402554512\n",
      "Epoch: 4/5, Loss: 0.006401115097105503\n",
      "Epoch: 4/5, Loss: 0.010556843131780624\n",
      "Epoch: 4/5, Loss: 0.004037998616695404\n",
      "Epoch: 4/5, Loss: 0.015744611620903015\n",
      "Epoch: 4/5, Loss: 0.019978942349553108\n",
      "Epoch: 4/5, Loss: 0.03461446985602379\n",
      "Epoch: 4/5, Loss: 0.019489062950015068\n",
      "Epoch: 4/5, Loss: 0.010325535200536251\n",
      "Epoch: 4/5, Loss: 0.0516231432557106\n",
      "Epoch: 4/5, Loss: 0.029787622392177582\n",
      "Epoch: 4/5, Loss: 0.01832166686654091\n",
      "Epoch: 4/5, Loss: 0.037792548537254333\n",
      "Epoch: 4/5, Loss: 0.034831032156944275\n",
      "Epoch: 4/5, Loss: 0.005393515340983868\n",
      "Epoch: 4/5, Loss: 0.0185324028134346\n",
      "Epoch: 4/5, Loss: 0.02193460613489151\n",
      "Epoch: 4/5, Loss: 0.004696257878094912\n",
      "Epoch: 4/5, Loss: 0.013437261804938316\n",
      "Epoch: 4/5, Loss: 0.014437597244977951\n",
      "Epoch: 4/5, Loss: 0.013139359652996063\n",
      "Epoch: 4/5, Loss: 0.017207810655236244\n",
      "Epoch: 4/5, Loss: 0.023051155731081963\n",
      "Epoch: 4/5, Loss: 0.0122574083507061\n",
      "Epoch: 4/5, Loss: 0.01888325624167919\n",
      "Epoch: 4/5, Loss: 0.0076322052627801895\n",
      "Epoch: 4/5, Loss: 0.016518056392669678\n",
      "Epoch: 4/5, Loss: 0.11666154861450195\n",
      "Epoch: 4/5, Loss: 0.003915556240826845\n",
      "Epoch: 4/5, Loss: 0.0067335572093725204\n",
      "Epoch: 4/5, Loss: 0.063972108066082\n",
      "Epoch: 4/5, Loss: 0.014386557042598724\n",
      "Epoch: 4/5, Loss: 0.009887397289276123\n",
      "Epoch: 4/5, Loss: 0.015477161854505539\n",
      "Epoch: 4/5, Loss: 0.031705860048532486\n",
      "Epoch: 4/5, Loss: 0.035532146692276\n",
      "Epoch: 4/5, Loss: 0.008025763556361198\n",
      "Epoch: 4/5, Loss: 0.01080462709069252\n",
      "Epoch: 4/5, Loss: 0.036704935133457184\n",
      "Epoch: 4/5, Loss: 0.00938740000128746\n",
      "Epoch: 4/5, Loss: 0.0168638676404953\n",
      "Epoch: 4/5, Loss: 0.04566727578639984\n",
      "Epoch: 4/5, Loss: 0.07690666615962982\n",
      "Epoch: 4/5, Loss: 0.020384816452860832\n",
      "Epoch: 4/5, Loss: 0.00922418013215065\n",
      "Epoch: 4/5, Loss: 0.008293630555272102\n",
      "Epoch: 4/5, Loss: 0.01937667652964592\n",
      "Epoch: 4/5, Loss: 0.017949093133211136\n",
      "Epoch: 4/5, Loss: 0.004555388353765011\n",
      "Epoch: 4/5, Loss: 0.002953083487227559\n",
      "Epoch: 4/5, Loss: 0.0003585251106414944\n",
      "Epoch: 4/5, Loss: 0.014714900404214859\n",
      "Epoch: 4/5, Loss: 0.01209620013833046\n",
      "Epoch: 4/5, Loss: 0.053650978952646255\n",
      "Epoch: 4/5, Loss: 0.03957269713282585\n",
      "Epoch: 4/5, Loss: 0.00991812627762556\n",
      "Epoch: 4/5, Loss: 0.01858149655163288\n",
      "Epoch: 4/5, Loss: 0.008842122741043568\n",
      "Epoch: 4/5, Loss: 0.014820498414337635\n",
      "Epoch: 4/5, Loss: 0.006461082026362419\n",
      "Epoch: 4/5, Loss: 0.009056642651557922\n",
      "Epoch: 4/5, Loss: 0.009510894306004047\n",
      "Epoch: 4/5, Loss: 0.006856852676719427\n",
      "Epoch: 4/5, Loss: 0.006512085907161236\n",
      "Epoch: 4/5, Loss: 0.03918193280696869\n",
      "Epoch: 4/5, Loss: 0.049113139510154724\n",
      "Epoch: 4/5, Loss: 0.04049511253833771\n",
      "Epoch: 4/5, Loss: 0.015468460507690907\n",
      "Epoch: 4/5, Loss: 0.01817745715379715\n",
      "Epoch: 4/5, Loss: 0.005161046050488949\n",
      "Epoch: 4/5, Loss: 0.02079617604613304\n",
      "Epoch: 4/5, Loss: 0.02459464780986309\n",
      "Epoch: 4/5, Loss: 0.0175998043268919\n",
      "Epoch: 4/5, Loss: 0.040231432765722275\n",
      "Epoch: 4/5, Loss: 0.0069436244666576385\n",
      "Epoch: 4/5, Loss: 0.004537696018815041\n",
      "Epoch: 4/5, Loss: 0.04425754025578499\n",
      "Epoch: 4/5, Loss: 0.023071110248565674\n",
      "Epoch: 4/5, Loss: 0.007846745662391186\n",
      "Epoch: 4/5, Loss: 0.0093895448371768\n",
      "Epoch: 4/5, Loss: 0.020841415971517563\n",
      "Epoch: 4/5, Loss: 0.005206323228776455\n",
      "Epoch: 4/5, Loss: 0.002263024915009737\n",
      "Epoch: 4/5, Loss: 0.016478730365633965\n",
      "Epoch: 4/5, Loss: 0.018772337585687637\n",
      "Epoch: 4/5, Loss: 0.038442354649305344\n",
      "Epoch: 4/5, Loss: 0.03619874641299248\n",
      "Epoch: 4/5, Loss: 0.0192508976906538\n",
      "Epoch: 4/5, Loss: 0.0223824642598629\n",
      "Epoch: 4/5, Loss: 0.013385403901338577\n",
      "Epoch: 4/5, Loss: 0.023202579468488693\n",
      "Epoch: 4/5, Loss: 0.0067612165585160255\n",
      "Epoch: 4/5, Loss: 0.0032921452075242996\n",
      "Epoch: 4/5, Loss: 0.04787735641002655\n",
      "Epoch: 4/5, Loss: 0.01784719154238701\n",
      "Epoch: 4/5, Loss: 0.00666077621281147\n",
      "Epoch: 4/5, Loss: 0.022880278527736664\n",
      "Epoch: 4/5, Loss: 0.03038375824689865\n",
      "Epoch: 4/5, Loss: 0.02716418355703354\n",
      "Epoch: 4/5, Loss: 0.015639986842870712\n",
      "Epoch: 4/5, Loss: 0.011322274804115295\n",
      "Epoch: 4/5, Loss: 0.002799556590616703\n",
      "Epoch: 4/5, Loss: 0.013087528757750988\n",
      "Epoch: 4/5, Loss: 0.004570298828184605\n",
      "Epoch: 4/5, Loss: 0.017450235784053802\n",
      "Epoch: 4/5, Loss: 0.0034165005199611187\n",
      "Epoch: 4/5, Loss: 0.025234252214431763\n",
      "Epoch: 4/5, Loss: 0.026602476835250854\n",
      "Epoch: 4/5, Loss: 0.032728634774684906\n",
      "Epoch: 4/5, Loss: 0.009040857665240765\n",
      "Epoch: 4/5, Loss: 0.010469647124409676\n",
      "Epoch: 4/5, Loss: 0.00691252900287509\n",
      "Epoch: 4/5, Loss: 0.016177238896489143\n",
      "Epoch: 4/5, Loss: 0.02188335917890072\n",
      "Epoch: 4/5, Loss: 0.02851545251905918\n",
      "Epoch: 4/5, Loss: 0.0014827128034085035\n",
      "Epoch: 4/5, Loss: 0.024024486541748047\n",
      "Epoch: 4/5, Loss: 0.020119208842515945\n",
      "Epoch: 4/5, Loss: 0.015534366481006145\n",
      "Epoch: 4/5, Loss: 0.0036140847951173782\n",
      "Epoch: 4/5, Loss: 0.021584896370768547\n",
      "Epoch: 4/5, Loss: 0.03207346796989441\n",
      "Epoch: 4/5, Loss: 0.007818784564733505\n",
      "Epoch: 4/5, Loss: 0.038670022040605545\n",
      "Epoch: 4/5, Loss: 0.00960453413426876\n",
      "Epoch: 4/5, Loss: 0.01957237720489502\n",
      "Epoch: 4/5, Loss: 0.02343400940299034\n",
      "Epoch: 4/5, Loss: 0.010635539889335632\n",
      "Epoch: 4/5, Loss: 0.02637367881834507\n",
      "Epoch: 4/5, Loss: 0.019637204706668854\n",
      "Epoch: 4/5, Loss: 0.010090729221701622\n",
      "Epoch: 4/5, Loss: 0.0031718353275209665\n",
      "Epoch: 4/5, Loss: 0.01738961972296238\n",
      "Epoch: 4/5, Loss: 0.03809041157364845\n",
      "Epoch: 4/5, Loss: 0.00429632468149066\n",
      "Epoch: 4/5, Loss: 0.03909933567047119\n",
      "Epoch: 4/5, Loss: 0.00710066594183445\n",
      "Epoch: 4/5, Loss: 0.14047513902187347\n",
      "Epoch: 4/5, Loss: 0.015425151214003563\n",
      "Epoch: 4/5, Loss: 0.026453230530023575\n",
      "Epoch: 4/5, Loss: 0.019402431324124336\n",
      "Epoch: 4/5, Loss: 0.03206095099449158\n",
      "Epoch: 4/5, Loss: 0.003687015501782298\n",
      "Epoch: 4/5, Loss: 0.011404668912291527\n",
      "Epoch: 4/5, Loss: 0.011128615587949753\n",
      "Epoch: 4/5, Loss: 0.041708704084157944\n",
      "Epoch: 4/5, Loss: 0.004415849689394236\n",
      "Epoch: 4/5, Loss: 0.0005497331731021404\n",
      "Epoch: 4/5, Loss: 0.031364597380161285\n",
      "Epoch: 4/5, Loss: 0.02844410017132759\n",
      "Epoch: 4/5, Loss: 0.004223664756864309\n",
      "Epoch: 4/5, Loss: 0.013415222987532616\n",
      "Epoch: 4/5, Loss: 0.013235104270279408\n",
      "Epoch: 4/5, Loss: 0.006907016970217228\n",
      "Epoch: 4/5, Loss: 0.02759544551372528\n",
      "Epoch: 4/5, Loss: 0.011644415557384491\n",
      "Epoch: 4/5, Loss: 0.03460399806499481\n",
      "Epoch: 4/5, Loss: 0.02925698086619377\n",
      "Epoch: 4/5, Loss: 0.01684659719467163\n",
      "Epoch: 4/5, Loss: 0.004297454841434956\n",
      "Epoch: 4/5, Loss: 0.03846770152449608\n",
      "Epoch: 4/5, Loss: 0.014089853502810001\n",
      "Epoch: 4/5, Loss: 0.03169320151209831\n",
      "Epoch: 4/5, Loss: 0.0011305063962936401\n",
      "Epoch: 4/5, Loss: 0.02918500453233719\n",
      "Epoch: 4/5, Loss: 0.04761437699198723\n",
      "Epoch: 5/5, Loss: 0.014604213647544384\n",
      "Epoch: 5/5, Loss: 0.02053198404610157\n",
      "Epoch: 5/5, Loss: 0.03727645426988602\n",
      "Epoch: 5/5, Loss: 0.008804279379546642\n",
      "Epoch: 5/5, Loss: 0.007384604308754206\n",
      "Epoch: 5/5, Loss: 0.017551710829138756\n",
      "Epoch: 5/5, Loss: 0.022403530776500702\n",
      "Epoch: 5/5, Loss: 0.014968516305088997\n",
      "Epoch: 5/5, Loss: 0.029847869649529457\n",
      "Epoch: 5/5, Loss: 0.022948594763875008\n",
      "Epoch: 5/5, Loss: 0.00649856636300683\n",
      "Epoch: 5/5, Loss: 0.012714128941297531\n",
      "Epoch: 5/5, Loss: 0.007245942018926144\n",
      "Epoch: 5/5, Loss: 0.032760344445705414\n",
      "Epoch: 5/5, Loss: 0.013999815098941326\n",
      "Epoch: 5/5, Loss: 0.023435024544596672\n",
      "Epoch: 5/5, Loss: 0.023145439103245735\n",
      "Epoch: 5/5, Loss: 0.025523625314235687\n",
      "Epoch: 5/5, Loss: 0.0073192911222577095\n",
      "Epoch: 5/5, Loss: 0.032346535474061966\n",
      "Epoch: 5/5, Loss: 0.0010836267611011863\n",
      "Epoch: 5/5, Loss: 0.035831697285175323\n",
      "Epoch: 5/5, Loss: 0.01750708371400833\n",
      "Epoch: 5/5, Loss: 0.02863532118499279\n",
      "Epoch: 5/5, Loss: 0.0018701519584283233\n",
      "Epoch: 5/5, Loss: 0.09993013739585876\n",
      "Epoch: 5/5, Loss: 0.005266590975224972\n",
      "Epoch: 5/5, Loss: 0.013254789635539055\n",
      "Epoch: 5/5, Loss: 0.006636240519583225\n",
      "Epoch: 5/5, Loss: 0.006855463609099388\n",
      "Epoch: 5/5, Loss: 0.04132998734712601\n",
      "Epoch: 5/5, Loss: 0.008216658607125282\n",
      "Epoch: 5/5, Loss: 0.005365863908082247\n",
      "Epoch: 5/5, Loss: 0.01026434451341629\n",
      "Epoch: 5/5, Loss: 0.03350053355097771\n",
      "Epoch: 5/5, Loss: 0.04290177300572395\n",
      "Epoch: 5/5, Loss: 0.029277529567480087\n",
      "Epoch: 5/5, Loss: 0.030596354976296425\n",
      "Epoch: 5/5, Loss: 0.031182821840047836\n",
      "Epoch: 5/5, Loss: 0.010461910627782345\n",
      "Epoch: 5/5, Loss: 0.05801253020763397\n",
      "Epoch: 5/5, Loss: 0.03110317327082157\n",
      "Epoch: 5/5, Loss: 0.035417065024375916\n",
      "Epoch: 5/5, Loss: 0.019525788724422455\n",
      "Epoch: 5/5, Loss: 0.0388941690325737\n",
      "Epoch: 5/5, Loss: 0.027597032487392426\n",
      "Epoch: 5/5, Loss: 0.02643030509352684\n",
      "Epoch: 5/5, Loss: 0.02377638965845108\n",
      "Epoch: 5/5, Loss: 0.013412807136774063\n",
      "Epoch: 5/5, Loss: 0.034881338477134705\n",
      "Epoch: 5/5, Loss: 0.010156061500310898\n",
      "Epoch: 5/5, Loss: 0.00151776522397995\n",
      "Epoch: 5/5, Loss: 0.02384672686457634\n",
      "Epoch: 5/5, Loss: 0.03067043237388134\n",
      "Epoch: 5/5, Loss: 0.011461244896054268\n",
      "Epoch: 5/5, Loss: 0.01846446841955185\n",
      "Epoch: 5/5, Loss: 0.0740274116396904\n",
      "Epoch: 5/5, Loss: 0.012470632791519165\n",
      "Epoch: 5/5, Loss: 0.007219156250357628\n",
      "Epoch: 5/5, Loss: 0.010627991519868374\n",
      "Epoch: 5/5, Loss: 0.004470360465347767\n",
      "Epoch: 5/5, Loss: 0.017281271517276764\n",
      "Epoch: 5/5, Loss: 0.026479318737983704\n",
      "Epoch: 5/5, Loss: 0.021815326064825058\n",
      "Epoch: 5/5, Loss: 0.04371218383312225\n",
      "Epoch: 5/5, Loss: 0.000632889976259321\n",
      "Epoch: 5/5, Loss: 0.028416216373443604\n",
      "Epoch: 5/5, Loss: 0.09109196811914444\n",
      "Epoch: 5/5, Loss: 0.021950121968984604\n",
      "Epoch: 5/5, Loss: 0.009328735992312431\n",
      "Epoch: 5/5, Loss: 0.00967827346175909\n",
      "Epoch: 5/5, Loss: 0.02118830755352974\n",
      "Epoch: 5/5, Loss: 0.007794397883117199\n",
      "Epoch: 5/5, Loss: 0.016363294795155525\n",
      "Epoch: 5/5, Loss: 0.008734701201319695\n",
      "Epoch: 5/5, Loss: 0.012498279102146626\n",
      "Epoch: 5/5, Loss: 0.01438488345593214\n",
      "Epoch: 5/5, Loss: 0.006468244828283787\n",
      "Epoch: 5/5, Loss: 0.03912605345249176\n",
      "Epoch: 5/5, Loss: 0.00785504374653101\n",
      "Epoch: 5/5, Loss: 0.030633337795734406\n",
      "Epoch: 5/5, Loss: 0.012621145695447922\n",
      "Epoch: 5/5, Loss: 0.02505471371114254\n",
      "Epoch: 5/5, Loss: 0.013341721147298813\n",
      "Epoch: 5/5, Loss: 0.0273035429418087\n",
      "Epoch: 5/5, Loss: 0.0022612884640693665\n",
      "Epoch: 5/5, Loss: 0.008978236466646194\n",
      "Epoch: 5/5, Loss: 0.007649313658475876\n",
      "Epoch: 5/5, Loss: 0.003773228032514453\n",
      "Epoch: 5/5, Loss: 0.07046452164649963\n",
      "Epoch: 5/5, Loss: 0.03474734351038933\n",
      "Epoch: 5/5, Loss: 0.013633768074214458\n",
      "Epoch: 5/5, Loss: 0.019358232617378235\n",
      "Epoch: 5/5, Loss: 0.023500004783272743\n",
      "Epoch: 5/5, Loss: 0.024101397022604942\n",
      "Epoch: 5/5, Loss: 0.033096835017204285\n",
      "Epoch: 5/5, Loss: 0.02715558558702469\n",
      "Epoch: 5/5, Loss: 0.002547497395426035\n",
      "Epoch: 5/5, Loss: 0.023073837161064148\n",
      "Epoch: 5/5, Loss: 0.004534395411610603\n",
      "Epoch: 5/5, Loss: 0.01527491770684719\n",
      "Epoch: 5/5, Loss: 0.02349790185689926\n",
      "Epoch: 5/5, Loss: 0.026131847873330116\n",
      "Epoch: 5/5, Loss: 0.007834721356630325\n",
      "Epoch: 5/5, Loss: 0.03234145790338516\n",
      "Epoch: 5/5, Loss: 0.05695873498916626\n",
      "Epoch: 5/5, Loss: 0.016676222905516624\n",
      "Epoch: 5/5, Loss: 0.01620347425341606\n",
      "Epoch: 5/5, Loss: 0.02800893597304821\n",
      "Epoch: 5/5, Loss: 0.03807814046740532\n",
      "Epoch: 5/5, Loss: 0.021583229303359985\n",
      "Epoch: 5/5, Loss: 0.01573595032095909\n",
      "Epoch: 5/5, Loss: 0.011729869991540909\n",
      "Epoch: 5/5, Loss: 0.018858540803194046\n",
      "Epoch: 5/5, Loss: 0.025218861177563667\n",
      "Epoch: 5/5, Loss: 0.00786278024315834\n",
      "Epoch: 5/5, Loss: 0.029416095465421677\n",
      "Epoch: 5/5, Loss: 0.021897414699196815\n",
      "Epoch: 5/5, Loss: 0.029066046699881554\n",
      "Epoch: 5/5, Loss: 0.02191370166838169\n",
      "Epoch: 5/5, Loss: 0.008581724017858505\n",
      "Epoch: 5/5, Loss: 0.013393044471740723\n",
      "Epoch: 5/5, Loss: 0.017009608447551727\n",
      "Epoch: 5/5, Loss: 0.00389717984944582\n",
      "Epoch: 5/5, Loss: 0.004905144218355417\n",
      "Epoch: 5/5, Loss: 0.012220374308526516\n",
      "Epoch: 5/5, Loss: 0.011665146797895432\n",
      "Epoch: 5/5, Loss: 0.008488637395203114\n",
      "Epoch: 5/5, Loss: 0.0125958900898695\n",
      "Epoch: 5/5, Loss: 0.01162307895720005\n",
      "Epoch: 5/5, Loss: 0.007701026741415262\n",
      "Epoch: 5/5, Loss: 0.03547770529985428\n",
      "Epoch: 5/5, Loss: 0.017338328063488007\n",
      "Epoch: 5/5, Loss: 0.010239686816930771\n",
      "Epoch: 5/5, Loss: 0.025913964956998825\n",
      "Epoch: 5/5, Loss: 0.02910918928682804\n",
      "Epoch: 5/5, Loss: 0.006308976095169783\n",
      "Epoch: 5/5, Loss: 0.016211044043302536\n",
      "Epoch: 5/5, Loss: 0.007167068775743246\n",
      "Epoch: 5/5, Loss: 0.006517842411994934\n",
      "Epoch: 5/5, Loss: 0.026042532175779343\n",
      "Epoch: 5/5, Loss: 0.05880174785852432\n",
      "Epoch: 5/5, Loss: 0.015724394470453262\n",
      "Epoch: 5/5, Loss: 0.02500087581574917\n",
      "Epoch: 5/5, Loss: 0.004167494829744101\n",
      "Epoch: 5/5, Loss: 0.004138213116675615\n",
      "Epoch: 5/5, Loss: 0.025089742615818977\n",
      "Epoch: 5/5, Loss: 0.013364274054765701\n",
      "Epoch: 5/5, Loss: 0.033010050654411316\n",
      "Epoch: 5/5, Loss: 0.014199341647326946\n",
      "Epoch: 5/5, Loss: 0.008634042926132679\n",
      "Epoch: 5/5, Loss: 0.03128444775938988\n",
      "Epoch: 5/5, Loss: 0.023732835426926613\n",
      "Epoch: 5/5, Loss: 0.03190808743238449\n",
      "Epoch: 5/5, Loss: 0.008659911341965199\n",
      "Epoch: 5/5, Loss: 0.057648077607154846\n",
      "Epoch: 5/5, Loss: 0.019074713811278343\n",
      "Epoch: 5/5, Loss: 0.058245860040187836\n",
      "Epoch: 5/5, Loss: 0.04185076802968979\n",
      "Epoch: 5/5, Loss: 0.011288095265626907\n",
      "Epoch: 5/5, Loss: 0.027096545323729515\n",
      "Epoch: 5/5, Loss: 0.019917571917176247\n",
      "Epoch: 5/5, Loss: 0.000942593498621136\n",
      "Epoch: 5/5, Loss: 0.07694051414728165\n",
      "Epoch: 5/5, Loss: 0.0014520552940666676\n",
      "Epoch: 5/5, Loss: 0.01161416620016098\n",
      "Epoch: 5/5, Loss: 0.009147657081484795\n",
      "Epoch: 5/5, Loss: 0.019383590668439865\n",
      "Epoch: 5/5, Loss: 0.01707186922430992\n",
      "Epoch: 5/5, Loss: 0.014880265109241009\n",
      "Epoch: 5/5, Loss: 0.0078099509701132774\n",
      "Epoch: 5/5, Loss: 0.0020670294761657715\n",
      "Epoch: 5/5, Loss: 0.01729014702141285\n",
      "Epoch: 5/5, Loss: 0.00978707242757082\n",
      "Epoch: 5/5, Loss: 0.028952166438102722\n",
      "Epoch: 5/5, Loss: 0.006064259447157383\n",
      "Epoch: 5/5, Loss: 0.024523895233869553\n",
      "Epoch: 5/5, Loss: 0.0016689221374690533\n",
      "Epoch: 5/5, Loss: 0.025622472167015076\n",
      "Epoch: 5/5, Loss: 0.011295812204480171\n",
      "Epoch: 5/5, Loss: 0.05987435206770897\n",
      "Epoch: 5/5, Loss: 0.0069605037569999695\n",
      "Epoch: 5/5, Loss: 0.011448255740106106\n",
      "Epoch: 5/5, Loss: 0.011282403022050858\n",
      "Epoch: 5/5, Loss: 0.009088636375963688\n",
      "Epoch: 5/5, Loss: 0.019005918875336647\n",
      "Epoch: 5/5, Loss: 0.021270904690027237\n",
      "Epoch: 5/5, Loss: 0.024156399071216583\n",
      "Epoch: 5/5, Loss: 0.007426517084240913\n",
      "Epoch: 5/5, Loss: 0.054754048585891724\n",
      "Epoch: 5/5, Loss: 0.008256648667156696\n",
      "Epoch: 5/5, Loss: 0.02235029637813568\n",
      "Epoch: 5/5, Loss: 0.006330098956823349\n",
      "Epoch: 5/5, Loss: 0.005108424462378025\n",
      "Epoch: 5/5, Loss: 0.028463847935199738\n",
      "Epoch: 5/5, Loss: 0.016932260245084763\n",
      "Epoch: 5/5, Loss: 0.03524880111217499\n",
      "Epoch: 5/5, Loss: 0.012287023477256298\n",
      "Epoch: 5/5, Loss: 0.04165573790669441\n",
      "Epoch: 5/5, Loss: 0.010616384446620941\n",
      "Epoch: 5/5, Loss: 0.030368613079190254\n",
      "Epoch: 5/5, Loss: 0.037175294011831284\n",
      "Epoch: 5/5, Loss: 0.008614098653197289\n",
      "Epoch: 5/5, Loss: 0.012067722156643867\n",
      "Epoch: 5/5, Loss: 0.020160766318440437\n",
      "Epoch: 5/5, Loss: 0.04216396436095238\n",
      "Epoch: 5/5, Loss: 0.05039546266198158\n",
      "Epoch: 5/5, Loss: 0.016381235793232918\n",
      "Epoch: 5/5, Loss: 0.03488418832421303\n",
      "Epoch: 5/5, Loss: 0.01407049223780632\n",
      "Epoch: 5/5, Loss: 0.003476326586678624\n",
      "Epoch: 5/5, Loss: 0.027413221076130867\n",
      "Epoch: 5/5, Loss: 0.034278642386198044\n",
      "Epoch: 5/5, Loss: 0.02024098113179207\n",
      "Epoch: 5/5, Loss: 0.016537195071578026\n",
      "Epoch: 5/5, Loss: 0.011916978284716606\n",
      "Epoch: 5/5, Loss: 0.011834360659122467\n",
      "Epoch: 5/5, Loss: 0.033484119921922684\n",
      "Epoch: 5/5, Loss: 0.025927387177944183\n",
      "Epoch: 5/5, Loss: 0.019888589158654213\n",
      "Epoch: 5/5, Loss: 0.019061021506786346\n",
      "Epoch: 5/5, Loss: 0.017511947080492973\n",
      "Epoch: 5/5, Loss: 0.018696289509534836\n",
      "Epoch: 5/5, Loss: 0.005673511419445276\n",
      "Epoch: 5/5, Loss: 0.050530511885881424\n",
      "Epoch: 5/5, Loss: 0.03297295793890953\n",
      "Epoch: 5/5, Loss: 0.014398796483874321\n",
      "Epoch: 5/5, Loss: 0.018360717222094536\n",
      "Epoch: 5/5, Loss: 0.021098341792821884\n",
      "Epoch: 5/5, Loss: 0.010677504353225231\n",
      "Epoch: 5/5, Loss: 0.0031421612948179245\n",
      "Epoch: 5/5, Loss: 0.0206507109105587\n",
      "Epoch: 5/5, Loss: 0.03584221005439758\n",
      "Epoch: 5/5, Loss: 0.023655127733945847\n",
      "Epoch: 5/5, Loss: 0.030773401260375977\n",
      "Epoch: 5/5, Loss: 0.022126130759716034\n",
      "Epoch: 5/5, Loss: 0.035933174192905426\n",
      "Epoch: 5/5, Loss: 0.02265569008886814\n",
      "Epoch: 5/5, Loss: 0.005935146939009428\n",
      "Epoch: 5/5, Loss: 0.01484319381415844\n",
      "Epoch: 5/5, Loss: 0.02030402049422264\n",
      "Epoch: 5/5, Loss: 0.006670096423476934\n",
      "Epoch: 5/5, Loss: 0.0061916159465909\n",
      "Epoch: 5/5, Loss: 0.018888210877776146\n",
      "Epoch: 5/5, Loss: 0.008343338966369629\n",
      "Epoch: 5/5, Loss: 0.024952281266450882\n",
      "Epoch: 5/5, Loss: 0.009836951270699501\n",
      "Epoch: 5/5, Loss: 0.008155555464327335\n",
      "Epoch: 5/5, Loss: 0.0586242601275444\n",
      "Epoch: 5/5, Loss: 0.004681244492530823\n",
      "Epoch: 5/5, Loss: 0.0183824822306633\n",
      "Epoch: 5/5, Loss: 0.024952152743935585\n",
      "Epoch: 5/5, Loss: 0.03518598526716232\n",
      "Epoch: 5/5, Loss: 0.014382386580109596\n",
      "Epoch: 5/5, Loss: 0.01403182651847601\n",
      "Epoch: 5/5, Loss: 0.0019623495172709227\n",
      "Epoch: 5/5, Loss: 0.0022650272585451603\n",
      "Epoch: 5/5, Loss: 0.005871566478163004\n",
      "Epoch: 5/5, Loss: 0.012793976813554764\n",
      "Epoch: 5/5, Loss: 0.01632850058376789\n",
      "Epoch: 5/5, Loss: 0.037291787564754486\n",
      "Epoch: 5/5, Loss: 0.0286085307598114\n",
      "Epoch: 5/5, Loss: 0.00925412680953741\n",
      "Epoch: 5/5, Loss: 0.010989600792527199\n",
      "Epoch: 5/5, Loss: 0.025334622710943222\n",
      "Epoch: 5/5, Loss: 0.05101606994867325\n",
      "Epoch: 5/5, Loss: 0.008355813100934029\n",
      "Epoch: 5/5, Loss: 0.023209866136312485\n",
      "Epoch: 5/5, Loss: 0.0006846397882327437\n",
      "Epoch: 5/5, Loss: 0.01819845847785473\n",
      "Epoch: 5/5, Loss: 0.04856506362557411\n",
      "Epoch: 5/5, Loss: 0.019969329237937927\n",
      "Epoch: 5/5, Loss: 0.03540964052081108\n",
      "Epoch: 5/5, Loss: 0.010639318265020847\n",
      "Epoch: 5/5, Loss: 0.01098946388810873\n",
      "Epoch: 5/5, Loss: 0.00994937215000391\n",
      "Epoch: 5/5, Loss: 0.014490042813122272\n",
      "Epoch: 5/5, Loss: 0.017790772020816803\n",
      "Epoch: 5/5, Loss: 0.029209213331341743\n",
      "Epoch: 5/5, Loss: 0.009018488228321075\n",
      "Epoch: 5/5, Loss: 0.021695395931601524\n",
      "Epoch: 5/5, Loss: 0.04157291725277901\n",
      "Epoch: 5/5, Loss: 0.066658616065979\n",
      "Epoch: 5/5, Loss: 0.017062464728951454\n",
      "Epoch: 5/5, Loss: 0.009326586499810219\n",
      "Epoch: 5/5, Loss: 0.010583817958831787\n",
      "Epoch: 5/5, Loss: 0.005703791975975037\n",
      "Epoch: 5/5, Loss: 0.005248159635812044\n",
      "Epoch: 5/5, Loss: 0.018642636016011238\n",
      "Epoch: 5/5, Loss: 0.002795641776174307\n",
      "Epoch: 5/5, Loss: 0.0090293288230896\n",
      "Epoch: 5/5, Loss: 0.03186334669589996\n",
      "Epoch: 5/5, Loss: 0.03951556235551834\n",
      "Epoch: 5/5, Loss: 0.14799553155899048\n",
      "Epoch: 5/5, Loss: 0.039979685097932816\n",
      "Epoch: 5/5, Loss: 0.012179568409919739\n",
      "Epoch: 5/5, Loss: 0.007272701244801283\n",
      "Epoch: 5/5, Loss: 0.02197120152413845\n",
      "Epoch: 5/5, Loss: 0.02178370952606201\n",
      "Epoch: 5/5, Loss: 0.01981426775455475\n",
      "Epoch: 5/5, Loss: 0.016438936814665794\n",
      "Epoch: 5/5, Loss: 0.004852555692195892\n",
      "Epoch: 5/5, Loss: 0.025101378560066223\n",
      "Epoch: 5/5, Loss: 0.005915787536650896\n",
      "Epoch: 5/5, Loss: 0.01893519051373005\n",
      "Epoch: 5/5, Loss: 0.02108510583639145\n",
      "Epoch: 5/5, Loss: 0.006903761066496372\n",
      "Epoch: 5/5, Loss: 0.03572507202625275\n",
      "Epoch: 5/5, Loss: 0.024753183126449585\n",
      "Epoch: 5/5, Loss: 0.017649341374635696\n",
      "Epoch: 5/5, Loss: 0.006048229523003101\n",
      "Epoch: 5/5, Loss: 0.010913271456956863\n",
      "Epoch: 5/5, Loss: 0.025535626336932182\n",
      "Epoch: 5/5, Loss: 0.020303554832935333\n",
      "Epoch: 5/5, Loss: 0.004672590177506208\n",
      "Epoch: 5/5, Loss: 0.021440790966153145\n",
      "Epoch: 5/5, Loss: 0.04053254425525665\n",
      "Epoch: 5/5, Loss: 0.01577078364789486\n",
      "Epoch: 5/5, Loss: 0.014377361163496971\n",
      "Epoch: 5/5, Loss: 0.006931959185749292\n",
      "Epoch: 5/5, Loss: 0.016679923981428146\n",
      "Epoch: 5/5, Loss: 0.0201784148812294\n",
      "Epoch: 5/5, Loss: 0.03428021818399429\n",
      "Epoch: 5/5, Loss: 0.012911153957247734\n",
      "Epoch: 5/5, Loss: 0.009318655356764793\n",
      "Epoch: 5/5, Loss: 0.016152769327163696\n",
      "Epoch: 5/5, Loss: 0.004962070845067501\n",
      "Epoch: 5/5, Loss: 0.04209011793136597\n",
      "Epoch: 5/5, Loss: 0.027818921953439713\n",
      "Epoch: 5/5, Loss: 0.00686169508844614\n",
      "Epoch: 5/5, Loss: 0.10260679572820663\n",
      "Epoch: 5/5, Loss: 0.013564709573984146\n",
      "Epoch: 5/5, Loss: 0.028073187917470932\n",
      "Epoch: 5/5, Loss: 0.005862024147063494\n",
      "Epoch: 5/5, Loss: 0.014125986024737358\n",
      "Epoch: 5/5, Loss: 0.01565229892730713\n",
      "Epoch: 5/5, Loss: 0.013110538944602013\n",
      "Epoch: 5/5, Loss: 0.03084239549934864\n",
      "Epoch: 5/5, Loss: 0.007564438972622156\n",
      "Epoch: 5/5, Loss: 0.004937521182000637\n",
      "Epoch: 5/5, Loss: 0.026533419266343117\n",
      "Epoch: 5/5, Loss: 0.02677452191710472\n",
      "Epoch: 5/5, Loss: 0.024325205013155937\n",
      "Epoch: 5/5, Loss: 0.020031867548823357\n",
      "Epoch: 5/5, Loss: 0.022018099203705788\n",
      "Epoch: 5/5, Loss: 0.016843300312757492\n",
      "Epoch: 5/5, Loss: 0.020387684926390648\n",
      "Epoch: 5/5, Loss: 0.01198656763881445\n",
      "Epoch: 5/5, Loss: 0.0016640936955809593\n",
      "Epoch: 5/5, Loss: 0.00475442735478282\n",
      "Epoch: 5/5, Loss: 0.004408576060086489\n",
      "Epoch: 5/5, Loss: 0.02443241886794567\n",
      "Epoch: 5/5, Loss: 0.009867705404758453\n",
      "Epoch: 5/5, Loss: 0.011438257060945034\n",
      "Epoch: 5/5, Loss: 0.009775876067578793\n",
      "Epoch: 5/5, Loss: 0.002325688023120165\n",
      "Epoch: 5/5, Loss: 0.02629786729812622\n",
      "Epoch: 5/5, Loss: 0.029110314324498177\n",
      "Epoch: 5/5, Loss: 0.011607701890170574\n",
      "Epoch: 5/5, Loss: 0.018194854259490967\n",
      "Epoch: 5/5, Loss: 0.016608158126473427\n",
      "Epoch: 5/5, Loss: 0.016581827774643898\n",
      "Epoch: 5/5, Loss: 0.012911658734083176\n",
      "Epoch: 5/5, Loss: 0.007458686828613281\n",
      "Epoch: 5/5, Loss: 0.030187122523784637\n",
      "Epoch: 5/5, Loss: 0.055782705545425415\n",
      "Epoch: 5/5, Loss: 0.023718098178505898\n",
      "Epoch: 5/5, Loss: 0.03003077022731304\n",
      "Epoch: 5/5, Loss: 0.012020640075206757\n",
      "Epoch: 5/5, Loss: 0.026031579822301865\n",
      "Epoch: 5/5, Loss: 0.008767331019043922\n",
      "Epoch: 5/5, Loss: 0.012888006865978241\n",
      "Epoch: 5/5, Loss: 0.015453025698661804\n",
      "Epoch: 5/5, Loss: 0.007762563414871693\n",
      "Epoch: 5/5, Loss: 0.02181047946214676\n",
      "Epoch: 5/5, Loss: 0.00419836537912488\n",
      "Epoch: 5/5, Loss: 0.019407954066991806\n",
      "Epoch: 5/5, Loss: 0.005161023698747158\n",
      "Epoch: 5/5, Loss: 0.013638438656926155\n",
      "Epoch: 5/5, Loss: 0.0429009273648262\n",
      "Epoch: 5/5, Loss: 0.0005684664938598871\n",
      "Epoch: 5/5, Loss: 0.03811737895011902\n",
      "Epoch: 5/5, Loss: 0.005921776406466961\n",
      "Epoch: 5/5, Loss: 0.019850697368383408\n",
      "Epoch: 5/5, Loss: 0.017774280160665512\n",
      "Epoch: 5/5, Loss: 0.01607365533709526\n",
      "Epoch: 5/5, Loss: 0.02108292654156685\n",
      "Epoch: 5/5, Loss: 0.002685653045773506\n",
      "Epoch: 5/5, Loss: 0.010006878525018692\n",
      "Epoch: 5/5, Loss: 0.0034762511495500803\n",
      "Epoch: 5/5, Loss: 0.010774181224405766\n",
      "Epoch: 5/5, Loss: 0.006413859780877829\n",
      "Epoch: 5/5, Loss: 0.024371379986405373\n",
      "Epoch: 5/5, Loss: 0.010627957060933113\n",
      "Epoch: 5/5, Loss: 0.03194066137075424\n",
      "Epoch: 5/5, Loss: 0.020442962646484375\n",
      "Epoch: 5/5, Loss: 0.03963271901011467\n",
      "Epoch: 5/5, Loss: 0.00783679448068142\n",
      "Epoch: 5/5, Loss: 0.006983860861510038\n",
      "Epoch: 5/5, Loss: 0.01568613387644291\n",
      "Epoch: 5/5, Loss: 0.016651030629873276\n",
      "Epoch: 5/5, Loss: 0.008179020136594772\n",
      "Epoch: 5/5, Loss: 0.013231628574430943\n",
      "Epoch: 5/5, Loss: 0.01796475239098072\n",
      "Epoch: 5/5, Loss: 0.026026874780654907\n",
      "Epoch: 5/5, Loss: 0.02310040220618248\n",
      "Epoch: 5/5, Loss: 0.015384272672235966\n",
      "Epoch: 5/5, Loss: 0.01345090288668871\n",
      "Epoch: 5/5, Loss: 0.04016361013054848\n",
      "Epoch: 5/5, Loss: 0.02542218752205372\n",
      "Epoch: 5/5, Loss: 0.0626722127199173\n",
      "Epoch: 5/5, Loss: 0.012853250838816166\n",
      "Epoch: 5/5, Loss: 0.009881028905510902\n",
      "Epoch: 5/5, Loss: 0.02514461800456047\n",
      "Epoch: 5/5, Loss: 0.013912880793213844\n",
      "Epoch: 5/5, Loss: 0.005516247823834419\n",
      "Epoch: 5/5, Loss: 0.032440051436424255\n",
      "Epoch: 5/5, Loss: 0.007196030113846064\n",
      "Epoch: 5/5, Loss: 0.002038548933342099\n",
      "Epoch: 5/5, Loss: 0.049467768520116806\n",
      "Epoch: 5/5, Loss: 0.007282385602593422\n",
      "Epoch: 5/5, Loss: 0.01918877474963665\n",
      "Epoch: 5/5, Loss: 0.03565727919340134\n",
      "Epoch: 5/5, Loss: 0.0057625374756753445\n",
      "Epoch: 5/5, Loss: 0.043824728578329086\n",
      "Epoch: 5/5, Loss: 0.00904148630797863\n",
      "Epoch: 5/5, Loss: 0.0040289973840117455\n",
      "Epoch: 5/5, Loss: 0.0014443050604313612\n",
      "Epoch: 5/5, Loss: 0.010104780085384846\n",
      "Epoch: 5/5, Loss: 0.04061655327677727\n",
      "Epoch: 5/5, Loss: 0.011613172478973866\n",
      "Epoch: 5/5, Loss: 0.009502989239990711\n",
      "Epoch: 5/5, Loss: 0.00022536076721735299\n",
      "Epoch: 5/5, Loss: 0.013827675953507423\n",
      "Epoch: 5/5, Loss: 0.008510146290063858\n",
      "Epoch: 5/5, Loss: 0.01507087517529726\n",
      "Epoch: 5/5, Loss: 0.010213105008006096\n",
      "Epoch: 5/5, Loss: 0.02892148867249489\n",
      "Epoch: 5/5, Loss: 0.0071794502437114716\n",
      "Epoch: 5/5, Loss: 0.002053478267043829\n",
      "Epoch: 5/5, Loss: 0.019900038838386536\n",
      "Epoch: 5/5, Loss: 0.02950715832412243\n",
      "Epoch: 5/5, Loss: 0.01668795756995678\n",
      "Epoch: 5/5, Loss: 0.021826544776558876\n",
      "Epoch: 5/5, Loss: 0.021534215658903122\n",
      "Epoch: 5/5, Loss: 0.01255575567483902\n",
      "Epoch: 5/5, Loss: 0.03689705953001976\n",
      "Epoch: 5/5, Loss: 0.011101868003606796\n",
      "Epoch: 5/5, Loss: 0.005400987807661295\n",
      "Epoch: 5/5, Loss: 0.004876915831118822\n",
      "Epoch: 5/5, Loss: 0.022508379071950912\n",
      "Epoch: 5/5, Loss: 0.03172283247113228\n",
      "Epoch: 5/5, Loss: 0.018932294100522995\n",
      "Epoch: 5/5, Loss: 0.028069457039237022\n",
      "Epoch: 5/5, Loss: 0.013469732366502285\n",
      "Epoch: 5/5, Loss: 0.014991058968007565\n",
      "Epoch: 5/5, Loss: 0.016886547207832336\n",
      "Epoch: 5/5, Loss: 0.007366055157035589\n",
      "Epoch: 5/5, Loss: 0.029616322368383408\n",
      "Epoch: 5/5, Loss: 0.011898641474545002\n",
      "Epoch: 5/5, Loss: 0.026844631880521774\n",
      "Epoch: 5/5, Loss: 0.014696087688207626\n",
      "Epoch: 5/5, Loss: 0.013482801616191864\n",
      "Epoch: 5/5, Loss: 0.010826761834323406\n",
      "Epoch: 5/5, Loss: 0.008476752787828445\n",
      "Epoch: 5/5, Loss: 0.032870203256607056\n",
      "Epoch: 5/5, Loss: 0.006247927434742451\n",
      "Epoch: 5/5, Loss: 0.01005160715430975\n",
      "Epoch: 5/5, Loss: 0.019038157537579536\n",
      "Epoch: 5/5, Loss: 0.022197309881448746\n",
      "Epoch: 5/5, Loss: 0.02516551874577999\n",
      "Epoch: 5/5, Loss: 0.007948512211441994\n",
      "Epoch: 5/5, Loss: 0.005599050782620907\n",
      "Epoch: 5/5, Loss: 0.008486364968121052\n",
      "Epoch: 5/5, Loss: 0.016562504693865776\n",
      "Epoch: 5/5, Loss: 0.005904356949031353\n",
      "Epoch: 5/5, Loss: 0.0024006711319088936\n",
      "Epoch: 5/5, Loss: 0.010070965625345707\n",
      "Epoch: 5/5, Loss: 0.12623842060565948\n",
      "Epoch: 5/5, Loss: 0.017370551824569702\n",
      "Epoch: 5/5, Loss: 0.014916827902197838\n",
      "Epoch: 5/5, Loss: 0.011212978512048721\n",
      "Epoch: 5/5, Loss: 0.009994863532483578\n",
      "Epoch: 5/5, Loss: 0.01705607771873474\n",
      "Epoch: 5/5, Loss: 0.016281504184007645\n",
      "Epoch: 5/5, Loss: 0.028735898435115814\n",
      "Epoch: 5/5, Loss: 0.014287030324339867\n",
      "Epoch: 5/5, Loss: 0.013705704361200333\n",
      "Epoch: 5/5, Loss: 0.02086481638252735\n",
      "Epoch: 5/5, Loss: 0.006318436935544014\n",
      "Epoch: 5/5, Loss: 0.0401194803416729\n",
      "Epoch: 5/5, Loss: 0.010601453483104706\n",
      "Epoch: 5/5, Loss: 0.008956783451139927\n",
      "Epoch: 5/5, Loss: 0.043566036969423294\n",
      "Epoch: 5/5, Loss: 0.002250371966511011\n",
      "Epoch: 5/5, Loss: 0.03815045580267906\n",
      "Epoch: 5/5, Loss: 0.019738968461751938\n",
      "Epoch: 5/5, Loss: 0.011400504969060421\n",
      "Epoch: 5/5, Loss: 0.017445433884859085\n",
      "Epoch: 5/5, Loss: 0.016323499381542206\n",
      "Epoch: 5/5, Loss: 0.00540454825386405\n",
      "Epoch: 5/5, Loss: 0.027835752815008163\n",
      "Epoch: 5/5, Loss: 0.03597892075777054\n",
      "Epoch: 5/5, Loss: 0.0270646121352911\n",
      "Epoch: 5/5, Loss: 0.04115621745586395\n",
      "Epoch: 5/5, Loss: 0.02181987650692463\n",
      "Epoch: 5/5, Loss: 0.011945263482630253\n",
      "Epoch: 5/5, Loss: 0.00743511039763689\n",
      "Epoch: 5/5, Loss: 0.008495519869029522\n",
      "Epoch: 5/5, Loss: 0.02121526189148426\n",
      "Epoch: 5/5, Loss: 0.014455841854214668\n",
      "Epoch: 5/5, Loss: 0.04572858288884163\n",
      "Epoch: 5/5, Loss: 0.01506030187010765\n",
      "Epoch: 5/5, Loss: 0.03481382876634598\n",
      "Epoch: 5/5, Loss: 0.015134438872337341\n",
      "Epoch: 5/5, Loss: 0.025672491639852524\n",
      "Epoch: 5/5, Loss: 0.0319126732647419\n",
      "Epoch: 5/5, Loss: 0.024310505017638206\n",
      "Epoch: 5/5, Loss: 0.02848622016608715\n",
      "Epoch: 5/5, Loss: 0.012860230170190334\n",
      "Epoch: 5/5, Loss: 0.029229260981082916\n",
      "Epoch: 5/5, Loss: 0.1065775603055954\n",
      "Epoch: 5/5, Loss: 0.026998233050107956\n",
      "Epoch: 5/5, Loss: 0.00504233269020915\n",
      "Epoch: 5/5, Loss: 0.016777146607637405\n",
      "Epoch: 5/5, Loss: 0.0196706410497427\n",
      "Epoch: 5/5, Loss: 0.01046035997569561\n",
      "Epoch: 5/5, Loss: 0.017203977331519127\n",
      "Epoch: 5/5, Loss: 0.016723088920116425\n",
      "Epoch: 5/5, Loss: 0.020145032554864883\n",
      "Epoch: 5/5, Loss: 0.00850125402212143\n",
      "Epoch: 5/5, Loss: 0.03423473984003067\n",
      "Epoch: 5/5, Loss: 0.015634695068001747\n",
      "Epoch: 5/5, Loss: 0.008831263519823551\n",
      "Epoch: 5/5, Loss: 0.007807926740497351\n",
      "Epoch: 5/5, Loss: 0.01469329372048378\n",
      "Epoch: 5/5, Loss: 0.040958624333143234\n",
      "Epoch: 5/5, Loss: 0.046410150825977325\n",
      "Epoch: 5/5, Loss: 0.021101713180541992\n",
      "Epoch: 5/5, Loss: 0.018171709030866623\n",
      "Epoch: 5/5, Loss: 0.014367446303367615\n",
      "Epoch: 5/5, Loss: 0.002316777827218175\n",
      "Epoch: 5/5, Loss: 0.005863547325134277\n",
      "Epoch: 5/5, Loss: 0.017276925966143608\n",
      "Epoch: 5/5, Loss: 0.019994836300611496\n",
      "Epoch: 5/5, Loss: 0.13445110619068146\n",
      "Epoch: 5/5, Loss: 0.05393407121300697\n",
      "Epoch: 5/5, Loss: 0.017304379492998123\n",
      "Epoch: 5/5, Loss: 0.013050145469605923\n",
      "Epoch: 5/5, Loss: 0.017747417092323303\n",
      "Epoch: 5/5, Loss: 0.034659646451473236\n",
      "Epoch: 5/5, Loss: 0.005707084201276302\n",
      "Epoch: 5/5, Loss: 0.012698703445494175\n",
      "Epoch: 5/5, Loss: 0.015134049579501152\n",
      "Epoch: 5/5, Loss: 0.00068899046164006\n",
      "Epoch: 5/5, Loss: 0.020807364955544472\n",
      "Epoch: 5/5, Loss: 0.011523754335939884\n",
      "Epoch: 5/5, Loss: 0.032692570239305496\n",
      "Epoch: 5/5, Loss: 0.02000066637992859\n",
      "Epoch: 5/5, Loss: 0.0205247700214386\n",
      "Epoch: 5/5, Loss: 0.008797463960945606\n",
      "Epoch: 5/5, Loss: 0.012253489345312119\n",
      "Epoch: 5/5, Loss: 0.010678570717573166\n",
      "Epoch: 5/5, Loss: 0.03612786531448364\n",
      "Epoch: 5/5, Loss: 0.011024207808077335\n",
      "Epoch: 5/5, Loss: 0.004579344764351845\n",
      "Epoch: 5/5, Loss: 0.023823736235499382\n",
      "Epoch: 5/5, Loss: 0.016318153589963913\n",
      "Epoch: 5/5, Loss: 0.008964124135673046\n",
      "Epoch: 5/5, Loss: 0.011440111324191093\n",
      "Epoch: 5/5, Loss: 0.006427528336644173\n",
      "Epoch: 5/5, Loss: 0.005445094313472509\n",
      "Epoch: 5/5, Loss: 0.017323287203907967\n",
      "Epoch: 5/5, Loss: 0.02909022569656372\n",
      "Epoch: 5/5, Loss: 0.013674388639628887\n",
      "Epoch: 5/5, Loss: 0.005491212941706181\n",
      "Epoch: 5/5, Loss: 0.007565803825855255\n",
      "Epoch: 5/5, Loss: 0.03180844709277153\n",
      "Epoch: 5/5, Loss: 0.012044254690408707\n",
      "Epoch: 5/5, Loss: 0.003047714941203594\n",
      "Epoch: 5/5, Loss: 0.034144770354032516\n",
      "Epoch: 5/5, Loss: 0.02004101499915123\n",
      "Epoch: 5/5, Loss: 0.002063157968223095\n",
      "Epoch: 5/5, Loss: 0.030546240508556366\n",
      "Epoch: 5/5, Loss: 0.025187557563185692\n",
      "Epoch: 5/5, Loss: 0.024712543934583664\n",
      "Epoch: 5/5, Loss: 0.0597476102411747\n",
      "Epoch: 5/5, Loss: 0.008889509364962578\n",
      "Epoch: 5/5, Loss: 0.003549919929355383\n",
      "Epoch: 5/5, Loss: 0.012045161798596382\n",
      "Epoch: 5/5, Loss: 0.0005565254832617939\n",
      "Epoch: 5/5, Loss: 0.009180035442113876\n",
      "Epoch: 5/5, Loss: 0.01780427247285843\n",
      "Epoch: 5/5, Loss: 0.008421828970313072\n",
      "Epoch: 5/5, Loss: 0.044594742357730865\n",
      "Epoch: 5/5, Loss: 0.018703043460845947\n",
      "Epoch: 5/5, Loss: 0.01677602343261242\n",
      "Epoch: 5/5, Loss: 0.012384096160531044\n",
      "Epoch: 5/5, Loss: 0.01589152403175831\n",
      "Epoch: 5/5, Loss: 0.002474449574947357\n",
      "Epoch: 5/5, Loss: 0.021374991163611412\n",
      "Epoch: 5/5, Loss: 0.007888407446444035\n",
      "Epoch: 5/5, Loss: 0.02336967922747135\n",
      "Epoch: 5/5, Loss: 0.04024828225374222\n",
      "Epoch: 5/5, Loss: 0.019587188959121704\n",
      "Epoch: 5/5, Loss: 0.011976874433457851\n",
      "Epoch: 5/5, Loss: 0.025861239060759544\n",
      "Epoch: 5/5, Loss: 0.01589668169617653\n",
      "Epoch: 5/5, Loss: 0.01902850717306137\n",
      "Epoch: 5/5, Loss: 0.02029743418097496\n",
      "Epoch: 5/5, Loss: 0.01892751082777977\n",
      "Epoch: 5/5, Loss: 0.00882391631603241\n",
      "Epoch: 5/5, Loss: 0.021137820556759834\n",
      "Epoch: 5/5, Loss: 0.021630534902215004\n",
      "Epoch: 5/5, Loss: 0.007244376465678215\n",
      "Epoch: 5/5, Loss: 0.10994609445333481\n",
      "Epoch: 5/5, Loss: 0.03837970271706581\n",
      "Epoch: 5/5, Loss: 0.010755191557109356\n",
      "Epoch: 5/5, Loss: 0.019968891516327858\n",
      "Epoch: 5/5, Loss: 0.0021991566754877567\n",
      "Epoch: 5/5, Loss: 0.023804523050785065\n",
      "Epoch: 5/5, Loss: 0.016594039276242256\n",
      "Epoch: 5/5, Loss: 0.023452170193195343\n",
      "Epoch: 5/5, Loss: 0.03313080593943596\n",
      "Epoch: 5/5, Loss: 0.015073463320732117\n",
      "Epoch: 5/5, Loss: 0.029155634343624115\n",
      "Epoch: 5/5, Loss: 0.040480367839336395\n",
      "Epoch: 5/5, Loss: 0.018376896157860756\n",
      "Epoch: 5/5, Loss: 0.020422516390681267\n",
      "Epoch: 5/5, Loss: 0.008720139972865582\n",
      "Epoch: 5/5, Loss: 0.028674107044935226\n",
      "Epoch: 5/5, Loss: 0.007733573205769062\n",
      "Epoch: 5/5, Loss: 0.008908985182642937\n",
      "Epoch: 5/5, Loss: 0.010227786377072334\n",
      "Epoch: 5/5, Loss: 0.023113610222935677\n",
      "Epoch: 5/5, Loss: 0.008278695866465569\n",
      "Epoch: 5/5, Loss: 0.0384739488363266\n",
      "Epoch: 5/5, Loss: 0.0030103670433163643\n",
      "Epoch: 5/5, Loss: 0.0010399847524240613\n",
      "Epoch: 5/5, Loss: 0.0010736169060692191\n",
      "Epoch: 5/5, Loss: 0.05922491475939751\n",
      "Epoch: 5/5, Loss: 0.007651605177670717\n",
      "Epoch: 5/5, Loss: 0.0580768957734108\n",
      "Epoch: 5/5, Loss: 0.005621946416795254\n",
      "Epoch: 5/5, Loss: 0.007006702478975058\n",
      "Epoch: 5/5, Loss: 0.04415716230869293\n",
      "Epoch: 5/5, Loss: 0.007594142109155655\n",
      "Epoch: 5/5, Loss: 0.015415452420711517\n",
      "Epoch: 5/5, Loss: 0.014754275791347027\n",
      "Epoch: 5/5, Loss: 0.002181712305173278\n",
      "Epoch: 5/5, Loss: 0.005073098000138998\n",
      "Epoch: 5/5, Loss: 0.02155858464539051\n",
      "Epoch: 5/5, Loss: 0.030774466693401337\n",
      "Epoch: 5/5, Loss: 0.0038154451176524162\n",
      "Epoch: 5/5, Loss: 0.016153069213032722\n",
      "Epoch: 5/5, Loss: 0.009179152548313141\n",
      "Epoch: 5/5, Loss: 0.01753699593245983\n",
      "Epoch: 5/5, Loss: 0.004666667897254229\n",
      "Epoch: 5/5, Loss: 0.010464856401085854\n",
      "Epoch: 5/5, Loss: 0.04308183491230011\n",
      "Epoch: 5/5, Loss: 0.00282061449252069\n",
      "Epoch: 5/5, Loss: 0.007787781767547131\n",
      "Epoch: 5/5, Loss: 0.020445607602596283\n",
      "Epoch: 5/5, Loss: 0.0019539499189704657\n",
      "Epoch: 5/5, Loss: 0.040334731340408325\n",
      "Epoch: 5/5, Loss: 0.0121538070961833\n",
      "Epoch: 5/5, Loss: 0.012172909453511238\n",
      "Epoch: 5/5, Loss: 0.06214988976716995\n",
      "Epoch: 5/5, Loss: 0.0224729236215353\n",
      "Epoch: 5/5, Loss: 0.006014701444655657\n",
      "Epoch: 5/5, Loss: 0.05627935752272606\n",
      "Epoch: 5/5, Loss: 0.005011999513953924\n",
      "Epoch: 5/5, Loss: 0.040043119341135025\n",
      "Epoch: 5/5, Loss: 0.033038899302482605\n",
      "Epoch: 5/5, Loss: 0.006654527969658375\n",
      "Epoch: 5/5, Loss: 0.031890012323856354\n",
      "Epoch: 5/5, Loss: 0.008146345615386963\n",
      "Epoch: 5/5, Loss: 0.03458121791481972\n",
      "Epoch: 5/5, Loss: 0.0016076292376965284\n",
      "Epoch: 5/5, Loss: 0.025319715961813927\n",
      "Epoch: 5/5, Loss: 0.030913256108760834\n",
      "Epoch: 5/5, Loss: 0.005964083131402731\n",
      "Epoch: 5/5, Loss: 0.04101501777768135\n",
      "Epoch: 5/5, Loss: 0.04668130725622177\n",
      "Epoch: 5/5, Loss: 0.020365707576274872\n",
      "Epoch: 5/5, Loss: 0.02861335128545761\n",
      "Epoch: 5/5, Loss: 0.00869810301810503\n",
      "Epoch: 5/5, Loss: 0.019775355234742165\n",
      "Epoch: 5/5, Loss: 0.0164811834692955\n",
      "Epoch: 5/5, Loss: 0.01212735939770937\n",
      "Epoch: 5/5, Loss: 0.0447688028216362\n",
      "Epoch: 5/5, Loss: 0.023989025503396988\n",
      "Epoch: 5/5, Loss: 0.006038630846887827\n",
      "Epoch: 5/5, Loss: 0.029048532247543335\n",
      "Epoch: 5/5, Loss: 0.009386546909809113\n",
      "Epoch: 5/5, Loss: 0.009222863242030144\n",
      "Epoch: 5/5, Loss: 0.020297640934586525\n",
      "Epoch: 5/5, Loss: 0.13596652448177338\n",
      "Epoch: 5/5, Loss: 0.012871989980340004\n",
      "Epoch: 5/5, Loss: 0.011539575643837452\n",
      "Epoch: 5/5, Loss: 0.013937892392277718\n",
      "Epoch: 5/5, Loss: 0.016451522707939148\n",
      "Epoch: 5/5, Loss: 0.025455661118030548\n",
      "Epoch: 5/5, Loss: 0.04914344474673271\n",
      "Epoch: 5/5, Loss: 0.0773545354604721\n",
      "Epoch: 5/5, Loss: 0.008589448407292366\n",
      "Epoch: 5/5, Loss: 0.009205730631947517\n",
      "Epoch: 5/5, Loss: 0.007927658967673779\n",
      "Epoch: 5/5, Loss: 0.006857431028038263\n",
      "Epoch: 5/5, Loss: 0.014106947928667068\n",
      "Epoch: 5/5, Loss: 0.0017737643793225288\n",
      "Epoch: 5/5, Loss: 0.01187841221690178\n",
      "Epoch: 5/5, Loss: 0.013636583462357521\n",
      "Epoch: 5/5, Loss: 0.011124992743134499\n",
      "Epoch: 5/5, Loss: 0.018575703725218773\n",
      "Epoch: 5/5, Loss: 0.0190057922154665\n",
      "Epoch: 5/5, Loss: 0.020898710936307907\n",
      "Epoch: 5/5, Loss: 0.023691829293966293\n",
      "Epoch: 5/5, Loss: 0.009190063923597336\n",
      "Epoch: 5/5, Loss: 0.009796148166060448\n",
      "Epoch: 5/5, Loss: 0.02072913385927677\n",
      "Epoch: 5/5, Loss: 0.026953797787427902\n",
      "Epoch: 5/5, Loss: 0.005974878557026386\n",
      "Epoch: 5/5, Loss: 0.010117166675627232\n",
      "Epoch: 5/5, Loss: 0.012790439650416374\n",
      "Epoch: 5/5, Loss: 0.009997386485338211\n",
      "Epoch: 5/5, Loss: 0.0239157285541296\n",
      "Epoch: 5/5, Loss: 0.024310654029250145\n",
      "Epoch: 5/5, Loss: 0.019037287682294846\n",
      "Epoch: 5/5, Loss: 0.012461110949516296\n",
      "Epoch: 5/5, Loss: 0.030515480786561966\n",
      "Epoch: 5/5, Loss: 0.008347609080374241\n",
      "Epoch: 5/5, Loss: 0.05898919701576233\n",
      "Epoch: 5/5, Loss: 0.046265777200460434\n",
      "Epoch: 5/5, Loss: 0.0124112069606781\n",
      "Epoch: 5/5, Loss: 0.013600749894976616\n",
      "Epoch: 5/5, Loss: 0.01070508360862732\n",
      "Epoch: 5/5, Loss: 0.0062063345685601234\n",
      "Epoch: 5/5, Loss: 0.002472230466082692\n",
      "Epoch: 5/5, Loss: 0.025080811232328415\n",
      "Epoch: 5/5, Loss: 0.05412549898028374\n",
      "Epoch: 5/5, Loss: 0.0197159256786108\n",
      "Epoch: 5/5, Loss: 0.03436993062496185\n",
      "Epoch: 5/5, Loss: 0.021781206130981445\n",
      "Epoch: 5/5, Loss: 0.0159415565431118\n",
      "Epoch: 5/5, Loss: 0.016990303993225098\n",
      "Epoch: 5/5, Loss: 0.014626392163336277\n",
      "Epoch: 5/5, Loss: 0.0340428464114666\n",
      "Epoch: 5/5, Loss: 0.017282355576753616\n",
      "Epoch: 5/5, Loss: 0.010316096246242523\n",
      "Epoch: 5/5, Loss: 0.027795055881142616\n",
      "Epoch: 5/5, Loss: 0.022263281047344208\n",
      "Epoch: 5/5, Loss: 0.03549632057547569\n",
      "Epoch: 5/5, Loss: 0.02667560800909996\n",
      "Epoch: 5/5, Loss: 0.005677955225110054\n",
      "Epoch: 5/5, Loss: 0.030389998108148575\n",
      "Epoch: 5/5, Loss: 0.013935971073806286\n",
      "Epoch: 5/5, Loss: 0.007987156510353088\n",
      "Epoch: 5/5, Loss: 0.013113337568938732\n",
      "Epoch: 5/5, Loss: 0.014322481118142605\n",
      "Epoch: 5/5, Loss: 0.03425449877977371\n",
      "Epoch: 5/5, Loss: 0.026242408901453018\n",
      "Epoch: 5/5, Loss: 0.018390707671642303\n",
      "Epoch: 5/5, Loss: 0.013163797557353973\n",
      "Epoch: 5/5, Loss: 0.005904364865273237\n",
      "Epoch: 5/5, Loss: 0.039583444595336914\n",
      "Epoch: 5/5, Loss: 0.007706643082201481\n",
      "Epoch: 5/5, Loss: 0.019138846546411514\n",
      "Epoch: 5/5, Loss: 0.009969684295356274\n",
      "Epoch: 5/5, Loss: 0.03439808264374733\n",
      "Epoch: 5/5, Loss: 0.009668445214629173\n",
      "Epoch: 5/5, Loss: 0.013380033895373344\n",
      "Epoch: 5/5, Loss: 0.023088645190000534\n",
      "Epoch: 5/5, Loss: 0.022693315520882607\n",
      "Epoch: 5/5, Loss: 0.035380419343709946\n",
      "Epoch: 5/5, Loss: 0.006388095673173666\n",
      "Epoch: 5/5, Loss: 0.013304022140800953\n",
      "Epoch: 5/5, Loss: 0.03309190273284912\n",
      "Epoch: 5/5, Loss: 0.054990921169519424\n",
      "Epoch: 5/5, Loss: 0.11802222579717636\n",
      "Epoch: 5/5, Loss: 0.001634395681321621\n",
      "Epoch: 5/5, Loss: 0.01518619991838932\n",
      "Epoch: 5/5, Loss: 0.045726675540208817\n",
      "Epoch: 5/5, Loss: 0.03571387380361557\n",
      "Epoch: 5/5, Loss: 0.05139908939599991\n",
      "Epoch: 5/5, Loss: 0.006071674171835184\n",
      "Epoch: 5/5, Loss: 0.020416000857949257\n",
      "Epoch: 5/5, Loss: 0.0386466309428215\n",
      "Epoch: 5/5, Loss: 0.01703595370054245\n",
      "Epoch: 5/5, Loss: 0.010923231020569801\n",
      "Epoch: 5/5, Loss: 0.010353484191000462\n",
      "Epoch: 5/5, Loss: 0.02830442413687706\n",
      "Epoch: 5/5, Loss: 0.007053225766867399\n",
      "Epoch: 5/5, Loss: 0.010590444318950176\n",
      "Epoch: 5/5, Loss: 0.006181175820529461\n",
      "Epoch: 5/5, Loss: 0.014707431197166443\n",
      "Epoch: 5/5, Loss: 0.02119397558271885\n",
      "Epoch: 5/5, Loss: 0.014412268064916134\n",
      "Epoch: 5/5, Loss: 0.03406016156077385\n",
      "Epoch: 5/5, Loss: 0.012822908349335194\n",
      "Epoch: 5/5, Loss: 0.0006552011473104358\n",
      "Epoch: 5/5, Loss: 0.018777819350361824\n",
      "Epoch: 5/5, Loss: 0.007479633204638958\n",
      "Epoch: 5/5, Loss: 0.01939244568347931\n",
      "Epoch: 5/5, Loss: 0.032161492854356766\n",
      "Epoch: 5/5, Loss: 0.0018265703693032265\n",
      "Epoch: 5/5, Loss: 0.04199831932783127\n",
      "Epoch: 5/5, Loss: 0.02373315393924713\n",
      "Epoch: 5/5, Loss: 0.04404331371188164\n",
      "Epoch: 5/5, Loss: 0.004301241599023342\n",
      "Epoch: 5/5, Loss: 0.021516738459467888\n",
      "Epoch: 5/5, Loss: 0.04205062985420227\n",
      "Epoch: 5/5, Loss: 0.01489347219467163\n",
      "Epoch: 5/5, Loss: 0.02736854925751686\n",
      "Epoch: 5/5, Loss: 0.03860030323266983\n",
      "Epoch: 5/5, Loss: 0.014417783357203007\n",
      "Epoch: 5/5, Loss: 0.011027420870959759\n",
      "Epoch: 5/5, Loss: 0.019734641537070274\n",
      "Epoch: 5/5, Loss: 0.029029686003923416\n",
      "Epoch: 5/5, Loss: 0.013049762696027756\n",
      "Epoch: 5/5, Loss: 0.011011560447514057\n",
      "Epoch: 5/5, Loss: 0.013598594814538956\n",
      "Epoch: 5/5, Loss: 0.010373897850513458\n",
      "Epoch: 5/5, Loss: 0.01122904010117054\n",
      "Epoch: 5/5, Loss: 0.002993805566802621\n",
      "Epoch: 5/5, Loss: 0.005747809074819088\n",
      "Epoch: 5/5, Loss: 0.019491735845804214\n",
      "Epoch: 5/5, Loss: 0.013539888896048069\n",
      "Epoch: 5/5, Loss: 0.024278216063976288\n",
      "Epoch: 5/5, Loss: 0.009485657326877117\n",
      "Epoch: 5/5, Loss: 0.05656924843788147\n",
      "Epoch: 5/5, Loss: 0.030978064984083176\n",
      "Epoch: 5/5, Loss: 0.01771336980164051\n",
      "Epoch: 5/5, Loss: 0.007357660215348005\n",
      "Epoch: 5/5, Loss: 0.006804137025028467\n",
      "Epoch: 5/5, Loss: 0.017284540459513664\n",
      "Epoch: 5/5, Loss: 0.009670750238001347\n",
      "Epoch: 5/5, Loss: 0.008634790778160095\n",
      "Epoch: 5/5, Loss: 0.015462778508663177\n",
      "Epoch: 5/5, Loss: 0.020264368504285812\n",
      "Epoch: 5/5, Loss: 0.011256848461925983\n",
      "Epoch: 5/5, Loss: 0.03053908795118332\n",
      "Epoch: 5/5, Loss: 0.025642842054367065\n",
      "Epoch: 5/5, Loss: 0.04996604099869728\n",
      "Epoch: 5/5, Loss: 0.0066514285281300545\n",
      "Epoch: 5/5, Loss: 0.03537440299987793\n",
      "Epoch: 5/5, Loss: 0.0005182233871892095\n",
      "Epoch: 5/5, Loss: 0.06301845610141754\n",
      "Epoch: 5/5, Loss: 0.008026991039514542\n",
      "Epoch: 5/5, Loss: 0.004026456736028194\n",
      "Epoch: 5/5, Loss: 0.019666656851768494\n",
      "Epoch: 5/5, Loss: 0.0262785404920578\n",
      "Epoch: 5/5, Loss: 0.003415829734876752\n",
      "Epoch: 5/5, Loss: 0.012500263750553131\n",
      "Epoch: 5/5, Loss: 0.025986554101109505\n",
      "Epoch: 5/5, Loss: 0.008048967458307743\n",
      "Epoch: 5/5, Loss: 0.010639587417244911\n",
      "Epoch: 5/5, Loss: 0.022533420473337173\n",
      "Epoch: 5/5, Loss: 0.00858631543815136\n",
      "Epoch: 5/5, Loss: 0.006429392844438553\n",
      "Epoch: 5/5, Loss: 0.006638544145971537\n",
      "Epoch: 5/5, Loss: 0.016438733786344528\n",
      "Epoch: 5/5, Loss: 0.10636410117149353\n",
      "Epoch: 5/5, Loss: 0.011574473232030869\n",
      "Epoch: 5/5, Loss: 0.004338926635682583\n",
      "Epoch: 5/5, Loss: 0.0065429722890257835\n",
      "Epoch: 5/5, Loss: 0.015056796371936798\n",
      "Epoch: 5/5, Loss: 0.045627471059560776\n",
      "Epoch: 5/5, Loss: 0.07804018259048462\n",
      "Epoch: 5/5, Loss: 0.023962516337633133\n",
      "Epoch: 5/5, Loss: 0.01008696760982275\n",
      "Epoch: 5/5, Loss: 0.0236486978828907\n",
      "Epoch: 5/5, Loss: 0.044809214770793915\n",
      "Epoch: 5/5, Loss: 0.03237646073102951\n",
      "Epoch: 5/5, Loss: 0.01454458013176918\n",
      "Epoch: 5/5, Loss: 0.00476944399997592\n",
      "Epoch: 5/5, Loss: 0.02237880788743496\n",
      "Epoch: 5/5, Loss: 0.022850118577480316\n",
      "Epoch: 5/5, Loss: 0.005046097561717033\n",
      "Epoch: 5/5, Loss: 0.03229689970612526\n",
      "Epoch: 5/5, Loss: 0.015654347836971283\n",
      "Epoch: 5/5, Loss: 0.03233010694384575\n",
      "Epoch: 5/5, Loss: 0.008021355606615543\n",
      "Epoch: 5/5, Loss: 0.026281440630555153\n",
      "Epoch: 5/5, Loss: 0.01932094246149063\n",
      "Epoch: 5/5, Loss: 0.009656352922320366\n",
      "Epoch: 5/5, Loss: 0.0032675506081432104\n",
      "Epoch: 5/5, Loss: 0.02846788801252842\n",
      "Epoch: 5/5, Loss: 0.026163065806031227\n",
      "Epoch: 5/5, Loss: 0.021830305457115173\n",
      "Epoch: 5/5, Loss: 0.030507352203130722\n",
      "Epoch: 5/5, Loss: 0.023624340072274208\n",
      "Epoch: 5/5, Loss: 0.007860146462917328\n",
      "Epoch: 5/5, Loss: 0.02932458184659481\n",
      "Epoch: 5/5, Loss: 0.006279570050537586\n",
      "Epoch: 5/5, Loss: 0.0063268207013607025\n",
      "Epoch: 5/5, Loss: 0.0041366093792021275\n",
      "Epoch: 5/5, Loss: 0.007616840768605471\n",
      "Epoch: 5/5, Loss: 0.027281593531370163\n",
      "Epoch: 5/5, Loss: 0.005883373785763979\n",
      "Epoch: 5/5, Loss: 0.008642099797725677\n",
      "Epoch: 5/5, Loss: 0.007149420212954283\n",
      "Epoch: 5/5, Loss: 0.01288318820297718\n",
      "Epoch: 5/5, Loss: 0.006264022551476955\n",
      "Epoch: 5/5, Loss: 0.0227711983025074\n",
      "Epoch: 5/5, Loss: 0.02961059659719467\n",
      "Epoch: 5/5, Loss: 0.016317037865519524\n",
      "Epoch: 5/5, Loss: 0.007469807751476765\n",
      "Epoch: 5/5, Loss: 0.030641868710517883\n",
      "Epoch: 5/5, Loss: 0.02285780757665634\n",
      "Epoch: 5/5, Loss: 0.01843581534922123\n",
      "Epoch: 5/5, Loss: 0.0373339019715786\n",
      "Epoch: 5/5, Loss: 0.04500097036361694\n",
      "Epoch: 5/5, Loss: 0.006948051508516073\n",
      "Epoch: 5/5, Loss: 0.012544829398393631\n",
      "Epoch: 5/5, Loss: 0.0018236441537737846\n",
      "Epoch: 5/5, Loss: 0.016569407656788826\n",
      "Epoch: 5/5, Loss: 0.0018345362041145563\n",
      "Epoch: 5/5, Loss: 0.06168055161833763\n",
      "Epoch: 5/5, Loss: 0.02364792302250862\n",
      "Epoch: 5/5, Loss: 0.057348866015672684\n",
      "Epoch: 5/5, Loss: 0.003383851144462824\n",
      "Epoch: 5/5, Loss: 0.033893562853336334\n",
      "Epoch: 5/5, Loss: 0.020181141793727875\n",
      "Epoch: 5/5, Loss: 0.013125063851475716\n",
      "Epoch: 5/5, Loss: 0.025427378714084625\n",
      "Epoch: 5/5, Loss: 0.009136149659752846\n",
      "Epoch: 5/5, Loss: 0.012762276455760002\n",
      "Epoch: 5/5, Loss: 0.0025656912475824356\n",
      "Epoch: 5/5, Loss: 0.11825096607208252\n",
      "Epoch: 5/5, Loss: 0.010129143483936787\n",
      "Epoch: 5/5, Loss: 0.03194272890686989\n",
      "Epoch: 5/5, Loss: 0.019442949444055557\n",
      "Epoch: 5/5, Loss: 0.00305739208124578\n",
      "Epoch: 5/5, Loss: 0.008348282426595688\n",
      "Epoch: 5/5, Loss: 0.024335304275155067\n",
      "Epoch: 5/5, Loss: 0.012957092374563217\n",
      "Epoch: 5/5, Loss: 0.03717312961816788\n",
      "Epoch: 5/5, Loss: 0.0015292554162442684\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        ## setar os gradientes\n",
    "        optimizer.zero_grad()\n",
    "        ## pegando os pacotes separados nos lotes\n",
    "        features, target = data\n",
    "        ## calculando as preds\n",
    "        pred = model(features)\n",
    "        ## Computando as perdas e os gradientes\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "        ## Atualizando a etapa\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show_results(model, dataloader) ## depois que terminar o curso criar essa função para descrever o modelo pra mim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid function Limitações\n",
    "* É limitada entre 0 e 1\n",
    "* Segue uma destribuição normal (graficamente)\n",
    "\n",
    "### SoftMax function\n",
    "* Quando calculamos o gradiente das duas funções elas se aproxima de zero\n",
    "* Também satura.\n",
    "\n",
    "\n",
    "Obs: Saturação acontece quando calculamos o gradiente de uma função e idependente dos sua primeira ou enezima gradiente ela converge para zero.\n",
    "E isso impede que nosso modelo rode $n$ vezes, assim impedindo que o peso seja alterado ou atualizado. (gradiente de fulga)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function ReLU\n",
    "$$ReLU(x)= max(0, x)$$\n",
    "\n",
    "* Não possui limite superior \n",
    "* Os gradientes não convergem para zero o que supera o gradiente de fuga\n",
    "\n",
    "### Function Leaky ReLU\n",
    "* Onde a diferença e apenas que para valores negativos ela tem um fato de multiplicação de x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# Create a ReLU function with PyTorch\n",
    "relu_pytorch = nn.ReLU()\n",
    "\n",
    "# Apply your ReLU function on x, and calculate gradients\n",
    "x = torch.tensor(-1.0, requires_grad=True)\n",
    "y = relu_pytorch(x)\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient of the ReLU function for x\n",
    "gradient = x.grad\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1000)\n"
     ]
    }
   ],
   "source": [
    "# Create a leaky relu function in PyTorch\n",
    "leaky_relu_pytorch = nn.LeakyReLU(negative_slope=0.05)\n",
    "\n",
    "x = torch.tensor(-2.0)\n",
    "# Call the above function on the tensor x\n",
    "output = leaky_relu_pytorch(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitetura de modelos\n",
    "Lembre-se que quando cada neuronio da camada está conectada a cada neuronio da camada anterior chamamos de camadas completamente conectadas. \n",
    "Cada neuronio de uma camada linear calculará um operação linear usando todos os neuronios da camada anterior.\n",
    "\n",
    "Ou seja cada neuronio tem $n+1$ que  e o parametro que pode ser aprendido mais um para o vies.\n",
    "\n",
    "**Redes Neurais Totalmente Conectadas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 8\n",
    "n_classes = 2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 4),\n",
    "    nn.Linear(4, 2),\n",
    ")\n",
    "\n",
    "## Temos duas camadas ocultas nesse modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "total = 0 \n",
    "for parameter in model.parameters():\n",
    "    total += parameter.numel()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_capacity(model):\n",
    "    total = 0\n",
    "    for p in model.parameters():\n",
    "        total += p.numel()\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimizador impactando no treinamento\n",
    "O que controla a inercia do otimizador e o momentum\n",
    "* Encontrar bons valores para a taxa de aprendizado e o impulso e fundamental para diminuir o tempo de treinamento do modelo ou mau desempenho.\n",
    "* Um dos maiores desafios e tentar encontrar o minimo de uma função não convexa e ficar preso em um minimo local.\n",
    "\n",
    "**Resumo**\n",
    "* Momento: Controla a inercia do otimizador, sem impulso o otimizador pode ficar preso em um otimo local. Ele varia de $0.85$ a $0.99$\n",
    "* Taxa de aprendizado: lr Tamanho da taxa do peso executado pelo otimizador variam $10^{-2}$ a $10^{-4}$ se a essa taxa for muito alta o otimizador podera nunca conseguir minimizar a função perda. E se tiver muito baixo o trinamento pode demorar mais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1249, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1250, grad_fn=<MinBackward1>)\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Linear(64, 128)\n",
    "\n",
    "print(layer.weight.max())\n",
    "print(layer.weight.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obs\n",
    "Engenheiros de machine learning nunca se baseam por pesos ja inicializados, geralmente utilizam um conceito chamado aprendizado por transferência.\n",
    "* O conceito se consiste em pegar um modelo treinado em uma tarefa e reutiliza-lo para a segunda tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Linear(64, 128)\n",
    "torch.save(layer, \"layer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_layer = torch.load(\"layer.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Podemos treinar uma parte so da rede neural\n",
    "* As camadas iniciais não precisão ser treinadas\n",
    "* Então podemos optar por congelar elas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(64, 128),\n",
    "    nn.Linear(128,256)\n",
    ")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name == \"0.weight\":\n",
    "        param.requires_grad = False ## definimos aqui como falso caso quera não carregar o gradiente 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ou podemos usar como\n",
    "for name, param in model.named_parameters():\n",
    "    # Check if the parameters belong to the first layer\n",
    "    if name == \"0.weight\" or name == \"0.bias\":\n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Check if the parameters belong to the second layer\n",
    "    if name == \"1.weight\" or name == \"1.bias\":\n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.8619, 0.7154, 0.1086,  ..., 0.3816, 0.5425, 0.2126],\n",
       "        [0.6017, 0.3698, 0.1405,  ..., 0.1874, 0.8832, 0.8190],\n",
       "        [0.3402, 0.1036, 0.1456,  ..., 0.7385, 0.8668, 0.2890],\n",
       "        ...,\n",
       "        [0.1188, 0.5179, 0.0949,  ..., 0.7750, 0.1203, 0.3434],\n",
       "        [0.3661, 0.6592, 0.4645,  ..., 0.7458, 0.4171, 0.3171],\n",
       "        [0.9486, 0.5198, 0.5865,  ..., 0.2267, 0.9688, 0.5751]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.uniform_(layer.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/zoo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal_name</th>\n",
       "      <th>hair</th>\n",
       "      <th>feathers</th>\n",
       "      <th>eggs</th>\n",
       "      <th>milk</th>\n",
       "      <th>airborne</th>\n",
       "      <th>aquatic</th>\n",
       "      <th>predator</th>\n",
       "      <th>toothed</th>\n",
       "      <th>backbone</th>\n",
       "      <th>breathes</th>\n",
       "      <th>venomous</th>\n",
       "      <th>fins</th>\n",
       "      <th>legs</th>\n",
       "      <th>tail</th>\n",
       "      <th>domestic</th>\n",
       "      <th>catsize</th>\n",
       "      <th>class_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antelope</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bass</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animal_name  hair  feathers  eggs  milk  airborne  aquatic  predator  \\\n",
       "0    aardvark     1         0     0     1         0        0         1   \n",
       "1    antelope     1         0     0     1         0        0         0   \n",
       "2        bass     0         0     1     0         0        1         1   \n",
       "3        bear     1         0     0     1         0        0         1   \n",
       "4        boar     1         0     0     1         0        0         1   \n",
       "\n",
       "   toothed  backbone  breathes  venomous  fins  legs  tail  domestic  catsize  \\\n",
       "0        1         1         1         0     0     4     0         0        1   \n",
       "1        1         1         1         0     0     4     1         0        1   \n",
       "2        1         1         0         0     1     0     1         0        0   \n",
       "3        1         1         1         0     0     4     0         0        1   \n",
       "4        1         1         1         0     0     4     1         0        1   \n",
       "\n",
       "   class_type  \n",
       "0           1  \n",
       "1           1  \n",
       "2           4  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"animal_name\", \"hair\", \"feathers\", \"eggs\", \"milk\", \"predator\", \"fins\", \"legs\", \"tail\", \"class_type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 1. 1. 0. 4. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 0.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 0.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 4. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 6. 0.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [0. 0. 0. 1. 1. 1. 0. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 6. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 4. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 4. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 2. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 2. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 6. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 2. 0.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 6. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 6. 0.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 6. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 6. 0.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 6. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 8. 0.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 0. 0. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 8. 1.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 1. 1. 1. 0. 0.]\n",
      " [1. 0. 0. 1. 1. 1. 2. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 5. 0.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 6. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 4. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 2. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 2. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 6. 0.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "features = df[df.columns[1:-1]]\n",
    "X = np.array(features).astype(float)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 4. 1. 1. 1. 1. 4. 4. 1. 1. 2. 4. 7. 7. 7. 2. 1. 4. 1. 2. 2. 1. 2.\n",
      " 6. 5. 5. 1. 1. 1. 6. 1. 1. 2. 4. 1. 1. 2. 4. 6. 6. 2. 6. 2. 1. 1. 7. 1.\n",
      " 1. 1. 1. 6. 5. 7. 1. 1. 2. 2. 2. 2. 4. 4. 3. 1. 1. 1. 1. 1. 1. 1. 1. 2.\n",
      " 7. 4. 1. 1. 3. 7. 2. 2. 3. 7. 4. 2. 1. 7. 4. 2. 6. 5. 3. 3. 4. 1. 1. 2.\n",
      " 1. 6. 1. 7. 2.]\n"
     ]
    }
   ],
   "source": [
    "target = df[df.columns[-1]]\n",
    "y = np.array(target).astype(float)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.tensor(X).float(), torch.tensor(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sample tensor([1., 0., 0., 1., 1., 0., 4., 0.])\n",
      "label_sample tensor(1., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[0]\n",
    "input_sample, label_sample = sample\n",
    "print(\"input sample\", input_sample)\n",
    "print(\"label_sample\", label_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2 ## tamanho do lote ## determina o quantas amostras retiramos do conjunto de dados por interação\n",
    "shuffle = True ## embaralha os dados em cada interação\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch input tensor([[0., 0., 1., 0., 1., 1., 0., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 4., 1.]])\n",
      "batch labels tensor([4., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 0., 6., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 2., 1.]])\n",
      "batch labels tensor([6., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 0., 0., 2., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([2., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 2., 0.]])\n",
      "batch labels tensor([4., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 1., 0., 2., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([2., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([1., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 1., 2., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 6., 0.]])\n",
      "batch labels tensor([1., 7.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 0., 0., 1., 0., 8., 1.],\n",
      "        [0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "batch labels tensor([7., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 0., 5., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 2., 1.]])\n",
      "batch labels tensor([7., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 4., 0.]])\n",
      "batch labels tensor([1., 7.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 4., 1.]])\n",
      "batch labels tensor([1., 3.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 4., 1.],\n",
      "        [1., 0., 1., 0., 0., 0., 6., 0.]])\n",
      "batch labels tensor([1., 6.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 6., 0.]])\n",
      "batch labels tensor([1., 7.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 4., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 2., 1.]])\n",
      "batch labels tensor([1., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 0., 0., 2., 1.],\n",
      "        [0., 1., 1., 0., 0., 0., 2., 1.]])\n",
      "batch labels tensor([2., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 2., 0.],\n",
      "        [0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "batch labels tensor([1., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([1., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 0., 0., 6., 0.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([6., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 4., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 6., 0.]])\n",
      "batch labels tensor([1., 6.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 1., 0., 2., 1.],\n",
      "        [1., 0., 1., 0., 0., 0., 6., 0.]])\n",
      "batch labels tensor([2., 6.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 4., 1.]])\n",
      "batch labels tensor([4., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 0., 0., 2., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 4., 1.]])\n",
      "batch labels tensor([2., 5.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 0., 8., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 0.]])\n",
      "batch labels tensor([7., 7.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 4., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 6., 0.]])\n",
      "batch labels tensor([1., 6.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 1., 0., 2., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 2., 1.]])\n",
      "batch labels tensor([2., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 0., 4., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 4., 1.]])\n",
      "batch labels tensor([5., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 1., 0., 1.],\n",
      "        [0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "batch labels tensor([4., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 1., 0., 1., 0., 2., 1.]])\n",
      "batch labels tensor([7., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 4., 1.]])\n",
      "batch labels tensor([1., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 4., 0.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([1., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 1., 0., 2., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([2., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 0., 0., 2., 1.],\n",
      "        [0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "batch labels tensor([2., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 0., 0., 2., 1.],\n",
      "        [0., 1., 1., 0., 1., 0., 2., 1.]])\n",
      "batch labels tensor([2., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 1., 0., 2., 1.],\n",
      "        [0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "batch labels tensor([2., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 0., 1., 1., 1., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 1.]])\n",
      "batch labels tensor([1., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([1., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 1., 0., 0., 0., 6., 0.],\n",
      "        [0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "batch labels tensor([6., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 2., 1.]])\n",
      "batch labels tensor([7., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 4., 1.],\n",
      "        [0., 1., 1., 0., 0., 0., 2., 1.]])\n",
      "batch labels tensor([1., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 4., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 4., 1.]])\n",
      "batch labels tensor([1., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 0., 1., 1., 1., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 4., 0.]])\n",
      "batch labels tensor([1., 5.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 2., 1.],\n",
      "        [1., 0., 1., 0., 0., 0., 6., 0.]])\n",
      "batch labels tensor([1., 6.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 0., 0., 2., 1.],\n",
      "        [0., 1., 1., 0., 1., 0., 2., 1.]])\n",
      "batch labels tensor([2., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 4., 1.]])\n",
      "batch labels tensor([3., 3.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 1., 0., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 2., 1.]])\n",
      "batch labels tensor([1., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([3., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "batch labels tensor([3., 7.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 1., 1., 1., 0., 4., 1.],\n",
      "        [0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "batch labels tensor([1., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 1.],\n",
      "        [0., 1., 1., 0., 1., 0., 2., 1.]])\n",
      "batch labels tensor([1., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 1.]])\n",
      "batch labels tensor([1., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 0., 4., 0.]])\n",
      "batch labels tensor([5.], dtype=torch.float64)\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for batch_inputs, batch_labels in dataloader:\n",
    "    print(\"batch input\", batch_inputs)\n",
    "    print(\"batch labels\", batch_labels)\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 1., 0., 0., 4., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "tensor([1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(dataloader)) ## nao sabia\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de avaliação dos modelos\n",
    "* Como no aprendizado de máquina, o conjunto de dados de teste é usado apenas uma vez para calcular as métricas finais\n",
    "* Tranig - 80 - 90 % -> Usado para ajustar os parametros do modelo\n",
    "* Validation 10 - 20 % -> tunar os hyperparametros\n",
    "* Testing 5 - 10 % -> usado para calcular as metricas finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando a perda no treinamento\n",
    "* Calculada somando a perda em cada interação do dataloader\n",
    "* Ao final de cada epoca calculamos o valor médio de perda de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainig_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(trainsloader):\n",
    "    ##....\n",
    "\n",
    "    loss = criterion(output, labels)\n",
    "    trainig_loss += loss.item()\n",
    "\n",
    "epoch_loss = trainig_loss / len(trainsloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_loss = 0.0\n",
    "model.eval() ## metodo de avaliacao da classe\n",
    "## por que  algumas camadas nos modelos de pytorch se comportam de maneira diferentes nos estagios de treinamento e validacao\n",
    "with torch.no_grad(): ## Indicando que nao vamos fazer calculos de gradientes nessa epoca\n",
    "    for i, data in enumerate(validationloader, 0):\n",
    "        ## Run the forward pass  \n",
    "        ##...\n",
    "        #..\n",
    "        #.\n",
    "        loss = criterion(outputs, labels)\n",
    "        validation_loss += loss.item()\n",
    "\n",
    "epoch_loss = validation_loss / len(validationloader) \n",
    "model.train() ## indica que colocamos o modelo de volta no modo de treino "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OBS\n",
    "* Assim podemos avaliar se o modelo esta tendo overfitting\n",
    "\n",
    "**Overfitting**: ocorre quando o modelo para de generalizar o desempenho no conjunto de dados e a validação diminui (ou seja ambas tem que estar andando juntas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)\n",
    "\n",
    "for i, data in enumerate(dataloader, 0):\n",
    "    features, labels = data\n",
    "    output = model(features)\n",
    "\n",
    "    ## calculando a acurracy\n",
    "    acc = metric(output, labels.argmax(dim=-1))\n",
    "\n",
    "acc = metric.compute()\n",
    "\n",
    "print(f\"Accurracy data: {acc}\")\n",
    "\n",
    "## reset na metrica para calcular de novo no proxima epoca\n",
    "\n",
    "metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maneiras de combater o overfitting\n",
    "* O problema do overfitting esta relacionado em memorizar os dados de treinamento\n",
    "* O que leva bom desempenho nos dados de treinamento mas um desempenho ruim no conjunto de validação\n",
    "* Um pequeno conjunto de dados pode levar a isso\n",
    "* Um modelo com muita capacidade ou grandes pesos \n",
    "* Para resolver isso podemos reduzir o tamanho do modelo, adicionar uma nova camada chamada de dropout\n",
    "* Podemos reduzir os pesos os parâmetros para ficarem pequenos\n",
    "* Podemos obter mais dados aumentando eles com augmenting data\n",
    "\n",
    "**Dropout: É uma técnica de regularização onde aleatoriamente uma fração de neuronios de entrada são definidos como zero, efetivamente descartamo-os, as conexões são temporariamente removidas** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 4),\n",
    "    nn.ReLU(), \n",
    "    nn.Dropout(p=0.5)  ## p indica o valor da probabilidade\n",
    ")\n",
    "\n",
    "features = torch.randn((1, 8))\n",
    "\n",
    "model(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Outra forma de regularização\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-4)  ## weight_decay ele varia entre zero e um\n",
    "## o peso é subtraido do gradiente durante a retropropagação\n",
    "## quanto mais auto definimos esse valor, menor sera a probabilidade de nosso modelo, para que o modelo possa generalizar melhor para novos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "1. Criar um modelo que possa ajustar nos demais conjunto de treinamento\n",
    "2. Definimos uma linha de base para alcançar com o conjunto de validação e assim reduzir o overfitting\n",
    "3. E finalmente podemos então ajustar os hyperparametros para garantir maior desempehno possivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## antes de sobreajustar todo o conjunto de dados de treinamento, é recomendado sobreajustar um único ponto de dados\n",
    "features, labels = next(iter(trainloader))\n",
    "\n",
    "for i in range(1e3): ## não interando apenas no sobre o dataloader para poder testar apenas com um ponto de diferenca nos dados\n",
    "    outputs = model(features)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step\n",
    "\n",
    "## o overfitting de um unico ponto de dados deve nos dar uma precisão de um e uma perda proxima a zero \n",
    "## Tambem ajuda a encontrar possiveis bugs no codigo se esses valores nao forem alcançados\n",
    "## Nessa fase nao devemos experimentar a arquitetura do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "2\n",
      "0.001\n",
      "3\n",
      "0.0001\n",
      "4\n",
      "1e-05\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "## Se tivermos a capacidade computacional podemos realizar um pesquisa em grade sobre os diferentes hiperparametros\n",
    "\n",
    "for factor in range(2, 6):\n",
    "    lr = 10 ** -factor ## feito nos parametros do otimizador como taxa de aprendizado e o impulso\n",
    "    print(lr)\n",
    "    print(factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.734814186544297\n",
      "0.00018415597466571148\n"
     ]
    }
   ],
   "source": [
    "## Tambem podemos usar uma pesquisa aleatoria que coleta amostras aleatorias de parâmetros entre intervalos\n",
    "factor = np.random.uniform(2,6)\n",
    "lr = 10 ** -factor\n",
    "print(factor)\n",
    "print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.00020293425935611484, 0.9609826216130108), (0.0013358366332887099, 0.9286957021589338), (0.00041414030302522743, 0.8659182726161213), (0.00010200337664917705, 0.8502143328467219), (0.0008945127633732375, 0.9476334547599924), (0.0029320141754875934, 0.9437448766165514), (0.0001855740748960863, 0.9377017015290997), (0.008401363924163513, 0.8514237472736581), (0.00037253863461034355, 0.9608902775064266), (0.006973885238226284, 0.8958051185078998)]\n"
     ]
    }
   ],
   "source": [
    "values = []\n",
    "for idx in range(10):\n",
    "    # Randomly sample a learning rate factor between 0.01 and 0.0001\n",
    "    factor = np.random.uniform(2,4)\n",
    "    lr = 10 ** -factor\n",
    "    \n",
    "    # Randomly select a momentum between 0.85 and 0.99\n",
    "    momentum = np.random.uniform(0.85, 0.99)\n",
    "    \n",
    "    values.append((lr, momentum))\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
