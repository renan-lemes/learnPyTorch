{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision ## suport para imagens \n",
    "import torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user torch torchvision torchaudio -f https://download.pytorch.org/whl/cu111/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [3, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "array = [[1,2,3], [3,2,1]]\n",
    "\n",
    "tensor = torch.tensor(array)\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [3 2 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_array = np.array(array)\n",
    "np_tensor = torch.from_numpy(np_array) \n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aprendizado de maquina profundo requer uma GPU que em recursos de computação paralela, tempos mais rapidos e \n",
    "## desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 3],\n",
      "        [5, 5]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,1], [2,2]])\n",
    "b = torch.tensor([[2,2], [3,3]])\n",
    "\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\RENANL~1\\AppData\\Local\\Temp/ipykernel_10472/241818026.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,1], [2,2]])\n",
    "c = torch.tensor([[2,2,4], [3,3,5]])\n",
    "\n",
    "print(a + c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2],\n",
      "        [6, 6]])\n"
     ]
    }
   ],
   "source": [
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "input_tensor = torch.tensor([[0.3471, 0.4547, -0.2356]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(in_features=3, out_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5755, 0.0364]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = linear_layer(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0246,  0.2566, -0.3642],\n",
       "        [ 0.4247, -0.0465, -0.3344]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.3645, -0.1687], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qual e a operação usada :\n",
    "$$\n",
    "    y_0 = W_0 \\cdot X + b_0\n",
    "$$\n",
    "* X input array\n",
    "* W weight (peso)\n",
    "* b bias (vies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obs \n",
    "* Redes apenas com camadas lineares são chamadas de redes totalmente conectadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 18),\n",
    "    nn.Linear(18,20),\n",
    "    nn.Linear(20, 5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([[-0.014, 0.4038, 1.0305, 0.7521, 0.7489, -0.3968, 0.0113, -1.3844, 0.8705, -0.9743]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0361,  0.2392,  0.0584, -0.3282, -0.0761]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = model(input_tensor)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função sigmoid\n",
    "* Função utilizada para problemas de classificação binária\n",
    "\n",
    "* Suposição: imagine que você quer classificar um animal se é mamifero ou não. Recebemos 3 informações número de membros se põe ovos e se tem pelos.  \n",
    "\n",
    "* A função simgoide transforma um número inteiro em um valor entre zero e um.\n",
    "* Se o valor maior que 0.5 então a resposta sera 1 caso contrario sera 0\n",
    "\n",
    "$$\n",
    "    \\sigma(x) = \\frac{1}{1 + e^{-1}}\n",
    "$$\n",
    "\n",
    "##### Obs:\n",
    "Uma rede neural com camadas lineares é equivalente a uma regressão logística usando aprendizado de maquina tradicional\n",
    "* Para rotulos de varias classes usamos softmax outra função de ativação\n",
    "$$\n",
    "    SoftMax(z)_i = \\frac{e^{z^i}}{\\sum_{j=1}^{K} e^{z_i}}\n",
    "$$\n",
    "$z = (z_1, z_2, ..., z_K) z_i \\text{ \\space um numero real }$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9975]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_tensor = torch.tensor([[6.0]])\n",
    "sigmoid = nn.Sigmoid()\n",
    "output = sigmoid(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4),\n",
    "    nn.Linear(4,1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1392, 0.8420, 0.0188]])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.tensor([[4.3, 6.1, 2.3]])\n",
    "\n",
    "prob = nn.Softmax(dim=-1) ## -1 implica que ele e aplicado a ultima dimensao do input_tensor\n",
    "output = prob(input_tensor)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerações de previsões a partir de modelos. \"Executar uma passagem direta\"\n",
    "* Objetivo e propagar os dados de entrada atraves da rede e produzir predições com base nos parâmentros aprendidos peso e vies\n",
    "* Isso é usado tanto para treinar quanto para gerar novas previsões\n",
    "* Os resultados pode ser classificações binárias, classificações multiclasse ou previsões numéricas (regressões)\n",
    "##### Obs :\n",
    "* retropropagação: é p processo pelo qual os pesos e tendências das camadas são atualizadas durante o treinamento.\n",
    "\n",
    "#### Loop de treinamento.\n",
    "1. Propagate\n",
    "2. Compare\n",
    "3. BackPropagate\n",
    "4. Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_list(num):\n",
    "    import random\n",
    "    list_rm = list()\n",
    "    for i in range(num):\n",
    "        list_rm.append(round(random.uniform(-2, 2), 4))\n",
    "\n",
    "    return list_rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.6821, -0.4032, 1.7437, 0.8528, 0.6716]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_list(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3030,  0.3275, -0.4911,  0.7394,  0.8377, -0.3272],\n",
      "        [-1.9366,  1.5638,  1.4196, -1.4898,  1.2209, -1.7915],\n",
      "        [-0.0815,  1.1365,  1.8121,  0.5956, -0.8902, -1.8634],\n",
      "        [ 0.8829,  1.2250, -0.7520, -0.0447, -0.8286,  0.8738],\n",
      "        [-1.1171, -1.2145,  0.7343, -0.6438, -1.3037,  1.1023]])\n"
     ]
    }
   ],
   "source": [
    "input_data = torch.tensor(\n",
    "[\n",
    "        generate_list(6),\n",
    "        generate_list(6),\n",
    "        generate_list(6),\n",
    "        generate_list(6),\n",
    "        generate_list(6),\n",
    "]\n",
    ")\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4834],\n",
      "        [0.3782],\n",
      "        [0.4935],\n",
      "        [0.5582],\n",
      "        [0.4370]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(6, 4),\n",
    "    nn.Linear(4, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "output = model(input_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "n_class = 3 ## numero de classes da multi class\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4),\n",
    "    nn.Linear(4, n_class),\n",
    "    nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "output = model(input_data)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2841, 0.4369, 0.2790],\n",
      "        [0.2400, 0.2642, 0.4958],\n",
      "        [0.2611, 0.4072, 0.3317],\n",
      "        [0.3234, 0.3558, 0.3209],\n",
      "        [0.3436, 0.2451, 0.4112]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4247],\n",
      "        [-1.1996],\n",
      "        [-0.9001],\n",
      "        [-0.9102],\n",
      "        [-1.3548]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(6,4),\n",
    "    nn.Linear(4,1)\n",
    "\n",
    ")\n",
    "\n",
    "output = model(input_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliar as predições com os valores reais\n",
    "* Avaliaremos isso com uma função de perda \n",
    "* Ele pega uma as previsões do modelo e um valor verdadeiro e gera um float\n",
    "##### Exemplo:\n",
    "Digamos que vamos prever com o modelo se um animal é um mamifero um pássaro ou outros.\n",
    "\n",
    "$$\n",
    "    loss = F(y, \\hat{y}) \n",
    "$$\n",
    "Usamos a codificação one-hot para transformar o inteiro y em um tensor\n",
    "* Quando $y = 0$ ha três classes ou  seja $\\hat{y} = [1,0,0]$\n",
    "\n",
    "##### Função de perda  entropia cruzada, é a função mais utilizada para problemas de classificação\n",
    "Função para variaveis class binarias\n",
    "$$\n",
    "    CrossEntropyLoss(y, \\hat{y}) = - (y \\cdot log(\\hat{y}) + (1 - y) \\cdot log(1 - \\hat{y}))\n",
    "$$\n",
    "Função para multi class\n",
    "$$\n",
    "    CrossEntropyLoss(y, \\hat{y}) = - \\sum_{i=1}^{C} y_i \\cdot log(\\hat{y_i})\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0])\n",
      "tensor([0, 1, 0])\n",
      "tensor([0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "print(F.one_hot(torch.tensor(0), num_classes=3))\n",
    "print(F.one_hot(torch.tensor(1), num_classes=3))\n",
    "print(F.one_hot(torch.tensor(2), num_classes=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8131, dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "score = torch.tensor([[-0.1211, 0.1059]])\n",
    "one_hot_target = torch.tensor([[1, 0]])\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "criterion(score.double(), one_hot_target.double()) ## valor de perda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resumo \n",
    "* A função de perda toma como entrada o tensor de pontuações que é o modelo\n",
    "* Ele gera um ponto flutuante da perda da amostra $\\newline$\n",
    "Obs: **O objetivo do treinamento é minimizar a perda.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0619, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), scores.shape[1])\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Calculate the cross entropy loss\n",
    "loss = criterion(scores.double(), one_hot_label.double())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Atualizando os parametros do modelo.\n",
    "\n",
    "OBS : pensamos na função de perda como uma função \"Vale\"\n",
    "* por conta pode existir o minimo local e o minimo global\n",
    "* e pode existir o maximo global e o maximo local\n",
    "\n",
    "Deep learning gradient = derivada\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.tensor(\n",
    "[\n",
    "        generate_list(16),\n",
    "        generate_list(16),\n",
    "        generate_list(16),\n",
    "        generate_list(16),\n",
    "        generate_list(16),\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor(\n",
    "[\n",
    "    generate_list(2),\n",
    "    generate_list(2),\n",
    "    generate_list(2),\n",
    "    generate_list(2),\n",
    "    generate_list(2)\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(16, 8),\n",
    "    nn.Linear(8, 4), \n",
    "    nn.Linear(4,2)\n",
    ")\n",
    "\n",
    "prediction = model(sample)\n",
    "\n",
    "criterion = CrossEntropyLoss() ## Essa função de perda e utilizada em classificações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1316,  0.4664],\n",
       "        [ 0.2982,  0.1074],\n",
       "        [ 0.4448,  0.2274],\n",
       "        [ 0.8192, -0.1931],\n",
       "        [-0.3420,  0.3670]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(prediction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.3437, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0471, -0.0113, -0.0580,  0.0658, -0.0146, -0.0068, -0.0657, -0.0986,\n",
       "          -0.0459,  0.0062, -0.0317,  0.0255, -0.0698, -0.0098,  0.0480,  0.0119],\n",
       "         [-0.0620,  0.0149,  0.0763, -0.0866,  0.0192,  0.0089,  0.0865,  0.1298,\n",
       "           0.0604, -0.0081,  0.0417, -0.0335,  0.0919,  0.0129, -0.0632, -0.0157],\n",
       "         [ 0.0159, -0.0038, -0.0195,  0.0221, -0.0049, -0.0023, -0.0221, -0.0332,\n",
       "          -0.0154,  0.0021, -0.0107,  0.0086, -0.0235, -0.0033,  0.0162,  0.0040],\n",
       "         [ 0.1594, -0.0382, -0.1961,  0.2225, -0.0493, -0.0230, -0.2223, -0.3334,\n",
       "          -0.1551,  0.0209, -0.1072,  0.0861, -0.2361, -0.0330,  0.1624,  0.0404],\n",
       "         [-0.0422,  0.0101,  0.0520, -0.0589,  0.0131,  0.0061,  0.0589,  0.0883,\n",
       "           0.0411, -0.0055,  0.0284, -0.0228,  0.0625,  0.0088, -0.0430, -0.0107],\n",
       "         [-0.1111,  0.0266,  0.1368, -0.1552,  0.0344,  0.0160,  0.1550,  0.2325,\n",
       "           0.1082, -0.0146,  0.0748, -0.0601,  0.1647,  0.0230, -0.1133, -0.0282],\n",
       "         [ 0.0799, -0.0191, -0.0983,  0.1115, -0.0247, -0.0115, -0.1114, -0.1671,\n",
       "          -0.0777,  0.0105, -0.0537,  0.0432, -0.1183, -0.0166,  0.0814,  0.0202],\n",
       "         [-0.0633,  0.0152,  0.0779, -0.0884,  0.0196,  0.0091,  0.0883,  0.1324,\n",
       "           0.0616, -0.0083,  0.0426, -0.0342,  0.0938,  0.0131, -0.0645, -0.0160]]),\n",
       " tensor([ 0.0686, -0.0903,  0.0231,  0.2319, -0.0614, -0.1617,  0.1162, -0.0921]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.grad, model[0].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.4497e-02, -1.9862e-04,  8.5360e-06, -2.6416e-02,  2.4687e-02,\n",
       "          -1.4890e-02, -3.2992e-02, -5.3365e-02],\n",
       "         [ 1.3266e-01, -5.9208e-04,  2.5527e-05, -7.8755e-02,  7.3599e-02,\n",
       "          -4.4391e-02, -9.8359e-02, -1.5910e-01],\n",
       "         [-9.8769e-02,  4.4085e-04, -1.8996e-05,  5.8636e-02, -5.4797e-02,\n",
       "           3.3051e-02,  7.3232e-02,  1.1845e-01],\n",
       "         [ 1.2364e-01, -5.5184e-04,  2.3780e-05, -7.3401e-02,  6.8595e-02,\n",
       "          -4.1374e-02, -9.1672e-02, -1.4828e-01]]),\n",
       " tensor([-0.0927, -0.2764,  0.2058, -0.2576]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].weight.grad, model[1].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0133,  0.0494,  0.0311,  0.0063],\n",
       "         [ 0.0133, -0.0494, -0.0311, -0.0063]]),\n",
       " tensor([-0.4257,  0.4257]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].weight.grad, model[2].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Atualizando as camadas do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate is typically small taxa de aprendizado\n",
    "lr = 0.001\n",
    "\n",
    "## upadete the weights atualizanfo os pesos\n",
    "weight = model[0].weight\n",
    "weight_grad =model[0].weight.grad\n",
    "weight = weight - lr* weight_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the biases atualizanfo os vies\n",
    "bias = model[0].bias\n",
    "bias_grad = model[0].bias.grad\n",
    "bias = bias - lr * bias_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBS matemáticas ....\n",
    "* Minimizar a função perda o objetivo e encontrar o minimo global.\n",
    "* Quando temos apenas um minimo global sabemos que nossa função e convexa.\n",
    "* Qaundo temos varios minimos locais sabemos que nossa função não e convexa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradiente descendente\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)     ## gradiente estocastico mais conhecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing our first training loop\n",
    "1. Criar o modelo\n",
    "2. Escolher a função perda\n",
    "3. Criar um dataset\n",
    "4. Definir um otimizador\n",
    "5. Percorrer cada elemento do conjunto de dados calcular. (ciclo de treinamento)\n",
    "    * Perda\n",
    "    * Clacular os gradientes locais\n",
    "    * Atualizar os parametros do modelo\n",
    "\n",
    "OBS: Criamos nosso proprio metodo fit em uma deep learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/ds_salaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>80000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>85847</td>\n",
       "      <td>ES</td>\n",
       "      <td>100</td>\n",
       "      <td>ES</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>30000</td>\n",
       "      <td>USD</td>\n",
       "      <td>30000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>25500</td>\n",
       "      <td>USD</td>\n",
       "      <td>25500</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>175000</td>\n",
       "      <td>USD</td>\n",
       "      <td>175000</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>120000</td>\n",
       "      <td>USD</td>\n",
       "      <td>120000</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year experience_level employment_type                 job_title  \\\n",
       "0       2023               SE              FT  Principal Data Scientist   \n",
       "1       2023               MI              CT               ML Engineer   \n",
       "2       2023               MI              CT               ML Engineer   \n",
       "3       2023               SE              FT            Data Scientist   \n",
       "4       2023               SE              FT            Data Scientist   \n",
       "\n",
       "   salary salary_currency  salary_in_usd employee_residence  remote_ratio  \\\n",
       "0   80000             EUR          85847                 ES           100   \n",
       "1   30000             USD          30000                 US           100   \n",
       "2   25500             USD          25500                 US           100   \n",
       "3  175000             USD         175000                 CA           100   \n",
       "4  120000             USD         120000                 CA           100   \n",
       "\n",
       "  company_location company_size  \n",
       "0               ES            L  \n",
       "1               US            S  \n",
       "2               US            S  \n",
       "3               CA            M  \n",
       "4               CA            M  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"experience_level\", \"employment_type\", \"remote_ratio\", \"company_size\", \"salary_in_usd\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_size</th>\n",
       "      <th>salary_in_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>100</td>\n",
       "      <td>L</td>\n",
       "      <td>85847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>100</td>\n",
       "      <td>S</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>100</td>\n",
       "      <td>S</td>\n",
       "      <td>25500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>100</td>\n",
       "      <td>M</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>100</td>\n",
       "      <td>M</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_level employment_type  remote_ratio company_size  salary_in_usd\n",
       "0               SE              FT           100            L          85847\n",
       "1               MI              CT           100            S          30000\n",
       "2               MI              CT           100            S          25500\n",
       "3               SE              FT           100            M         175000\n",
       "4               SE              FT           100            M         120000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "standar_scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "## Transformando as variaveis em categoricas Ok\n",
    "df.experience_level = label_encoder.fit_transform(df[\"employment_type\"])\n",
    "df.employment_type = label_encoder.fit_transform(df[\"employment_type\"])\n",
    "df.company_size = label_encoder.fit_transform(df.company_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"salary_in_usd\", \"remote_ratio\"]] = scaler.fit_transform(\n",
    "    df[[\"salary_in_usd\", \"remote_ratio\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_size</th>\n",
       "      <th>salary_in_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.055900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.045784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.381839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.258207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.914581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.327891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.224489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.213250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.201257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3755 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      experience_level  employment_type  remote_ratio  company_size  \\\n",
       "0                    2                2           1.0             0   \n",
       "1                    0                0           1.0             2   \n",
       "2                    0                0           1.0             2   \n",
       "3                    2                2           1.0             1   \n",
       "4                    2                2           1.0             1   \n",
       "...                ...              ...           ...           ...   \n",
       "3750                 2                2           1.0             0   \n",
       "3751                 2                2           1.0             0   \n",
       "3752                 2                2           1.0             2   \n",
       "3753                 0                0           1.0             0   \n",
       "3754                 2                2           0.5             0   \n",
       "\n",
       "      salary_in_usd  \n",
       "0          0.181436  \n",
       "1          0.055900  \n",
       "2          0.045784  \n",
       "3          0.381839  \n",
       "4          0.258207  \n",
       "...             ...  \n",
       "3750       0.914581  \n",
       "3751       0.327891  \n",
       "3752       0.224489  \n",
       "3753       0.213250  \n",
       "3754       0.201257  \n",
       "\n",
       "[3755 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_loss(prediction, target): ## MSE\n",
    "    from numpy import mean as m\n",
    "    return m((prediction - target)**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ou entao podemos usar\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(prediction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[[\"experience_level\", \"employment_type\", \"remote_ratio\", \"company_size\"]].values\n",
    "target = df[[\"salary_in_usd\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creando o dataset e o dataloader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(\n",
    "    torch.tensor(features).float(), torch.tensor(target).float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criando o modelo\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Linear(2, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Loss: 0.06031482666730881\n",
      "Epoch: 1/5, Loss: 0.031628478318452835\n",
      "Epoch: 1/5, Loss: 0.027172639966011047\n",
      "Epoch: 1/5, Loss: 0.06647778302431107\n",
      "Epoch: 1/5, Loss: 0.0314297191798687\n",
      "Epoch: 1/5, Loss: 0.032982341945171356\n",
      "Epoch: 1/5, Loss: 0.047544773668050766\n",
      "Epoch: 1/5, Loss: 0.1476508378982544\n",
      "Epoch: 1/5, Loss: 0.11596079915761948\n",
      "Epoch: 1/5, Loss: 0.0540112629532814\n",
      "Epoch: 1/5, Loss: 0.045871131122112274\n",
      "Epoch: 1/5, Loss: 0.09112731367349625\n",
      "Epoch: 1/5, Loss: 0.04865649715065956\n",
      "Epoch: 1/5, Loss: 0.03691526874899864\n",
      "Epoch: 1/5, Loss: 0.050243742763996124\n",
      "Epoch: 1/5, Loss: 0.03383703902363777\n",
      "Epoch: 1/5, Loss: 0.0678509771823883\n",
      "Epoch: 1/5, Loss: 0.04061385616660118\n",
      "Epoch: 1/5, Loss: 0.0872306078672409\n",
      "Epoch: 1/5, Loss: 0.01640937477350235\n",
      "Epoch: 1/5, Loss: 0.027068395167589188\n",
      "Epoch: 1/5, Loss: 0.07344000786542892\n",
      "Epoch: 1/5, Loss: 0.028919978067278862\n",
      "Epoch: 1/5, Loss: 0.03578856214880943\n",
      "Epoch: 1/5, Loss: 0.08142293244600296\n",
      "Epoch: 1/5, Loss: 0.0365072526037693\n",
      "Epoch: 1/5, Loss: 0.11377193033695221\n",
      "Epoch: 1/5, Loss: 0.017041334882378578\n",
      "Epoch: 1/5, Loss: 0.021583475172519684\n",
      "Epoch: 1/5, Loss: 0.08442515879869461\n",
      "Epoch: 1/5, Loss: 0.048476170748472214\n",
      "Epoch: 1/5, Loss: 0.014131993986666203\n",
      "Epoch: 1/5, Loss: 0.05746963247656822\n",
      "Epoch: 1/5, Loss: 0.028941065073013306\n",
      "Epoch: 1/5, Loss: 0.052766792476177216\n",
      "Epoch: 1/5, Loss: 0.05852028355002403\n",
      "Epoch: 1/5, Loss: 0.02311553806066513\n",
      "Epoch: 1/5, Loss: 0.022850755602121353\n",
      "Epoch: 1/5, Loss: 0.021855998784303665\n",
      "Epoch: 1/5, Loss: 0.001180962659418583\n",
      "Epoch: 1/5, Loss: 0.06260110437870026\n",
      "Epoch: 1/5, Loss: 0.09045110642910004\n",
      "Epoch: 1/5, Loss: 0.08218333125114441\n",
      "Epoch: 1/5, Loss: 0.06097685173153877\n",
      "Epoch: 1/5, Loss: 0.03702772781252861\n",
      "Epoch: 1/5, Loss: 0.02175094187259674\n",
      "Epoch: 1/5, Loss: 0.03281717747449875\n",
      "Epoch: 1/5, Loss: 0.057329047471284866\n",
      "Epoch: 1/5, Loss: 0.02708333358168602\n",
      "Epoch: 1/5, Loss: 0.012593382969498634\n",
      "Epoch: 1/5, Loss: 0.04184252396225929\n",
      "Epoch: 1/5, Loss: 0.0283708143979311\n",
      "Epoch: 1/5, Loss: 0.06658173352479935\n",
      "Epoch: 1/5, Loss: 0.019595205783843994\n",
      "Epoch: 1/5, Loss: 0.03350247070193291\n",
      "Epoch: 1/5, Loss: 0.03173690661787987\n",
      "Epoch: 1/5, Loss: 0.04439632594585419\n",
      "Epoch: 1/5, Loss: 0.04197153076529503\n",
      "Epoch: 1/5, Loss: 0.025684738531708717\n",
      "Epoch: 1/5, Loss: 0.028162699192762375\n",
      "Epoch: 1/5, Loss: 0.045245155692100525\n",
      "Epoch: 1/5, Loss: 0.019791822880506516\n",
      "Epoch: 1/5, Loss: 0.08311522006988525\n",
      "Epoch: 1/5, Loss: 0.008468437939882278\n",
      "Epoch: 1/5, Loss: 0.02754896692931652\n",
      "Epoch: 1/5, Loss: 0.022601017728447914\n",
      "Epoch: 1/5, Loss: 0.050860509276390076\n",
      "Epoch: 1/5, Loss: 0.02577224187552929\n",
      "Epoch: 1/5, Loss: 0.04904833808541298\n",
      "Epoch: 1/5, Loss: 0.021757960319519043\n",
      "Epoch: 1/5, Loss: 0.04893495887517929\n",
      "Epoch: 1/5, Loss: 0.03399934247136116\n",
      "Epoch: 1/5, Loss: 0.03652260825037956\n",
      "Epoch: 1/5, Loss: 0.020542312413454056\n",
      "Epoch: 1/5, Loss: 0.011767309159040451\n",
      "Epoch: 1/5, Loss: 0.06799902021884918\n",
      "Epoch: 1/5, Loss: 0.03887872025370598\n",
      "Epoch: 1/5, Loss: 0.06211353465914726\n",
      "Epoch: 1/5, Loss: 0.04133426398038864\n",
      "Epoch: 1/5, Loss: 0.020109882578253746\n",
      "Epoch: 1/5, Loss: 0.016121570020914078\n",
      "Epoch: 1/5, Loss: 0.005937342531979084\n",
      "Epoch: 1/5, Loss: 0.011713512241840363\n",
      "Epoch: 1/5, Loss: 0.021223701536655426\n",
      "Epoch: 1/5, Loss: 0.009916705079376698\n",
      "Epoch: 1/5, Loss: 0.025518618524074554\n",
      "Epoch: 1/5, Loss: 0.01729096658527851\n",
      "Epoch: 1/5, Loss: 0.033388301730155945\n",
      "Epoch: 1/5, Loss: 0.0645182654261589\n",
      "Epoch: 1/5, Loss: 0.06858643144369125\n",
      "Epoch: 1/5, Loss: 0.037866488099098206\n",
      "Epoch: 1/5, Loss: 0.022684255614876747\n",
      "Epoch: 1/5, Loss: 0.1500449776649475\n",
      "Epoch: 1/5, Loss: 0.05005236715078354\n",
      "Epoch: 1/5, Loss: 0.008905114606022835\n",
      "Epoch: 1/5, Loss: 0.029732704162597656\n",
      "Epoch: 1/5, Loss: 0.05429042875766754\n",
      "Epoch: 1/5, Loss: 0.007032402791082859\n",
      "Epoch: 1/5, Loss: 0.027933374047279358\n",
      "Epoch: 1/5, Loss: 0.04313547909259796\n",
      "Epoch: 1/5, Loss: 0.013742227107286453\n",
      "Epoch: 1/5, Loss: 0.038311667740345\n",
      "Epoch: 1/5, Loss: 0.08862674236297607\n",
      "Epoch: 1/5, Loss: 0.023603036999702454\n",
      "Epoch: 1/5, Loss: 0.005228011403232813\n",
      "Epoch: 1/5, Loss: 0.010490097105503082\n",
      "Epoch: 1/5, Loss: 0.015780963003635406\n",
      "Epoch: 1/5, Loss: 0.02765009179711342\n",
      "Epoch: 1/5, Loss: 0.05763264000415802\n",
      "Epoch: 1/5, Loss: 0.04524264112114906\n",
      "Epoch: 1/5, Loss: 0.0228688046336174\n",
      "Epoch: 1/5, Loss: 0.08264409750699997\n",
      "Epoch: 1/5, Loss: 0.06174803525209427\n",
      "Epoch: 1/5, Loss: 0.013376683928072453\n",
      "Epoch: 1/5, Loss: 0.05159100517630577\n",
      "Epoch: 1/5, Loss: 0.026939358562231064\n",
      "Epoch: 1/5, Loss: 0.07297280430793762\n",
      "Epoch: 1/5, Loss: 0.07732024788856506\n",
      "Epoch: 1/5, Loss: 0.024725640192627907\n",
      "Epoch: 1/5, Loss: 0.04145652800798416\n",
      "Epoch: 1/5, Loss: 0.015706783160567284\n",
      "Epoch: 1/5, Loss: 0.04889761283993721\n",
      "Epoch: 1/5, Loss: 0.11236140877008438\n",
      "Epoch: 1/5, Loss: 0.03988400101661682\n",
      "Epoch: 1/5, Loss: 0.09666872024536133\n",
      "Epoch: 1/5, Loss: 0.012406050227582455\n",
      "Epoch: 1/5, Loss: 0.01726282760500908\n",
      "Epoch: 1/5, Loss: 0.054015424102544785\n",
      "Epoch: 1/5, Loss: 0.10265249013900757\n",
      "Epoch: 1/5, Loss: 0.022485971450805664\n",
      "Epoch: 1/5, Loss: 0.018863607197999954\n",
      "Epoch: 1/5, Loss: 0.031239453703165054\n",
      "Epoch: 1/5, Loss: 0.06401985883712769\n",
      "Epoch: 1/5, Loss: 0.03620186820626259\n",
      "Epoch: 1/5, Loss: 0.08177605271339417\n",
      "Epoch: 1/5, Loss: 0.036900345236063004\n",
      "Epoch: 1/5, Loss: 0.03002380207180977\n",
      "Epoch: 1/5, Loss: 0.06137428432703018\n",
      "Epoch: 1/5, Loss: 0.025469716638326645\n",
      "Epoch: 1/5, Loss: 0.040992312133312225\n",
      "Epoch: 1/5, Loss: 0.033414095640182495\n",
      "Epoch: 1/5, Loss: 0.0298185795545578\n",
      "Epoch: 1/5, Loss: 0.012753915041685104\n",
      "Epoch: 1/5, Loss: 0.04338637366890907\n",
      "Epoch: 1/5, Loss: 0.01060241274535656\n",
      "Epoch: 1/5, Loss: 0.049069397151470184\n",
      "Epoch: 1/5, Loss: 0.017225679010152817\n",
      "Epoch: 1/5, Loss: 0.01993895135819912\n",
      "Epoch: 1/5, Loss: 0.0036803288385272026\n",
      "Epoch: 1/5, Loss: 0.012212332338094711\n",
      "Epoch: 1/5, Loss: 0.017949730157852173\n",
      "Epoch: 1/5, Loss: 0.017194312065839767\n",
      "Epoch: 1/5, Loss: 0.012794115580618382\n",
      "Epoch: 1/5, Loss: 0.07360698282718658\n",
      "Epoch: 1/5, Loss: 0.030464114621281624\n",
      "Epoch: 1/5, Loss: 0.036172542721033096\n",
      "Epoch: 1/5, Loss: 0.015294939279556274\n",
      "Epoch: 1/5, Loss: 0.026882771402597427\n",
      "Epoch: 1/5, Loss: 0.09953214228153229\n",
      "Epoch: 1/5, Loss: 0.11725766956806183\n",
      "Epoch: 1/5, Loss: 0.004588098265230656\n",
      "Epoch: 1/5, Loss: 0.0025011422112584114\n",
      "Epoch: 1/5, Loss: 0.0050789169035851955\n",
      "Epoch: 1/5, Loss: 0.024304546415805817\n",
      "Epoch: 1/5, Loss: 0.017949368804693222\n",
      "Epoch: 1/5, Loss: 0.025397611781954765\n",
      "Epoch: 1/5, Loss: 0.03648141771554947\n",
      "Epoch: 1/5, Loss: 0.032741039991378784\n",
      "Epoch: 1/5, Loss: 0.05888049304485321\n",
      "Epoch: 1/5, Loss: 0.029489312320947647\n",
      "Epoch: 1/5, Loss: 0.020253926515579224\n",
      "Epoch: 1/5, Loss: 0.014422435313463211\n",
      "Epoch: 1/5, Loss: 0.04462626203894615\n",
      "Epoch: 1/5, Loss: 0.07131081819534302\n",
      "Epoch: 1/5, Loss: 0.029682718217372894\n",
      "Epoch: 1/5, Loss: 0.015076950192451477\n",
      "Epoch: 1/5, Loss: 0.018362287431955338\n",
      "Epoch: 1/5, Loss: 0.006573560647666454\n",
      "Epoch: 1/5, Loss: 0.02492753230035305\n",
      "Epoch: 1/5, Loss: 0.03781023994088173\n",
      "Epoch: 1/5, Loss: 0.04663482680916786\n",
      "Epoch: 1/5, Loss: 0.04831625148653984\n",
      "Epoch: 1/5, Loss: 0.05392748862504959\n",
      "Epoch: 1/5, Loss: 0.05845290422439575\n",
      "Epoch: 1/5, Loss: 0.03224186599254608\n",
      "Epoch: 1/5, Loss: 0.023336712270975113\n",
      "Epoch: 1/5, Loss: 0.023545900359749794\n",
      "Epoch: 1/5, Loss: 0.022954370826482773\n",
      "Epoch: 1/5, Loss: 0.012469171546399593\n",
      "Epoch: 1/5, Loss: 0.01180357113480568\n",
      "Epoch: 1/5, Loss: 0.05210920795798302\n",
      "Epoch: 1/5, Loss: 0.01860017701983452\n",
      "Epoch: 1/5, Loss: 0.022496365010738373\n",
      "Epoch: 1/5, Loss: 0.018342340365052223\n",
      "Epoch: 1/5, Loss: 0.047296375036239624\n",
      "Epoch: 1/5, Loss: 0.005888466723263264\n",
      "Epoch: 1/5, Loss: 0.023885810747742653\n",
      "Epoch: 1/5, Loss: 0.11571960896253586\n",
      "Epoch: 1/5, Loss: 0.058116450905799866\n",
      "Epoch: 1/5, Loss: 0.024699125438928604\n",
      "Epoch: 1/5, Loss: 0.08074025809764862\n",
      "Epoch: 1/5, Loss: 0.030772849917411804\n",
      "Epoch: 1/5, Loss: 0.03729112446308136\n",
      "Epoch: 1/5, Loss: 0.004528020974248648\n",
      "Epoch: 1/5, Loss: 0.03069026954472065\n",
      "Epoch: 1/5, Loss: 0.01455885823816061\n",
      "Epoch: 1/5, Loss: 0.0334165133535862\n",
      "Epoch: 1/5, Loss: 0.008983778767287731\n",
      "Epoch: 1/5, Loss: 0.019230986014008522\n",
      "Epoch: 1/5, Loss: 0.00448685884475708\n",
      "Epoch: 1/5, Loss: 0.005863148253411055\n",
      "Epoch: 1/5, Loss: 0.01872115023434162\n",
      "Epoch: 1/5, Loss: 0.009017911739647388\n",
      "Epoch: 1/5, Loss: 0.012902534566819668\n",
      "Epoch: 1/5, Loss: 0.06112479045987129\n",
      "Epoch: 1/5, Loss: 0.046188123524188995\n",
      "Epoch: 1/5, Loss: 0.01884397491812706\n",
      "Epoch: 1/5, Loss: 0.05683491379022598\n",
      "Epoch: 1/5, Loss: 0.07110736519098282\n",
      "Epoch: 1/5, Loss: 0.08702610433101654\n",
      "Epoch: 1/5, Loss: 0.095913365483284\n",
      "Epoch: 1/5, Loss: 0.038083769381046295\n",
      "Epoch: 1/5, Loss: 0.017853008583188057\n",
      "Epoch: 1/5, Loss: 0.027498139068484306\n",
      "Epoch: 1/5, Loss: 0.023113496601581573\n",
      "Epoch: 1/5, Loss: 0.09319159388542175\n",
      "Epoch: 1/5, Loss: 0.0060013337060809135\n",
      "Epoch: 1/5, Loss: 0.015660885721445084\n",
      "Epoch: 1/5, Loss: 0.03281524032354355\n",
      "Epoch: 1/5, Loss: 0.03157157078385353\n",
      "Epoch: 1/5, Loss: 0.01860162429511547\n",
      "Epoch: 1/5, Loss: 0.017998578026890755\n",
      "Epoch: 1/5, Loss: 0.06201079860329628\n",
      "Epoch: 1/5, Loss: 0.044969119131565094\n",
      "Epoch: 1/5, Loss: 0.018379364162683487\n",
      "Epoch: 1/5, Loss: 0.06980007141828537\n",
      "Epoch: 1/5, Loss: 0.026854820549488068\n",
      "Epoch: 1/5, Loss: 0.018473664298653603\n",
      "Epoch: 1/5, Loss: 0.019539818167686462\n",
      "Epoch: 1/5, Loss: 0.04833978787064552\n",
      "Epoch: 1/5, Loss: 0.0036148279905319214\n",
      "Epoch: 1/5, Loss: 0.03982296586036682\n",
      "Epoch: 1/5, Loss: 0.06732086092233658\n",
      "Epoch: 1/5, Loss: 0.03848164528608322\n",
      "Epoch: 1/5, Loss: 0.0154824648052454\n",
      "Epoch: 1/5, Loss: 0.025330014526844025\n",
      "Epoch: 1/5, Loss: 0.009835720993578434\n",
      "Epoch: 1/5, Loss: 0.019289730116724968\n",
      "Epoch: 1/5, Loss: 0.049045663326978683\n",
      "Epoch: 1/5, Loss: 0.011271795257925987\n",
      "Epoch: 1/5, Loss: 0.06617165356874466\n",
      "Epoch: 1/5, Loss: 0.013301251456141472\n",
      "Epoch: 1/5, Loss: 0.0511946827173233\n",
      "Epoch: 1/5, Loss: 0.01431104727089405\n",
      "Epoch: 1/5, Loss: 0.0068820021115243435\n",
      "Epoch: 1/5, Loss: 0.02814999781548977\n",
      "Epoch: 1/5, Loss: 0.02433517388999462\n",
      "Epoch: 1/5, Loss: 0.007035418879240751\n",
      "Epoch: 1/5, Loss: 0.008128456771373749\n",
      "Epoch: 1/5, Loss: 0.020613323897123337\n",
      "Epoch: 1/5, Loss: 0.02438742108643055\n",
      "Epoch: 1/5, Loss: 0.05012861639261246\n",
      "Epoch: 1/5, Loss: 0.009884868748486042\n",
      "Epoch: 1/5, Loss: 0.012422245927155018\n",
      "Epoch: 1/5, Loss: 0.046854183077812195\n",
      "Epoch: 1/5, Loss: 0.03123355656862259\n",
      "Epoch: 1/5, Loss: 0.06529779732227325\n",
      "Epoch: 1/5, Loss: 0.025931142270565033\n",
      "Epoch: 1/5, Loss: 0.027121860533952713\n",
      "Epoch: 1/5, Loss: 0.03742818534374237\n",
      "Epoch: 1/5, Loss: 0.0340370275080204\n",
      "Epoch: 1/5, Loss: 0.041700579226017\n",
      "Epoch: 1/5, Loss: 0.04413742199540138\n",
      "Epoch: 1/5, Loss: 0.030205128714442253\n",
      "Epoch: 1/5, Loss: 0.0365237221121788\n",
      "Epoch: 1/5, Loss: 0.03291936218738556\n",
      "Epoch: 1/5, Loss: 0.06326257437467575\n",
      "Epoch: 1/5, Loss: 0.07634685933589935\n",
      "Epoch: 1/5, Loss: 0.015281971544027328\n",
      "Epoch: 1/5, Loss: 0.04595721513032913\n",
      "Epoch: 1/5, Loss: 0.009470158256590366\n",
      "Epoch: 1/5, Loss: 0.026223665103316307\n",
      "Epoch: 1/5, Loss: 0.07116459310054779\n",
      "Epoch: 1/5, Loss: 0.009694078005850315\n",
      "Epoch: 1/5, Loss: 0.034008488059043884\n",
      "Epoch: 1/5, Loss: 0.02358810231089592\n",
      "Epoch: 1/5, Loss: 0.06715855002403259\n",
      "Epoch: 1/5, Loss: 0.06573676317930222\n",
      "Epoch: 1/5, Loss: 0.003988585434854031\n",
      "Epoch: 1/5, Loss: 0.048328690230846405\n",
      "Epoch: 1/5, Loss: 0.011668817140161991\n",
      "Epoch: 1/5, Loss: 0.04591991752386093\n",
      "Epoch: 1/5, Loss: 0.06000983715057373\n",
      "Epoch: 1/5, Loss: 0.010868341661989689\n",
      "Epoch: 1/5, Loss: 0.017668474465608597\n",
      "Epoch: 1/5, Loss: 0.02593906596302986\n",
      "Epoch: 1/5, Loss: 0.015000205487012863\n",
      "Epoch: 1/5, Loss: 0.06308198720216751\n",
      "Epoch: 1/5, Loss: 0.009989217855036259\n",
      "Epoch: 1/5, Loss: 0.014113363809883595\n",
      "Epoch: 1/5, Loss: 0.0025459136813879013\n",
      "Epoch: 1/5, Loss: 0.04422231763601303\n",
      "Epoch: 1/5, Loss: 0.021929055452346802\n",
      "Epoch: 1/5, Loss: 0.01234098244458437\n",
      "Epoch: 1/5, Loss: 0.013827965594828129\n",
      "Epoch: 1/5, Loss: 0.04688415676355362\n",
      "Epoch: 1/5, Loss: 0.0051122852601110935\n",
      "Epoch: 1/5, Loss: 0.023266121745109558\n",
      "Epoch: 1/5, Loss: 0.040992479771375656\n",
      "Epoch: 1/5, Loss: 0.03674939274787903\n",
      "Epoch: 1/5, Loss: 0.037441957741975784\n",
      "Epoch: 1/5, Loss: 0.016144560649991035\n",
      "Epoch: 1/5, Loss: 0.10758877545595169\n",
      "Epoch: 1/5, Loss: 0.0505356639623642\n",
      "Epoch: 1/5, Loss: 0.01789037510752678\n",
      "Epoch: 1/5, Loss: 0.027087334543466568\n",
      "Epoch: 1/5, Loss: 0.05905172973871231\n",
      "Epoch: 1/5, Loss: 0.022375887259840965\n",
      "Epoch: 1/5, Loss: 0.0166927557438612\n",
      "Epoch: 1/5, Loss: 0.01279616728425026\n",
      "Epoch: 1/5, Loss: 0.019376685842871666\n",
      "Epoch: 1/5, Loss: 0.029139582067728043\n",
      "Epoch: 1/5, Loss: 0.021829551085829735\n",
      "Epoch: 1/5, Loss: 0.01920308545231819\n",
      "Epoch: 1/5, Loss: 0.07768574357032776\n",
      "Epoch: 1/5, Loss: 0.019791580736637115\n",
      "Epoch: 1/5, Loss: 0.06143133342266083\n",
      "Epoch: 1/5, Loss: 0.07829886674880981\n",
      "Epoch: 1/5, Loss: 0.050991982221603394\n",
      "Epoch: 1/5, Loss: 0.018678758293390274\n",
      "Epoch: 1/5, Loss: 0.014714168384671211\n",
      "Epoch: 1/5, Loss: 0.028730405494570732\n",
      "Epoch: 1/5, Loss: 0.040458377450704575\n",
      "Epoch: 1/5, Loss: 0.040745172649621964\n",
      "Epoch: 1/5, Loss: 0.023558761924505234\n",
      "Epoch: 1/5, Loss: 0.037230685353279114\n",
      "Epoch: 1/5, Loss: 0.0383988693356514\n",
      "Epoch: 1/5, Loss: 0.013870788738131523\n",
      "Epoch: 1/5, Loss: 0.030460555106401443\n",
      "Epoch: 1/5, Loss: 0.023129474371671677\n",
      "Epoch: 1/5, Loss: 0.015111833810806274\n",
      "Epoch: 1/5, Loss: 0.05729268491268158\n",
      "Epoch: 1/5, Loss: 0.05512474849820137\n",
      "Epoch: 1/5, Loss: 0.032785333693027496\n",
      "Epoch: 1/5, Loss: 0.025098273530602455\n",
      "Epoch: 1/5, Loss: 0.010002672672271729\n",
      "Epoch: 1/5, Loss: 0.050799135118722916\n",
      "Epoch: 1/5, Loss: 0.028859395533800125\n",
      "Epoch: 1/5, Loss: 0.01985190436244011\n",
      "Epoch: 1/5, Loss: 0.03342583775520325\n",
      "Epoch: 1/5, Loss: 0.00252959574572742\n",
      "Epoch: 1/5, Loss: 0.007588548120111227\n",
      "Epoch: 1/5, Loss: 0.03147437050938606\n",
      "Epoch: 1/5, Loss: 0.03833308070898056\n",
      "Epoch: 1/5, Loss: 0.0074005634523928165\n",
      "Epoch: 1/5, Loss: 0.0279639083892107\n",
      "Epoch: 1/5, Loss: 0.038064002990722656\n",
      "Epoch: 1/5, Loss: 0.052567172795534134\n",
      "Epoch: 1/5, Loss: 0.01605786755681038\n",
      "Epoch: 1/5, Loss: 0.005349451210349798\n",
      "Epoch: 1/5, Loss: 0.010032383725047112\n",
      "Epoch: 1/5, Loss: 0.0517745316028595\n",
      "Epoch: 1/5, Loss: 0.06169424206018448\n",
      "Epoch: 1/5, Loss: 0.007431479636579752\n",
      "Epoch: 1/5, Loss: 0.03442492336034775\n",
      "Epoch: 1/5, Loss: 0.04061568155884743\n",
      "Epoch: 1/5, Loss: 0.07701575756072998\n",
      "Epoch: 1/5, Loss: 0.016258008778095245\n",
      "Epoch: 1/5, Loss: 0.005257067270576954\n",
      "Epoch: 1/5, Loss: 0.038214050233364105\n",
      "Epoch: 1/5, Loss: 0.022739168256521225\n",
      "Epoch: 1/5, Loss: 0.03140738606452942\n",
      "Epoch: 1/5, Loss: 0.004813130013644695\n",
      "Epoch: 1/5, Loss: 0.030575361102819443\n",
      "Epoch: 1/5, Loss: 0.07911807298660278\n",
      "Epoch: 1/5, Loss: 0.006029714830219746\n",
      "Epoch: 1/5, Loss: 0.03159713000059128\n",
      "Epoch: 1/5, Loss: 0.02812456339597702\n",
      "Epoch: 1/5, Loss: 0.03210461139678955\n",
      "Epoch: 1/5, Loss: 0.044153664261102676\n",
      "Epoch: 1/5, Loss: 0.025085894390940666\n",
      "Epoch: 1/5, Loss: 0.013274342752993107\n",
      "Epoch: 1/5, Loss: 0.00324815372005105\n",
      "Epoch: 1/5, Loss: 0.01573302410542965\n",
      "Epoch: 1/5, Loss: 0.04160211607813835\n",
      "Epoch: 1/5, Loss: 0.012416640296578407\n",
      "Epoch: 1/5, Loss: 0.03669419139623642\n",
      "Epoch: 1/5, Loss: 0.03745514526963234\n",
      "Epoch: 1/5, Loss: 0.0029294630512595177\n",
      "Epoch: 1/5, Loss: 0.03339213877916336\n",
      "Epoch: 1/5, Loss: 0.041138485074043274\n",
      "Epoch: 1/5, Loss: 0.01778334379196167\n",
      "Epoch: 1/5, Loss: 0.025395680218935013\n",
      "Epoch: 1/5, Loss: 0.022516468539834023\n",
      "Epoch: 1/5, Loss: 0.013753155246376991\n",
      "Epoch: 1/5, Loss: 0.04381158575415611\n",
      "Epoch: 1/5, Loss: 0.03139543533325195\n",
      "Epoch: 1/5, Loss: 0.06516972184181213\n",
      "Epoch: 1/5, Loss: 0.01100863702595234\n",
      "Epoch: 1/5, Loss: 0.04807423800230026\n",
      "Epoch: 1/5, Loss: 0.014215990900993347\n",
      "Epoch: 1/5, Loss: 0.04068718105554581\n",
      "Epoch: 1/5, Loss: 0.10294540971517563\n",
      "Epoch: 1/5, Loss: 0.05580044910311699\n",
      "Epoch: 1/5, Loss: 0.015223387628793716\n",
      "Epoch: 1/5, Loss: 0.0116260452196002\n",
      "Epoch: 1/5, Loss: 0.013299088925123215\n",
      "Epoch: 1/5, Loss: 0.04944121837615967\n",
      "Epoch: 1/5, Loss: 0.05163189396262169\n",
      "Epoch: 1/5, Loss: 0.03583966940641403\n",
      "Epoch: 1/5, Loss: 0.001218226389028132\n",
      "Epoch: 1/5, Loss: 0.06612780690193176\n",
      "Epoch: 1/5, Loss: 0.021525554358959198\n",
      "Epoch: 1/5, Loss: 0.010422494262456894\n",
      "Epoch: 1/5, Loss: 0.12185999751091003\n",
      "Epoch: 1/5, Loss: 0.050726912915706635\n",
      "Epoch: 1/5, Loss: 0.009007258340716362\n",
      "Epoch: 1/5, Loss: 0.030784590169787407\n",
      "Epoch: 1/5, Loss: 0.02730545587837696\n",
      "Epoch: 1/5, Loss: 0.019204920157790184\n",
      "Epoch: 1/5, Loss: 0.047082990407943726\n",
      "Epoch: 1/5, Loss: 0.02992873266339302\n",
      "Epoch: 1/5, Loss: 0.04210865870118141\n",
      "Epoch: 1/5, Loss: 0.028195584192872047\n",
      "Epoch: 1/5, Loss: 0.024230703711509705\n",
      "Epoch: 1/5, Loss: 0.01180462259799242\n",
      "Epoch: 1/5, Loss: 0.07196013629436493\n",
      "Epoch: 1/5, Loss: 0.026062732562422752\n",
      "Epoch: 1/5, Loss: 0.02480284869670868\n",
      "Epoch: 1/5, Loss: 0.04801405966281891\n",
      "Epoch: 1/5, Loss: 0.016364188864827156\n",
      "Epoch: 1/5, Loss: 0.027161579579114914\n",
      "Epoch: 1/5, Loss: 0.02105930633842945\n",
      "Epoch: 1/5, Loss: 0.023716246709227562\n",
      "Epoch: 1/5, Loss: 0.003044119570404291\n",
      "Epoch: 1/5, Loss: 0.004668917041271925\n",
      "Epoch: 1/5, Loss: 0.007555697578936815\n",
      "Epoch: 1/5, Loss: 0.02478676661849022\n",
      "Epoch: 1/5, Loss: 0.016398848965764046\n",
      "Epoch: 1/5, Loss: 0.04831961542367935\n",
      "Epoch: 1/5, Loss: 0.023024756461381912\n",
      "Epoch: 1/5, Loss: 0.03859710320830345\n",
      "Epoch: 1/5, Loss: 0.005573582835495472\n",
      "Epoch: 1/5, Loss: 0.0576077438890934\n",
      "Epoch: 1/5, Loss: 0.017860010266304016\n",
      "Epoch: 1/5, Loss: 0.007963470183312893\n",
      "Epoch: 1/5, Loss: 0.12388044595718384\n",
      "Epoch: 1/5, Loss: 0.009095372632145882\n",
      "Epoch: 1/5, Loss: 0.01397302933037281\n",
      "Epoch: 1/5, Loss: 0.012676768936216831\n",
      "Epoch: 1/5, Loss: 0.022311914712190628\n",
      "Epoch: 1/5, Loss: 0.10605157911777496\n",
      "Epoch: 1/5, Loss: 0.025077635422348976\n",
      "Epoch: 1/5, Loss: 0.017628472298383713\n",
      "Epoch: 1/5, Loss: 0.006182414013892412\n",
      "Epoch: 1/5, Loss: 0.015282809734344482\n",
      "Epoch: 1/5, Loss: 0.0201399065554142\n",
      "Epoch: 1/5, Loss: 0.006981604732573032\n",
      "Epoch: 1/5, Loss: 0.007223422639071941\n",
      "Epoch: 1/5, Loss: 0.07178034633398056\n",
      "Epoch: 1/5, Loss: 0.015812721103429794\n",
      "Epoch: 1/5, Loss: 0.03333652392029762\n",
      "Epoch: 1/5, Loss: 0.02430589497089386\n",
      "Epoch: 1/5, Loss: 0.014131186529994011\n",
      "Epoch: 1/5, Loss: 0.020080817863345146\n",
      "Epoch: 1/5, Loss: 0.02083214558660984\n",
      "Epoch: 1/5, Loss: 0.024491392076015472\n",
      "Epoch: 1/5, Loss: 0.02022131346166134\n",
      "Epoch: 1/5, Loss: 0.03923182934522629\n",
      "Epoch: 1/5, Loss: 0.01807877980172634\n",
      "Epoch: 1/5, Loss: 0.016123007982969284\n",
      "Epoch: 1/5, Loss: 0.019555984064936638\n",
      "Epoch: 1/5, Loss: 0.03035161830484867\n",
      "Epoch: 1/5, Loss: 0.017167696729302406\n",
      "Epoch: 1/5, Loss: 0.010581299662590027\n",
      "Epoch: 1/5, Loss: 0.0773756206035614\n",
      "Epoch: 1/5, Loss: 0.0015459229471161962\n",
      "Epoch: 1/5, Loss: 0.06604528427124023\n",
      "Epoch: 1/5, Loss: 0.010893933475017548\n",
      "Epoch: 1/5, Loss: 0.013518314808607101\n",
      "Epoch: 1/5, Loss: 0.033322837203741074\n",
      "Epoch: 1/5, Loss: 0.02318894863128662\n",
      "Epoch: 1/5, Loss: 0.017399534583091736\n",
      "Epoch: 1/5, Loss: 0.06372406333684921\n",
      "Epoch: 1/5, Loss: 0.016290348023176193\n",
      "Epoch: 1/5, Loss: 0.010782420635223389\n",
      "Epoch: 1/5, Loss: 0.036535341292619705\n",
      "Epoch: 1/5, Loss: 0.006841180380433798\n",
      "Epoch: 1/5, Loss: 0.012859654612839222\n",
      "Epoch: 1/5, Loss: 0.004730944521725178\n",
      "Epoch: 1/5, Loss: 0.05548562481999397\n",
      "Epoch: 1/5, Loss: 0.007553696632385254\n",
      "Epoch: 1/5, Loss: 0.04275859147310257\n",
      "Epoch: 1/5, Loss: 0.019389647990465164\n",
      "Epoch: 1/5, Loss: 0.0707436352968216\n",
      "Epoch: 1/5, Loss: 0.02273840829730034\n",
      "Epoch: 1/5, Loss: 0.04953174665570259\n",
      "Epoch: 1/5, Loss: 0.030768638476729393\n",
      "Epoch: 1/5, Loss: 0.011030885390937328\n",
      "Epoch: 1/5, Loss: 0.03190440312027931\n",
      "Epoch: 1/5, Loss: 0.00823893491178751\n",
      "Epoch: 1/5, Loss: 0.03500690311193466\n",
      "Epoch: 1/5, Loss: 0.02257702685892582\n",
      "Epoch: 1/5, Loss: 0.03763985633850098\n",
      "Epoch: 1/5, Loss: 0.006810212507843971\n",
      "Epoch: 1/5, Loss: 0.03999326378107071\n",
      "Epoch: 1/5, Loss: 0.02513236552476883\n",
      "Epoch: 1/5, Loss: 0.07774913311004639\n",
      "Epoch: 1/5, Loss: 0.01358458399772644\n",
      "Epoch: 1/5, Loss: 0.02502804435789585\n",
      "Epoch: 1/5, Loss: 0.010815871879458427\n",
      "Epoch: 1/5, Loss: 0.025123246014118195\n",
      "Epoch: 1/5, Loss: 0.014548582024872303\n",
      "Epoch: 1/5, Loss: 0.035209041088819504\n",
      "Epoch: 1/5, Loss: 0.02375154010951519\n",
      "Epoch: 1/5, Loss: 0.019308820366859436\n",
      "Epoch: 1/5, Loss: 0.03262495994567871\n",
      "Epoch: 1/5, Loss: 0.044665735214948654\n",
      "Epoch: 1/5, Loss: 0.018447132781147957\n",
      "Epoch: 1/5, Loss: 0.01941613480448723\n",
      "Epoch: 1/5, Loss: 0.022603046149015427\n",
      "Epoch: 1/5, Loss: 0.009517312049865723\n",
      "Epoch: 1/5, Loss: 0.03420955687761307\n",
      "Epoch: 1/5, Loss: 0.007166052237153053\n",
      "Epoch: 1/5, Loss: 0.0538528636097908\n",
      "Epoch: 1/5, Loss: 0.032435543835163116\n",
      "Epoch: 1/5, Loss: 0.031875770539045334\n",
      "Epoch: 1/5, Loss: 0.008791513741016388\n",
      "Epoch: 1/5, Loss: 0.015029463917016983\n",
      "Epoch: 1/5, Loss: 0.01211363635957241\n",
      "Epoch: 1/5, Loss: 0.09063316881656647\n",
      "Epoch: 1/5, Loss: 0.04624413698911667\n",
      "Epoch: 1/5, Loss: 0.04127393662929535\n",
      "Epoch: 1/5, Loss: 0.11800236254930496\n",
      "Epoch: 1/5, Loss: 0.03362279385328293\n",
      "Epoch: 1/5, Loss: 0.028243007138371468\n",
      "Epoch: 1/5, Loss: 0.011190156452357769\n",
      "Epoch: 1/5, Loss: 0.05136273056268692\n",
      "Epoch: 1/5, Loss: 0.01077345386147499\n",
      "Epoch: 1/5, Loss: 0.015069976449012756\n",
      "Epoch: 1/5, Loss: 0.034371741116046906\n",
      "Epoch: 1/5, Loss: 0.046959038823843\n",
      "Epoch: 1/5, Loss: 0.04348600655794144\n",
      "Epoch: 1/5, Loss: 0.027568841353058815\n",
      "Epoch: 1/5, Loss: 0.045618779957294464\n",
      "Epoch: 1/5, Loss: 0.029987335205078125\n",
      "Epoch: 1/5, Loss: 0.0010938436025753617\n",
      "Epoch: 1/5, Loss: 0.032672543078660965\n",
      "Epoch: 1/5, Loss: 0.01286953967064619\n",
      "Epoch: 1/5, Loss: 0.06490635126829147\n",
      "Epoch: 1/5, Loss: 0.01998845860362053\n",
      "Epoch: 1/5, Loss: 0.002837245585396886\n",
      "Epoch: 1/5, Loss: 0.009802659973502159\n",
      "Epoch: 1/5, Loss: 0.006618429906666279\n",
      "Epoch: 1/5, Loss: 0.02024677023291588\n",
      "Epoch: 1/5, Loss: 0.01372424978762865\n",
      "Epoch: 1/5, Loss: 0.02740747295320034\n",
      "Epoch: 1/5, Loss: 0.0539882630109787\n",
      "Epoch: 1/5, Loss: 0.01679067686200142\n",
      "Epoch: 1/5, Loss: 0.04601190984249115\n",
      "Epoch: 1/5, Loss: 0.03232830762863159\n",
      "Epoch: 1/5, Loss: 0.007447786629199982\n",
      "Epoch: 1/5, Loss: 0.00847269594669342\n",
      "Epoch: 1/5, Loss: 0.01762821152806282\n",
      "Epoch: 1/5, Loss: 0.03895631432533264\n",
      "Epoch: 1/5, Loss: 0.034462928771972656\n",
      "Epoch: 1/5, Loss: 0.017674146220088005\n",
      "Epoch: 1/5, Loss: 0.011354190297424793\n",
      "Epoch: 1/5, Loss: 0.00322120008058846\n",
      "Epoch: 1/5, Loss: 0.042559877038002014\n",
      "Epoch: 1/5, Loss: 0.005820544436573982\n",
      "Epoch: 1/5, Loss: 0.02166013978421688\n",
      "Epoch: 1/5, Loss: 0.06693337857723236\n",
      "Epoch: 1/5, Loss: 0.007769119925796986\n",
      "Epoch: 1/5, Loss: 0.012912447564303875\n",
      "Epoch: 1/5, Loss: 0.020087074488401413\n",
      "Epoch: 1/5, Loss: 0.006856461986899376\n",
      "Epoch: 1/5, Loss: 0.022244125604629517\n",
      "Epoch: 1/5, Loss: 0.02361767739057541\n",
      "Epoch: 1/5, Loss: 0.19757694005966187\n",
      "Epoch: 1/5, Loss: 0.026725634932518005\n",
      "Epoch: 1/5, Loss: 0.010312829166650772\n",
      "Epoch: 1/5, Loss: 0.015432104468345642\n",
      "Epoch: 1/5, Loss: 0.023306557908654213\n",
      "Epoch: 1/5, Loss: 0.032277658581733704\n",
      "Epoch: 1/5, Loss: 0.013962557539343834\n",
      "Epoch: 1/5, Loss: 0.019863102585077286\n",
      "Epoch: 1/5, Loss: 0.0087222158908844\n",
      "Epoch: 1/5, Loss: 0.03835694491863251\n",
      "Epoch: 1/5, Loss: 0.01443212479352951\n",
      "Epoch: 1/5, Loss: 0.04369736090302467\n",
      "Epoch: 1/5, Loss: 0.030852295458316803\n",
      "Epoch: 1/5, Loss: 0.03969522565603256\n",
      "Epoch: 1/5, Loss: 0.014427496120333672\n",
      "Epoch: 1/5, Loss: 0.06829508394002914\n",
      "Epoch: 1/5, Loss: 0.016603020951151848\n",
      "Epoch: 1/5, Loss: 0.12588413059711456\n",
      "Epoch: 1/5, Loss: 0.06446503102779388\n",
      "Epoch: 1/5, Loss: 0.09413160383701324\n",
      "Epoch: 1/5, Loss: 0.01569785736501217\n",
      "Epoch: 1/5, Loss: 0.03302926570177078\n",
      "Epoch: 1/5, Loss: 0.014523542486131191\n",
      "Epoch: 1/5, Loss: 0.022942475974559784\n",
      "Epoch: 1/5, Loss: 0.013439389877021313\n",
      "Epoch: 1/5, Loss: 0.005912899971008301\n",
      "Epoch: 1/5, Loss: 0.04591343551874161\n",
      "Epoch: 1/5, Loss: 0.03009873814880848\n",
      "Epoch: 1/5, Loss: 0.047310084104537964\n",
      "Epoch: 1/5, Loss: 0.018370496109128\n",
      "Epoch: 1/5, Loss: 0.010877098888158798\n",
      "Epoch: 1/5, Loss: 0.016376830637454987\n",
      "Epoch: 1/5, Loss: 0.05100609362125397\n",
      "Epoch: 1/5, Loss: 0.023765118792653084\n",
      "Epoch: 1/5, Loss: 0.02438889443874359\n",
      "Epoch: 1/5, Loss: 0.013448040932416916\n",
      "Epoch: 1/5, Loss: 0.054839007556438446\n",
      "Epoch: 1/5, Loss: 0.014696307480335236\n",
      "Epoch: 1/5, Loss: 0.019063392654061317\n",
      "Epoch: 1/5, Loss: 0.0015021790750324726\n",
      "Epoch: 1/5, Loss: 0.03264855965971947\n",
      "Epoch: 1/5, Loss: 0.023135237395763397\n",
      "Epoch: 1/5, Loss: 0.0276171937584877\n",
      "Epoch: 1/5, Loss: 0.02414928562939167\n",
      "Epoch: 1/5, Loss: 0.014033626765012741\n",
      "Epoch: 1/5, Loss: 0.058929260820150375\n",
      "Epoch: 1/5, Loss: 0.032842181622982025\n",
      "Epoch: 1/5, Loss: 0.03643162176012993\n",
      "Epoch: 1/5, Loss: 0.05078430473804474\n",
      "Epoch: 1/5, Loss: 0.0524764358997345\n",
      "Epoch: 1/5, Loss: 0.06020142510533333\n",
      "Epoch: 1/5, Loss: 0.015922240912914276\n",
      "Epoch: 1/5, Loss: 0.045830659568309784\n",
      "Epoch: 1/5, Loss: 0.009126227349042892\n",
      "Epoch: 1/5, Loss: 0.01842052862048149\n",
      "Epoch: 1/5, Loss: 0.04122140631079674\n",
      "Epoch: 1/5, Loss: 0.049451109021902084\n",
      "Epoch: 1/5, Loss: 0.01475408673286438\n",
      "Epoch: 1/5, Loss: 0.012924706563353539\n",
      "Epoch: 1/5, Loss: 0.05125923827290535\n",
      "Epoch: 1/5, Loss: 0.010692263022065163\n",
      "Epoch: 1/5, Loss: 0.040615640580654144\n",
      "Epoch: 1/5, Loss: 0.005518573336303234\n",
      "Epoch: 1/5, Loss: 0.04507897049188614\n",
      "Epoch: 1/5, Loss: 0.01981436088681221\n",
      "Epoch: 1/5, Loss: 0.03691967576742172\n",
      "Epoch: 1/5, Loss: 0.014645383693277836\n",
      "Epoch: 1/5, Loss: 0.04202570766210556\n",
      "Epoch: 1/5, Loss: 0.02944325841963291\n",
      "Epoch: 1/5, Loss: 0.0270831398665905\n",
      "Epoch: 1/5, Loss: 0.07871858030557632\n",
      "Epoch: 1/5, Loss: 0.010081712156534195\n",
      "Epoch: 1/5, Loss: 0.02187681384384632\n",
      "Epoch: 1/5, Loss: 0.01742669753730297\n",
      "Epoch: 1/5, Loss: 0.054118674248456955\n",
      "Epoch: 1/5, Loss: 0.04706963524222374\n",
      "Epoch: 1/5, Loss: 0.016058657318353653\n",
      "Epoch: 1/5, Loss: 0.03192422538995743\n",
      "Epoch: 1/5, Loss: 0.024229004979133606\n",
      "Epoch: 1/5, Loss: 0.02001035027205944\n",
      "Epoch: 1/5, Loss: 0.006740102544426918\n",
      "Epoch: 1/5, Loss: 0.0318826287984848\n",
      "Epoch: 1/5, Loss: 0.004491179250180721\n",
      "Epoch: 1/5, Loss: 0.04414079338312149\n",
      "Epoch: 1/5, Loss: 0.02215951681137085\n",
      "Epoch: 1/5, Loss: 0.022776704281568527\n",
      "Epoch: 1/5, Loss: 0.016302192583680153\n",
      "Epoch: 1/5, Loss: 0.06250584870576859\n",
      "Epoch: 1/5, Loss: 0.00635932944715023\n",
      "Epoch: 1/5, Loss: 0.02822207286953926\n",
      "Epoch: 1/5, Loss: 0.010382197797298431\n",
      "Epoch: 1/5, Loss: 0.0770692527294159\n",
      "Epoch: 1/5, Loss: 0.011154834181070328\n",
      "Epoch: 1/5, Loss: 0.019510582089424133\n",
      "Epoch: 1/5, Loss: 0.10333140194416046\n",
      "Epoch: 1/5, Loss: 0.1317102015018463\n",
      "Epoch: 1/5, Loss: 0.028597500175237656\n",
      "Epoch: 1/5, Loss: 0.031110037118196487\n",
      "Epoch: 1/5, Loss: 0.006044951267540455\n",
      "Epoch: 1/5, Loss: 0.032349277287721634\n",
      "Epoch: 1/5, Loss: 0.031214697286486626\n",
      "Epoch: 1/5, Loss: 0.016438543796539307\n",
      "Epoch: 1/5, Loss: 0.039105065166950226\n",
      "Epoch: 1/5, Loss: 0.008861630223691463\n",
      "Epoch: 1/5, Loss: 0.013457308523356915\n",
      "Epoch: 1/5, Loss: 0.05280594900250435\n",
      "Epoch: 1/5, Loss: 0.05935092270374298\n",
      "Epoch: 1/5, Loss: 0.028786124661564827\n",
      "Epoch: 1/5, Loss: 0.018616197630763054\n",
      "Epoch: 1/5, Loss: 0.018450744450092316\n",
      "Epoch: 1/5, Loss: 0.011350768618285656\n",
      "Epoch: 1/5, Loss: 0.15465141832828522\n",
      "Epoch: 1/5, Loss: 0.04848229140043259\n",
      "Epoch: 1/5, Loss: 0.024002106860280037\n",
      "Epoch: 1/5, Loss: 0.027505850419402122\n",
      "Epoch: 1/5, Loss: 0.01129127200692892\n",
      "Epoch: 1/5, Loss: 0.0243294145911932\n",
      "Epoch: 1/5, Loss: 0.010124566033482552\n",
      "Epoch: 1/5, Loss: 0.04247504100203514\n",
      "Epoch: 1/5, Loss: 0.012624254450201988\n",
      "Epoch: 1/5, Loss: 0.04907689243555069\n",
      "Epoch: 1/5, Loss: 0.011375433765351772\n",
      "Epoch: 1/5, Loss: 0.014866970479488373\n",
      "Epoch: 1/5, Loss: 0.019832784309983253\n",
      "Epoch: 1/5, Loss: 0.03124896250665188\n",
      "Epoch: 1/5, Loss: 0.00997532345354557\n",
      "Epoch: 1/5, Loss: 0.005707164295017719\n",
      "Epoch: 1/5, Loss: 0.0040891519747674465\n",
      "Epoch: 1/5, Loss: 0.01321837492287159\n",
      "Epoch: 1/5, Loss: 0.005757839884608984\n",
      "Epoch: 1/5, Loss: 0.00811519380658865\n",
      "Epoch: 1/5, Loss: 0.07067715376615524\n",
      "Epoch: 1/5, Loss: 0.008375304751098156\n",
      "Epoch: 1/5, Loss: 0.008870283141732216\n",
      "Epoch: 1/5, Loss: 0.02739918790757656\n",
      "Epoch: 1/5, Loss: 0.04127362370491028\n",
      "Epoch: 1/5, Loss: 0.004701153840869665\n",
      "Epoch: 1/5, Loss: 0.032602790743112564\n",
      "Epoch: 1/5, Loss: 0.007790157571434975\n",
      "Epoch: 1/5, Loss: 0.044749919325113297\n",
      "Epoch: 1/5, Loss: 0.02436460182070732\n",
      "Epoch: 1/5, Loss: 0.007841859012842178\n",
      "Epoch: 1/5, Loss: 0.031146004796028137\n",
      "Epoch: 1/5, Loss: 0.017784886062145233\n",
      "Epoch: 1/5, Loss: 0.03433782979846001\n",
      "Epoch: 1/5, Loss: 0.0339287631213665\n",
      "Epoch: 1/5, Loss: 0.0448441281914711\n",
      "Epoch: 1/5, Loss: 0.012456679716706276\n",
      "Epoch: 1/5, Loss: 0.008744173683226109\n",
      "Epoch: 1/5, Loss: 0.011378144845366478\n",
      "Epoch: 1/5, Loss: 0.029982447624206543\n",
      "Epoch: 1/5, Loss: 0.005393411498516798\n",
      "Epoch: 1/5, Loss: 0.02036476880311966\n",
      "Epoch: 1/5, Loss: 0.038867466151714325\n",
      "Epoch: 1/5, Loss: 0.022321736440062523\n",
      "Epoch: 1/5, Loss: 0.019927360117435455\n",
      "Epoch: 1/5, Loss: 0.007404995150864124\n",
      "Epoch: 1/5, Loss: 0.00595336826518178\n",
      "Epoch: 1/5, Loss: 0.019227221608161926\n",
      "Epoch: 1/5, Loss: 0.022784721106290817\n",
      "Epoch: 1/5, Loss: 0.03297870233654976\n",
      "Epoch: 1/5, Loss: 0.05361302196979523\n",
      "Epoch: 1/5, Loss: 0.09521345049142838\n",
      "Epoch: 1/5, Loss: 0.01461460068821907\n",
      "Epoch: 1/5, Loss: 0.011974003165960312\n",
      "Epoch: 1/5, Loss: 0.035784635692834854\n",
      "Epoch: 1/5, Loss: 0.01872122660279274\n",
      "Epoch: 1/5, Loss: 0.04861807823181152\n",
      "Epoch: 1/5, Loss: 0.007385982200503349\n",
      "Epoch: 1/5, Loss: 0.01651119440793991\n",
      "Epoch: 1/5, Loss: 0.018637584522366524\n",
      "Epoch: 1/5, Loss: 0.01885356195271015\n",
      "Epoch: 1/5, Loss: 0.028600914403796196\n",
      "Epoch: 1/5, Loss: 0.07386299222707748\n",
      "Epoch: 1/5, Loss: 0.051689621061086655\n",
      "Epoch: 1/5, Loss: 0.06920747458934784\n",
      "Epoch: 1/5, Loss: 0.039553381502628326\n",
      "Epoch: 1/5, Loss: 0.006479357834905386\n",
      "Epoch: 1/5, Loss: 0.006512596737593412\n",
      "Epoch: 1/5, Loss: 0.024294095113873482\n",
      "Epoch: 1/5, Loss: 0.04232919588685036\n",
      "Epoch: 1/5, Loss: 0.020324066281318665\n",
      "Epoch: 1/5, Loss: 0.08393777906894684\n",
      "Epoch: 1/5, Loss: 0.09210408478975296\n",
      "Epoch: 1/5, Loss: 0.016727779060602188\n",
      "Epoch: 1/5, Loss: 0.06422737240791321\n",
      "Epoch: 1/5, Loss: 0.018025554716587067\n",
      "Epoch: 1/5, Loss: 0.004272550344467163\n",
      "Epoch: 1/5, Loss: 0.038918960839509964\n",
      "Epoch: 1/5, Loss: 0.09846832603216171\n",
      "Epoch: 1/5, Loss: 0.010403865948319435\n",
      "Epoch: 1/5, Loss: 0.01467630360275507\n",
      "Epoch: 1/5, Loss: 0.033864304423332214\n",
      "Epoch: 1/5, Loss: 0.015327680855989456\n",
      "Epoch: 1/5, Loss: 0.03975507244467735\n",
      "Epoch: 1/5, Loss: 0.034454066306352615\n",
      "Epoch: 1/5, Loss: 0.0065036797896027565\n",
      "Epoch: 1/5, Loss: 0.006822476163506508\n",
      "Epoch: 1/5, Loss: 0.046278953552246094\n",
      "Epoch: 1/5, Loss: 0.03770095482468605\n",
      "Epoch: 1/5, Loss: 0.004760079551488161\n",
      "Epoch: 1/5, Loss: 0.05509777367115021\n",
      "Epoch: 1/5, Loss: 0.013967200182378292\n",
      "Epoch: 1/5, Loss: 0.03777862340211868\n",
      "Epoch: 1/5, Loss: 0.00419983034953475\n",
      "Epoch: 1/5, Loss: 0.019257748499512672\n",
      "Epoch: 1/5, Loss: 0.005035090260207653\n",
      "Epoch: 1/5, Loss: 0.05424753576517105\n",
      "Epoch: 1/5, Loss: 0.08593358844518661\n",
      "Epoch: 1/5, Loss: 0.01443815603852272\n",
      "Epoch: 1/5, Loss: 0.04280601069331169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Loss: 0.024382691830396652\n",
      "Epoch: 1/5, Loss: 0.04024592414498329\n",
      "Epoch: 1/5, Loss: 0.005442417226731777\n",
      "Epoch: 1/5, Loss: 0.009135809727013111\n",
      "Epoch: 1/5, Loss: 0.017157860100269318\n",
      "Epoch: 1/5, Loss: 0.00855586864054203\n",
      "Epoch: 1/5, Loss: 0.015481509268283844\n",
      "Epoch: 1/5, Loss: 0.012787370942533016\n",
      "Epoch: 1/5, Loss: 0.03398417308926582\n",
      "Epoch: 1/5, Loss: 0.038596261292696\n",
      "Epoch: 1/5, Loss: 0.07609329372644424\n",
      "Epoch: 1/5, Loss: 0.021417545154690742\n",
      "Epoch: 1/5, Loss: 0.020517893135547638\n",
      "Epoch: 1/5, Loss: 0.0096110999584198\n",
      "Epoch: 1/5, Loss: 0.01596149615943432\n",
      "Epoch: 1/5, Loss: 0.00836610235273838\n",
      "Epoch: 1/5, Loss: 0.04537900164723396\n",
      "Epoch: 1/5, Loss: 0.036458492279052734\n",
      "Epoch: 1/5, Loss: 0.026121828705072403\n",
      "Epoch: 1/5, Loss: 0.02355378307402134\n",
      "Epoch: 1/5, Loss: 0.023211494088172913\n",
      "Epoch: 1/5, Loss: 0.010793793015182018\n",
      "Epoch: 1/5, Loss: 0.0010509913554415107\n",
      "Epoch: 1/5, Loss: 0.029705047607421875\n",
      "Epoch: 1/5, Loss: 0.01966405101120472\n",
      "Epoch: 1/5, Loss: 0.019466523081064224\n",
      "Epoch: 1/5, Loss: 0.005251822527498007\n",
      "Epoch: 1/5, Loss: 0.022592851892113686\n",
      "Epoch: 1/5, Loss: 0.014849048107862473\n",
      "Epoch: 1/5, Loss: 0.05540076270699501\n",
      "Epoch: 1/5, Loss: 0.022752545773983\n",
      "Epoch: 1/5, Loss: 0.03566572815179825\n",
      "Epoch: 1/5, Loss: 0.0342816598713398\n",
      "Epoch: 1/5, Loss: 0.007485236972570419\n",
      "Epoch: 1/5, Loss: 0.007318176794797182\n",
      "Epoch: 1/5, Loss: 0.031285300850868225\n",
      "Epoch: 1/5, Loss: 0.05917763337492943\n",
      "Epoch: 1/5, Loss: 0.0358271487057209\n",
      "Epoch: 1/5, Loss: 0.018430544063448906\n",
      "Epoch: 1/5, Loss: 0.014390687458217144\n",
      "Epoch: 1/5, Loss: 0.03468071669340134\n",
      "Epoch: 1/5, Loss: 0.026506690308451653\n",
      "Epoch: 1/5, Loss: 0.00876622274518013\n",
      "Epoch: 1/5, Loss: 0.03806942328810692\n",
      "Epoch: 1/5, Loss: 0.030511584132909775\n",
      "Epoch: 1/5, Loss: 0.022541558369994164\n",
      "Epoch: 1/5, Loss: 0.017539920285344124\n",
      "Epoch: 1/5, Loss: 0.04934290051460266\n",
      "Epoch: 1/5, Loss: 0.014010618440806866\n",
      "Epoch: 1/5, Loss: 0.00829789787530899\n",
      "Epoch: 1/5, Loss: 0.02608826942741871\n",
      "Epoch: 1/5, Loss: 0.032656293362379074\n",
      "Epoch: 1/5, Loss: 0.02975023165345192\n",
      "Epoch: 1/5, Loss: 0.04686976596713066\n",
      "Epoch: 1/5, Loss: 0.004762622993439436\n",
      "Epoch: 1/5, Loss: 0.009379630908370018\n",
      "Epoch: 1/5, Loss: 0.008370151743292809\n",
      "Epoch: 1/5, Loss: 0.009025088511407375\n",
      "Epoch: 1/5, Loss: 0.01375172846019268\n",
      "Epoch: 1/5, Loss: 0.013617749325931072\n",
      "Epoch: 1/5, Loss: 0.012516714632511139\n",
      "Epoch: 1/5, Loss: 0.004371372051537037\n",
      "Epoch: 1/5, Loss: 0.013748608529567719\n",
      "Epoch: 1/5, Loss: 0.023108217865228653\n",
      "Epoch: 1/5, Loss: 0.040433306246995926\n",
      "Epoch: 1/5, Loss: 0.005037249997258186\n",
      "Epoch: 1/5, Loss: 0.019963083788752556\n",
      "Epoch: 1/5, Loss: 0.00989238265901804\n",
      "Epoch: 1/5, Loss: 0.026481853798031807\n",
      "Epoch: 1/5, Loss: 0.017832256853580475\n",
      "Epoch: 1/5, Loss: 0.08862002938985825\n",
      "Epoch: 1/5, Loss: 0.02724284864962101\n",
      "Epoch: 1/5, Loss: 0.026444153860211372\n",
      "Epoch: 1/5, Loss: 0.05774926394224167\n",
      "Epoch: 1/5, Loss: 0.015997210517525673\n",
      "Epoch: 1/5, Loss: 0.014383453875780106\n",
      "Epoch: 1/5, Loss: 0.0130428746342659\n",
      "Epoch: 1/5, Loss: 0.006902754306793213\n",
      "Epoch: 1/5, Loss: 0.005367014557123184\n",
      "Epoch: 1/5, Loss: 0.012633916921913624\n",
      "Epoch: 1/5, Loss: 0.09387414902448654\n",
      "Epoch: 1/5, Loss: 0.04567733034491539\n",
      "Epoch: 1/5, Loss: 0.009433270432054996\n",
      "Epoch: 1/5, Loss: 0.01573331654071808\n",
      "Epoch: 1/5, Loss: 0.00959208607673645\n",
      "Epoch: 1/5, Loss: 0.04200876131653786\n",
      "Epoch: 1/5, Loss: 0.02043439820408821\n",
      "Epoch: 1/5, Loss: 0.014756361022591591\n",
      "Epoch: 1/5, Loss: 0.037542469799518585\n",
      "Epoch: 1/5, Loss: 0.05421764776110649\n",
      "Epoch: 1/5, Loss: 0.010255587287247181\n",
      "Epoch: 1/5, Loss: 0.02499200403690338\n",
      "Epoch: 1/5, Loss: 0.05363641306757927\n",
      "Epoch: 1/5, Loss: 0.009259700775146484\n",
      "Epoch: 1/5, Loss: 0.00318139442242682\n",
      "Epoch: 1/5, Loss: 0.0463663749396801\n",
      "Epoch: 1/5, Loss: 0.07939615100622177\n",
      "Epoch: 1/5, Loss: 0.022190187126398087\n",
      "Epoch: 1/5, Loss: 0.03983890265226364\n",
      "Epoch: 1/5, Loss: 0.03277042880654335\n",
      "Epoch: 1/5, Loss: 0.027733273804187775\n",
      "Epoch: 1/5, Loss: 0.04582194983959198\n",
      "Epoch: 1/5, Loss: 0.04981228709220886\n",
      "Epoch: 1/5, Loss: 0.03687020391225815\n",
      "Epoch: 1/5, Loss: 0.003320961957797408\n",
      "Epoch: 1/5, Loss: 0.010153603740036488\n",
      "Epoch: 1/5, Loss: 0.005064067430794239\n",
      "Epoch: 1/5, Loss: 0.016734959557652473\n",
      "Epoch: 1/5, Loss: 0.00939707551151514\n",
      "Epoch: 1/5, Loss: 0.020449399948120117\n",
      "Epoch: 1/5, Loss: 0.0378665030002594\n",
      "Epoch: 1/5, Loss: 0.03972941264510155\n",
      "Epoch: 1/5, Loss: 0.020168762654066086\n",
      "Epoch: 1/5, Loss: 0.07344701886177063\n",
      "Epoch: 1/5, Loss: 0.03203243389725685\n",
      "Epoch: 1/5, Loss: 0.033192262053489685\n",
      "Epoch: 1/5, Loss: 0.052955515682697296\n",
      "Epoch: 1/5, Loss: 0.007675057277083397\n",
      "Epoch: 1/5, Loss: 0.011308403685688972\n",
      "Epoch: 1/5, Loss: 0.0765240341424942\n",
      "Epoch: 1/5, Loss: 0.021249761804938316\n",
      "Epoch: 1/5, Loss: 0.06180571764707565\n",
      "Epoch: 1/5, Loss: 0.00898589938879013\n",
      "Epoch: 1/5, Loss: 0.02449541911482811\n",
      "Epoch: 1/5, Loss: 0.012838935479521751\n",
      "Epoch: 1/5, Loss: 0.05703459307551384\n",
      "Epoch: 1/5, Loss: 0.03385975956916809\n",
      "Epoch: 1/5, Loss: 0.03453851491212845\n",
      "Epoch: 1/5, Loss: 0.021362513303756714\n",
      "Epoch: 1/5, Loss: 0.0006638102931901813\n",
      "Epoch: 1/5, Loss: 0.03911999613046646\n",
      "Epoch: 1/5, Loss: 0.021094579249620438\n",
      "Epoch: 1/5, Loss: 0.051083214581012726\n",
      "Epoch: 1/5, Loss: 0.028587423264980316\n",
      "Epoch: 1/5, Loss: 0.0013318323763087392\n",
      "Epoch: 1/5, Loss: 0.01909751258790493\n",
      "Epoch: 1/5, Loss: 0.052481021732091904\n",
      "Epoch: 1/5, Loss: 0.10943327844142914\n",
      "Epoch: 1/5, Loss: 0.08009164035320282\n",
      "Epoch: 1/5, Loss: 0.013385863974690437\n",
      "Epoch: 1/5, Loss: 0.08924026787281036\n",
      "Epoch: 1/5, Loss: 0.02941988967359066\n",
      "Epoch: 1/5, Loss: 0.002547528827562928\n",
      "Epoch: 1/5, Loss: 0.023297665640711784\n",
      "Epoch: 1/5, Loss: 0.025289418175816536\n",
      "Epoch: 1/5, Loss: 0.032371845096349716\n",
      "Epoch: 1/5, Loss: 0.02916322834789753\n",
      "Epoch: 1/5, Loss: 0.07659133523702621\n",
      "Epoch: 1/5, Loss: 0.06046872213482857\n",
      "Epoch: 2/5, Loss: 0.0217719916254282\n",
      "Epoch: 2/5, Loss: 0.06376289576292038\n",
      "Epoch: 2/5, Loss: 0.0038562407717108727\n",
      "Epoch: 2/5, Loss: 0.02443654090166092\n",
      "Epoch: 2/5, Loss: 0.03278345614671707\n",
      "Epoch: 2/5, Loss: 0.04284396767616272\n",
      "Epoch: 2/5, Loss: 0.014828993007540703\n",
      "Epoch: 2/5, Loss: 0.019487392157316208\n",
      "Epoch: 2/5, Loss: 0.012045597657561302\n",
      "Epoch: 2/5, Loss: 0.020278701558709145\n",
      "Epoch: 2/5, Loss: 0.04937371984124184\n",
      "Epoch: 2/5, Loss: 0.04669640585780144\n",
      "Epoch: 2/5, Loss: 0.014066657051444054\n",
      "Epoch: 2/5, Loss: 0.0197142381221056\n",
      "Epoch: 2/5, Loss: 0.0234591756016016\n",
      "Epoch: 2/5, Loss: 0.0060122013092041016\n",
      "Epoch: 2/5, Loss: 0.017676223069429398\n",
      "Epoch: 2/5, Loss: 0.03870845213532448\n",
      "Epoch: 2/5, Loss: 0.049475520849227905\n",
      "Epoch: 2/5, Loss: 0.008267661556601524\n",
      "Epoch: 2/5, Loss: 0.025804657489061356\n",
      "Epoch: 2/5, Loss: 0.09620139747858047\n",
      "Epoch: 2/5, Loss: 0.013752104714512825\n",
      "Epoch: 2/5, Loss: 0.02490227296948433\n",
      "Epoch: 2/5, Loss: 0.026994861662387848\n",
      "Epoch: 2/5, Loss: 0.06529892981052399\n",
      "Epoch: 2/5, Loss: 0.011446813121438026\n",
      "Epoch: 2/5, Loss: 0.01738409698009491\n",
      "Epoch: 2/5, Loss: 0.02424119971692562\n",
      "Epoch: 2/5, Loss: 0.016704808920621872\n",
      "Epoch: 2/5, Loss: 0.05447006598114967\n",
      "Epoch: 2/5, Loss: 0.011932515539228916\n",
      "Epoch: 2/5, Loss: 0.02958706021308899\n",
      "Epoch: 2/5, Loss: 0.06282543390989304\n",
      "Epoch: 2/5, Loss: 0.003093952080234885\n",
      "Epoch: 2/5, Loss: 0.015441513620316982\n",
      "Epoch: 2/5, Loss: 0.035054102540016174\n",
      "Epoch: 2/5, Loss: 0.019546959549188614\n",
      "Epoch: 2/5, Loss: 0.016887525096535683\n",
      "Epoch: 2/5, Loss: 0.02347843535244465\n",
      "Epoch: 2/5, Loss: 0.033090170472860336\n",
      "Epoch: 2/5, Loss: 0.029288504272699356\n",
      "Epoch: 2/5, Loss: 0.006551957689225674\n",
      "Epoch: 2/5, Loss: 0.03578578308224678\n",
      "Epoch: 2/5, Loss: 0.009791580960154533\n",
      "Epoch: 2/5, Loss: 0.07375215739011765\n",
      "Epoch: 2/5, Loss: 0.0070130107924342155\n",
      "Epoch: 2/5, Loss: 0.02948516234755516\n",
      "Epoch: 2/5, Loss: 0.02157396450638771\n",
      "Epoch: 2/5, Loss: 0.0693635493516922\n",
      "Epoch: 2/5, Loss: 0.02429981529712677\n",
      "Epoch: 2/5, Loss: 0.04080966114997864\n",
      "Epoch: 2/5, Loss: 0.026338135823607445\n",
      "Epoch: 2/5, Loss: 0.05156291276216507\n",
      "Epoch: 2/5, Loss: 0.03222835808992386\n",
      "Epoch: 2/5, Loss: 0.018881289288401604\n",
      "Epoch: 2/5, Loss: 0.006631937343627214\n",
      "Epoch: 2/5, Loss: 0.013322912156581879\n",
      "Epoch: 2/5, Loss: 0.007733914535492659\n",
      "Epoch: 2/5, Loss: 0.07759927213191986\n",
      "Epoch: 2/5, Loss: 0.05364195257425308\n",
      "Epoch: 2/5, Loss: 0.04720452427864075\n",
      "Epoch: 2/5, Loss: 0.007721123285591602\n",
      "Epoch: 2/5, Loss: 0.02021806500852108\n",
      "Epoch: 2/5, Loss: 0.04357928782701492\n",
      "Epoch: 2/5, Loss: 0.03373177349567413\n",
      "Epoch: 2/5, Loss: 0.017712995409965515\n",
      "Epoch: 2/5, Loss: 0.0323815792798996\n",
      "Epoch: 2/5, Loss: 0.040382422506809235\n",
      "Epoch: 2/5, Loss: 0.020974595099687576\n",
      "Epoch: 2/5, Loss: 0.009443869814276695\n",
      "Epoch: 2/5, Loss: 0.02462632581591606\n",
      "Epoch: 2/5, Loss: 0.06896359473466873\n",
      "Epoch: 2/5, Loss: 0.031239844858646393\n",
      "Epoch: 2/5, Loss: 0.037287987768650055\n",
      "Epoch: 2/5, Loss: 0.01414145901799202\n",
      "Epoch: 2/5, Loss: 0.02365889772772789\n",
      "Epoch: 2/5, Loss: 0.023902762681245804\n",
      "Epoch: 2/5, Loss: 0.02521470934152603\n",
      "Epoch: 2/5, Loss: 0.01719006896018982\n",
      "Epoch: 2/5, Loss: 0.009928826242685318\n",
      "Epoch: 2/5, Loss: 0.01983719691634178\n",
      "Epoch: 2/5, Loss: 0.032410264015197754\n",
      "Epoch: 2/5, Loss: 0.020717475563287735\n",
      "Epoch: 2/5, Loss: 0.05942859500646591\n",
      "Epoch: 2/5, Loss: 0.02955908514559269\n",
      "Epoch: 2/5, Loss: 0.04292653501033783\n",
      "Epoch: 2/5, Loss: 0.018597353249788284\n",
      "Epoch: 2/5, Loss: 0.007965628989040852\n",
      "Epoch: 2/5, Loss: 0.010572616010904312\n",
      "Epoch: 2/5, Loss: 0.010537282563745975\n",
      "Epoch: 2/5, Loss: 0.005986563861370087\n",
      "Epoch: 2/5, Loss: 0.04021456465125084\n",
      "Epoch: 2/5, Loss: 0.03862444683909416\n",
      "Epoch: 2/5, Loss: 0.03554503619670868\n",
      "Epoch: 2/5, Loss: 0.015189442783594131\n",
      "Epoch: 2/5, Loss: 0.03692216798663139\n",
      "Epoch: 2/5, Loss: 0.009349256753921509\n",
      "Epoch: 2/5, Loss: 0.03564829006791115\n",
      "Epoch: 2/5, Loss: 0.030735377222299576\n",
      "Epoch: 2/5, Loss: 0.08339456468820572\n",
      "Epoch: 2/5, Loss: 0.04510243237018585\n",
      "Epoch: 2/5, Loss: 0.002140241675078869\n",
      "Epoch: 2/5, Loss: 0.020771970972418785\n",
      "Epoch: 2/5, Loss: 0.03600938990712166\n",
      "Epoch: 2/5, Loss: 0.020302170887589455\n",
      "Epoch: 2/5, Loss: 0.0683736726641655\n",
      "Epoch: 2/5, Loss: 0.03362034261226654\n",
      "Epoch: 2/5, Loss: 0.008151632733643055\n",
      "Epoch: 2/5, Loss: 0.01331113651394844\n",
      "Epoch: 2/5, Loss: 0.00804315134882927\n",
      "Epoch: 2/5, Loss: 0.00456557422876358\n",
      "Epoch: 2/5, Loss: 0.00974503718316555\n",
      "Epoch: 2/5, Loss: 0.0030241156928241253\n",
      "Epoch: 2/5, Loss: 0.03496214747428894\n",
      "Epoch: 2/5, Loss: 0.06221643090248108\n",
      "Epoch: 2/5, Loss: 0.03478772193193436\n",
      "Epoch: 2/5, Loss: 0.02704707160592079\n",
      "Epoch: 2/5, Loss: 0.008599274791777134\n",
      "Epoch: 2/5, Loss: 0.0667191743850708\n",
      "Epoch: 2/5, Loss: 0.09959228336811066\n",
      "Epoch: 2/5, Loss: 0.024100959300994873\n",
      "Epoch: 2/5, Loss: 0.0016754730604588985\n",
      "Epoch: 2/5, Loss: 0.01948494091629982\n",
      "Epoch: 2/5, Loss: 0.03167995437979698\n",
      "Epoch: 2/5, Loss: 0.005404263734817505\n",
      "Epoch: 2/5, Loss: 0.04398228973150253\n",
      "Epoch: 2/5, Loss: 0.030347075313329697\n",
      "Epoch: 2/5, Loss: 0.026599936187267303\n",
      "Epoch: 2/5, Loss: 0.012511593289673328\n",
      "Epoch: 2/5, Loss: 0.002963957842439413\n",
      "Epoch: 2/5, Loss: 0.005518421996384859\n",
      "Epoch: 2/5, Loss: 0.07311639934778214\n",
      "Epoch: 2/5, Loss: 0.036280710250139236\n",
      "Epoch: 2/5, Loss: 0.1247306615114212\n",
      "Epoch: 2/5, Loss: 0.004662696272134781\n",
      "Epoch: 2/5, Loss: 0.010832021944224834\n",
      "Epoch: 2/5, Loss: 0.03414583578705788\n",
      "Epoch: 2/5, Loss: 0.03595300018787384\n",
      "Epoch: 2/5, Loss: 0.0038694064132869244\n",
      "Epoch: 2/5, Loss: 0.03514472022652626\n",
      "Epoch: 2/5, Loss: 0.011213375255465508\n",
      "Epoch: 2/5, Loss: 0.01961817406117916\n",
      "Epoch: 2/5, Loss: 0.017844364047050476\n",
      "Epoch: 2/5, Loss: 0.033260028809309006\n",
      "Epoch: 2/5, Loss: 0.0184317734092474\n",
      "Epoch: 2/5, Loss: 0.020932985469698906\n",
      "Epoch: 2/5, Loss: 0.048434942960739136\n",
      "Epoch: 2/5, Loss: 0.023494254797697067\n",
      "Epoch: 2/5, Loss: 0.006007861811667681\n",
      "Epoch: 2/5, Loss: 0.04576882719993591\n",
      "Epoch: 2/5, Loss: 0.030002832412719727\n",
      "Epoch: 2/5, Loss: 0.019699018448591232\n",
      "Epoch: 2/5, Loss: 0.02983177825808525\n",
      "Epoch: 2/5, Loss: 0.023036856204271317\n",
      "Epoch: 2/5, Loss: 0.00986500270664692\n",
      "Epoch: 2/5, Loss: 0.005873918067663908\n",
      "Epoch: 2/5, Loss: 0.03911469131708145\n",
      "Epoch: 2/5, Loss: 0.02868136391043663\n",
      "Epoch: 2/5, Loss: 0.03183390945196152\n",
      "Epoch: 2/5, Loss: 0.005838141310960054\n",
      "Epoch: 2/5, Loss: 0.06534336507320404\n",
      "Epoch: 2/5, Loss: 0.03487518057227135\n",
      "Epoch: 2/5, Loss: 0.007902459241449833\n",
      "Epoch: 2/5, Loss: 0.024177955463528633\n",
      "Epoch: 2/5, Loss: 0.054375529289245605\n",
      "Epoch: 2/5, Loss: 0.00419450830668211\n",
      "Epoch: 2/5, Loss: 0.031991519033908844\n",
      "Epoch: 2/5, Loss: 0.066525898873806\n",
      "Epoch: 2/5, Loss: 0.013553659431636333\n",
      "Epoch: 2/5, Loss: 0.038732703775167465\n",
      "Epoch: 2/5, Loss: 0.045161135494709015\n",
      "Epoch: 2/5, Loss: 0.00912434235215187\n",
      "Epoch: 2/5, Loss: 0.018552009016275406\n",
      "Epoch: 2/5, Loss: 0.0896727666258812\n",
      "Epoch: 2/5, Loss: 0.030402498319745064\n",
      "Epoch: 2/5, Loss: 0.008462781086564064\n",
      "Epoch: 2/5, Loss: 0.023449311032891273\n",
      "Epoch: 2/5, Loss: 0.022551311179995537\n",
      "Epoch: 2/5, Loss: 0.0374443344771862\n",
      "Epoch: 2/5, Loss: 0.005309796892106533\n",
      "Epoch: 2/5, Loss: 0.07368094474077225\n",
      "Epoch: 2/5, Loss: 0.036176081746816635\n",
      "Epoch: 2/5, Loss: 0.027566952630877495\n",
      "Epoch: 2/5, Loss: 0.037236884236335754\n",
      "Epoch: 2/5, Loss: 0.0031224461272358894\n",
      "Epoch: 2/5, Loss: 0.0065115829929709435\n",
      "Epoch: 2/5, Loss: 0.02702886424958706\n",
      "Epoch: 2/5, Loss: 0.06642714887857437\n",
      "Epoch: 2/5, Loss: 0.015532247722148895\n",
      "Epoch: 2/5, Loss: 0.003755246289074421\n",
      "Epoch: 2/5, Loss: 0.027416180819272995\n",
      "Epoch: 2/5, Loss: 0.022918928414583206\n",
      "Epoch: 2/5, Loss: 0.02404050901532173\n",
      "Epoch: 2/5, Loss: 0.014891690574586391\n",
      "Epoch: 2/5, Loss: 0.0399872362613678\n",
      "Epoch: 2/5, Loss: 0.06137382239103317\n",
      "Epoch: 2/5, Loss: 0.03339606523513794\n",
      "Epoch: 2/5, Loss: 0.040937259793281555\n",
      "Epoch: 2/5, Loss: 0.007837174460291862\n",
      "Epoch: 2/5, Loss: 0.016174500808119774\n",
      "Epoch: 2/5, Loss: 0.044988133013248444\n",
      "Epoch: 2/5, Loss: 0.02910424955189228\n",
      "Epoch: 2/5, Loss: 0.02773328498005867\n",
      "Epoch: 2/5, Loss: 0.015180645510554314\n",
      "Epoch: 2/5, Loss: 0.007487935945391655\n",
      "Epoch: 2/5, Loss: 0.012489775195717812\n",
      "Epoch: 2/5, Loss: 0.052674300968647\n",
      "Epoch: 2/5, Loss: 0.02028469182550907\n",
      "Epoch: 2/5, Loss: 0.04484201967716217\n",
      "Epoch: 2/5, Loss: 0.02759259194135666\n",
      "Epoch: 2/5, Loss: 0.01154913380742073\n",
      "Epoch: 2/5, Loss: 0.021839279681444168\n",
      "Epoch: 2/5, Loss: 0.01918705552816391\n",
      "Epoch: 2/5, Loss: 0.08616171777248383\n",
      "Epoch: 2/5, Loss: 0.03370872139930725\n",
      "Epoch: 2/5, Loss: 0.006824424955993891\n",
      "Epoch: 2/5, Loss: 0.03305511549115181\n",
      "Epoch: 2/5, Loss: 0.02404070273041725\n",
      "Epoch: 2/5, Loss: 0.019432522356510162\n",
      "Epoch: 2/5, Loss: 0.016933336853981018\n",
      "Epoch: 2/5, Loss: 0.03432090952992439\n",
      "Epoch: 2/5, Loss: 0.01977594941854477\n",
      "Epoch: 2/5, Loss: 0.046925902366638184\n",
      "Epoch: 2/5, Loss: 0.021805528551340103\n",
      "Epoch: 2/5, Loss: 0.022204313427209854\n",
      "Epoch: 2/5, Loss: 0.011230014264583588\n",
      "Epoch: 2/5, Loss: 0.07271900773048401\n",
      "Epoch: 2/5, Loss: 0.01750386320054531\n",
      "Epoch: 2/5, Loss: 0.016965359449386597\n",
      "Epoch: 2/5, Loss: 0.011887721717357635\n",
      "Epoch: 2/5, Loss: 0.012380911037325859\n",
      "Epoch: 2/5, Loss: 0.017840078100562096\n",
      "Epoch: 2/5, Loss: 0.06047074869275093\n",
      "Epoch: 2/5, Loss: 0.013638845644891262\n",
      "Epoch: 2/5, Loss: 0.011089173145592213\n",
      "Epoch: 2/5, Loss: 0.05858416482806206\n",
      "Epoch: 2/5, Loss: 0.036231547594070435\n",
      "Epoch: 2/5, Loss: 0.007208110298961401\n",
      "Epoch: 2/5, Loss: 0.015720153227448463\n",
      "Epoch: 2/5, Loss: 0.005251501686871052\n",
      "Epoch: 2/5, Loss: 0.02767040580511093\n",
      "Epoch: 2/5, Loss: 0.032379310578107834\n",
      "Epoch: 2/5, Loss: 0.00699021527543664\n",
      "Epoch: 2/5, Loss: 0.0034372496884316206\n",
      "Epoch: 2/5, Loss: 0.05291362851858139\n",
      "Epoch: 2/5, Loss: 0.023963650688529015\n",
      "Epoch: 2/5, Loss: 0.03317994996905327\n",
      "Epoch: 2/5, Loss: 0.04412519931793213\n",
      "Epoch: 2/5, Loss: 0.031094420701265335\n",
      "Epoch: 2/5, Loss: 0.056869953870773315\n",
      "Epoch: 2/5, Loss: 0.010920143686234951\n",
      "Epoch: 2/5, Loss: 0.015101786702871323\n",
      "Epoch: 2/5, Loss: 0.03387505188584328\n",
      "Epoch: 2/5, Loss: 0.004632649477571249\n",
      "Epoch: 2/5, Loss: 0.08183078467845917\n",
      "Epoch: 2/5, Loss: 0.009559919126331806\n",
      "Epoch: 2/5, Loss: 0.02300998941063881\n",
      "Epoch: 2/5, Loss: 0.02874741703271866\n",
      "Epoch: 2/5, Loss: 0.04880879074335098\n",
      "Epoch: 2/5, Loss: 0.030617695301771164\n",
      "Epoch: 2/5, Loss: 0.03712540119886398\n",
      "Epoch: 2/5, Loss: 0.0017602738225832582\n",
      "Epoch: 2/5, Loss: 0.01882993057370186\n",
      "Epoch: 2/5, Loss: 0.02108369581401348\n",
      "Epoch: 2/5, Loss: 0.06448739767074585\n",
      "Epoch: 2/5, Loss: 0.004140115343034267\n",
      "Epoch: 2/5, Loss: 0.024889349937438965\n",
      "Epoch: 2/5, Loss: 0.034062840044498444\n",
      "Epoch: 2/5, Loss: 0.05113546550273895\n",
      "Epoch: 2/5, Loss: 0.03322484716773033\n",
      "Epoch: 2/5, Loss: 0.07745669782161713\n",
      "Epoch: 2/5, Loss: 0.007981397211551666\n",
      "Epoch: 2/5, Loss: 0.012267002835869789\n",
      "Epoch: 2/5, Loss: 0.037304915487766266\n",
      "Epoch: 2/5, Loss: 0.0013551119482144713\n",
      "Epoch: 2/5, Loss: 0.023059949278831482\n",
      "Epoch: 2/5, Loss: 0.03408284857869148\n",
      "Epoch: 2/5, Loss: 0.01998315192759037\n",
      "Epoch: 2/5, Loss: 0.007882528007030487\n",
      "Epoch: 2/5, Loss: 0.03068004548549652\n",
      "Epoch: 2/5, Loss: 0.015184266492724419\n",
      "Epoch: 2/5, Loss: 0.05724377557635307\n",
      "Epoch: 2/5, Loss: 0.012846643105149269\n",
      "Epoch: 2/5, Loss: 0.03957575187087059\n",
      "Epoch: 2/5, Loss: 0.013023678213357925\n",
      "Epoch: 2/5, Loss: 0.13891014456748962\n",
      "Epoch: 2/5, Loss: 0.020142966881394386\n",
      "Epoch: 2/5, Loss: 0.047103945165872574\n",
      "Epoch: 2/5, Loss: 0.02844710275530815\n",
      "Epoch: 2/5, Loss: 0.03171408176422119\n",
      "Epoch: 2/5, Loss: 0.015435893088579178\n",
      "Epoch: 2/5, Loss: 0.03293091431260109\n",
      "Epoch: 2/5, Loss: 0.08878355473279953\n",
      "Epoch: 2/5, Loss: 0.011794744990766048\n",
      "Epoch: 2/5, Loss: 0.004085839260369539\n",
      "Epoch: 2/5, Loss: 0.002655911259353161\n",
      "Epoch: 2/5, Loss: 0.01654365099966526\n",
      "Epoch: 2/5, Loss: 0.0466250516474247\n",
      "Epoch: 2/5, Loss: 0.016453303396701813\n",
      "Epoch: 2/5, Loss: 0.006126855034381151\n",
      "Epoch: 2/5, Loss: 0.0027893183287233114\n",
      "Epoch: 2/5, Loss: 0.005818013101816177\n",
      "Epoch: 2/5, Loss: 0.036451391875743866\n",
      "Epoch: 2/5, Loss: 0.009334948845207691\n",
      "Epoch: 2/5, Loss: 0.0765257254242897\n",
      "Epoch: 2/5, Loss: 0.021832555532455444\n",
      "Epoch: 2/5, Loss: 0.08662339299917221\n",
      "Epoch: 2/5, Loss: 0.06439106166362762\n",
      "Epoch: 2/5, Loss: 0.043811291456222534\n",
      "Epoch: 2/5, Loss: 0.04184974730014801\n",
      "Epoch: 2/5, Loss: 0.01473989151418209\n",
      "Epoch: 2/5, Loss: 0.001239784643985331\n",
      "Epoch: 2/5, Loss: 0.021512236446142197\n",
      "Epoch: 2/5, Loss: 0.06291558593511581\n",
      "Epoch: 2/5, Loss: 0.022906124591827393\n",
      "Epoch: 2/5, Loss: 0.010783948935568333\n",
      "Epoch: 2/5, Loss: 0.04150034114718437\n",
      "Epoch: 2/5, Loss: 0.02478494495153427\n",
      "Epoch: 2/5, Loss: 0.021143198013305664\n",
      "Epoch: 2/5, Loss: 0.033504240214824677\n",
      "Epoch: 2/5, Loss: 0.08922437578439713\n",
      "Epoch: 2/5, Loss: 0.009284199215471745\n",
      "Epoch: 2/5, Loss: 0.061818353831768036\n",
      "Epoch: 2/5, Loss: 0.003106062300503254\n",
      "Epoch: 2/5, Loss: 0.011040209792554379\n",
      "Epoch: 2/5, Loss: 0.016972843557596207\n",
      "Epoch: 2/5, Loss: 0.008065074682235718\n",
      "Epoch: 2/5, Loss: 0.05682462453842163\n",
      "Epoch: 2/5, Loss: 0.04863899201154709\n",
      "Epoch: 2/5, Loss: 0.05153699964284897\n",
      "Epoch: 2/5, Loss: 0.00795724056661129\n",
      "Epoch: 2/5, Loss: 0.03682230785489082\n",
      "Epoch: 2/5, Loss: 0.037322431802749634\n",
      "Epoch: 2/5, Loss: 0.009819597005844116\n",
      "Epoch: 2/5, Loss: 0.014920453540980816\n",
      "Epoch: 2/5, Loss: 0.02677672542631626\n",
      "Epoch: 2/5, Loss: 0.029841767624020576\n",
      "Epoch: 2/5, Loss: 0.034757670015096664\n",
      "Epoch: 2/5, Loss: 0.016378210857510567\n",
      "Epoch: 2/5, Loss: 0.08872254937887192\n",
      "Epoch: 2/5, Loss: 0.030354037880897522\n",
      "Epoch: 2/5, Loss: 0.0070310900919139385\n",
      "Epoch: 2/5, Loss: 0.028894636780023575\n",
      "Epoch: 2/5, Loss: 0.023531541228294373\n",
      "Epoch: 2/5, Loss: 0.019644564017653465\n",
      "Epoch: 2/5, Loss: 0.0020846070256084204\n",
      "Epoch: 2/5, Loss: 0.02022957056760788\n",
      "Epoch: 2/5, Loss: 0.06602180749177933\n",
      "Epoch: 2/5, Loss: 0.012234359048306942\n",
      "Epoch: 2/5, Loss: 0.012913895770907402\n",
      "Epoch: 2/5, Loss: 0.04806814715266228\n",
      "Epoch: 2/5, Loss: 0.06056855618953705\n",
      "Epoch: 2/5, Loss: 0.022449959069490433\n",
      "Epoch: 2/5, Loss: 0.026267919689416885\n",
      "Epoch: 2/5, Loss: 0.023502573370933533\n",
      "Epoch: 2/5, Loss: 0.003149375319480896\n",
      "Epoch: 2/5, Loss: 0.00901586003601551\n",
      "Epoch: 2/5, Loss: 0.014320684596896172\n",
      "Epoch: 2/5, Loss: 0.022064650431275368\n",
      "Epoch: 2/5, Loss: 0.01898237317800522\n",
      "Epoch: 2/5, Loss: 0.013329144567251205\n",
      "Epoch: 2/5, Loss: 0.01148002315312624\n",
      "Epoch: 2/5, Loss: 0.054733723402023315\n",
      "Epoch: 2/5, Loss: 0.04476594179868698\n",
      "Epoch: 2/5, Loss: 0.011490248143672943\n",
      "Epoch: 2/5, Loss: 0.006070698145776987\n",
      "Epoch: 2/5, Loss: 0.011050311848521233\n",
      "Epoch: 2/5, Loss: 0.0063320910558104515\n",
      "Epoch: 2/5, Loss: 0.008456090465188026\n",
      "Epoch: 2/5, Loss: 0.017184928059577942\n",
      "Epoch: 2/5, Loss: 0.013103755190968513\n",
      "Epoch: 2/5, Loss: 0.015338260680437088\n",
      "Epoch: 2/5, Loss: 0.0014634279068559408\n",
      "Epoch: 2/5, Loss: 0.023331481963396072\n",
      "Epoch: 2/5, Loss: 0.027331547811627388\n",
      "Epoch: 2/5, Loss: 0.013300660997629166\n",
      "Epoch: 2/5, Loss: 0.016961541026830673\n",
      "Epoch: 2/5, Loss: 0.025475487112998962\n",
      "Epoch: 2/5, Loss: 0.05272044241428375\n",
      "Epoch: 2/5, Loss: 0.024241730570793152\n",
      "Epoch: 2/5, Loss: 0.038576506078243256\n",
      "Epoch: 2/5, Loss: 0.034041307866573334\n",
      "Epoch: 2/5, Loss: 0.00701988535001874\n",
      "Epoch: 2/5, Loss: 0.03441115468740463\n",
      "Epoch: 2/5, Loss: 0.010116337798535824\n",
      "Epoch: 2/5, Loss: 0.02470703423023224\n",
      "Epoch: 2/5, Loss: 0.17449745535850525\n",
      "Epoch: 2/5, Loss: 0.05093420296907425\n",
      "Epoch: 2/5, Loss: 0.04785090684890747\n",
      "Epoch: 2/5, Loss: 0.003255902323871851\n",
      "Epoch: 2/5, Loss: 0.00541231594979763\n",
      "Epoch: 2/5, Loss: 0.01761801168322563\n",
      "Epoch: 2/5, Loss: 0.03159995377063751\n",
      "Epoch: 2/5, Loss: 0.005594820249825716\n",
      "Epoch: 2/5, Loss: 0.024212416261434555\n",
      "Epoch: 2/5, Loss: 0.013768965378403664\n",
      "Epoch: 2/5, Loss: 0.0030821128748357296\n",
      "Epoch: 2/5, Loss: 0.055169325321912766\n",
      "Epoch: 2/5, Loss: 0.023516874760389328\n",
      "Epoch: 2/5, Loss: 0.046469010412693024\n",
      "Epoch: 2/5, Loss: 0.02095158025622368\n",
      "Epoch: 2/5, Loss: 0.03975813090801239\n",
      "Epoch: 2/5, Loss: 0.006844795774668455\n",
      "Epoch: 2/5, Loss: 0.021530909463763237\n",
      "Epoch: 2/5, Loss: 0.004908572416752577\n",
      "Epoch: 2/5, Loss: 0.028224028646945953\n",
      "Epoch: 2/5, Loss: 0.02497796155512333\n",
      "Epoch: 2/5, Loss: 0.045640572905540466\n",
      "Epoch: 2/5, Loss: 0.02009059116244316\n",
      "Epoch: 2/5, Loss: 0.0931745246052742\n",
      "Epoch: 2/5, Loss: 0.002376643707975745\n",
      "Epoch: 2/5, Loss: 0.010985285975039005\n",
      "Epoch: 2/5, Loss: 0.03498818725347519\n",
      "Epoch: 2/5, Loss: 0.004397252108901739\n",
      "Epoch: 2/5, Loss: 0.012527929618954659\n",
      "Epoch: 2/5, Loss: 0.011209054850041866\n",
      "Epoch: 2/5, Loss: 0.009849747642874718\n",
      "Epoch: 2/5, Loss: 0.0256122387945652\n",
      "Epoch: 2/5, Loss: 0.024411197751760483\n",
      "Epoch: 2/5, Loss: 0.004364560358226299\n",
      "Epoch: 2/5, Loss: 0.005952131934463978\n",
      "Epoch: 2/5, Loss: 0.007176963146775961\n",
      "Epoch: 2/5, Loss: 0.0151071073487401\n",
      "Epoch: 2/5, Loss: 0.047895804047584534\n",
      "Epoch: 2/5, Loss: 0.009381354786455631\n",
      "Epoch: 2/5, Loss: 0.01958104968070984\n",
      "Epoch: 2/5, Loss: 0.0030931327491998672\n",
      "Epoch: 2/5, Loss: 0.012605942785739899\n",
      "Epoch: 2/5, Loss: 0.01788504794239998\n",
      "Epoch: 2/5, Loss: 0.0071074771694839\n",
      "Epoch: 2/5, Loss: 0.05378691479563713\n",
      "Epoch: 2/5, Loss: 0.023190250620245934\n",
      "Epoch: 2/5, Loss: 0.03225073590874672\n",
      "Epoch: 2/5, Loss: 0.030291352421045303\n",
      "Epoch: 2/5, Loss: 0.0061982860788702965\n",
      "Epoch: 2/5, Loss: 0.019050374627113342\n",
      "Epoch: 2/5, Loss: 0.019934672862291336\n",
      "Epoch: 2/5, Loss: 0.030936364084482193\n",
      "Epoch: 2/5, Loss: 0.035535965114831924\n",
      "Epoch: 2/5, Loss: 0.025529183447360992\n",
      "Epoch: 2/5, Loss: 0.01840876042842865\n",
      "Epoch: 2/5, Loss: 0.00809819158166647\n",
      "Epoch: 2/5, Loss: 0.05329706892371178\n",
      "Epoch: 2/5, Loss: 0.02671511285007\n",
      "Epoch: 2/5, Loss: 0.04497307166457176\n",
      "Epoch: 2/5, Loss: 0.0395292267203331\n",
      "Epoch: 2/5, Loss: 0.007883583195507526\n",
      "Epoch: 2/5, Loss: 0.017796866595745087\n",
      "Epoch: 2/5, Loss: 0.020882872864603996\n",
      "Epoch: 2/5, Loss: 0.03629295527935028\n",
      "Epoch: 2/5, Loss: 0.0011029596207663417\n",
      "Epoch: 2/5, Loss: 0.007276705000549555\n",
      "Epoch: 2/5, Loss: 0.028802577406167984\n",
      "Epoch: 2/5, Loss: 0.027227234095335007\n",
      "Epoch: 2/5, Loss: 0.009891966357827187\n",
      "Epoch: 2/5, Loss: 0.03064405918121338\n",
      "Epoch: 2/5, Loss: 0.02112089842557907\n",
      "Epoch: 2/5, Loss: 0.03283541277050972\n",
      "Epoch: 2/5, Loss: 0.03827030584216118\n",
      "Epoch: 2/5, Loss: 0.009988242760300636\n",
      "Epoch: 2/5, Loss: 0.10070493072271347\n",
      "Epoch: 2/5, Loss: 0.06649567186832428\n",
      "Epoch: 2/5, Loss: 0.02926885336637497\n",
      "Epoch: 2/5, Loss: 0.054588183760643005\n",
      "Epoch: 2/5, Loss: 0.036648545414209366\n",
      "Epoch: 2/5, Loss: 0.03690814599394798\n",
      "Epoch: 2/5, Loss: 0.06118563935160637\n",
      "Epoch: 2/5, Loss: 0.026986155658960342\n",
      "Epoch: 2/5, Loss: 0.017631715163588524\n",
      "Epoch: 2/5, Loss: 0.016756562516093254\n",
      "Epoch: 2/5, Loss: 0.028498955070972443\n",
      "Epoch: 2/5, Loss: 0.0021876301616430283\n",
      "Epoch: 2/5, Loss: 0.03163725510239601\n",
      "Epoch: 2/5, Loss: 0.055147264152765274\n",
      "Epoch: 2/5, Loss: 0.058600153774023056\n",
      "Epoch: 2/5, Loss: 0.01999102160334587\n",
      "Epoch: 2/5, Loss: 0.012727562338113785\n",
      "Epoch: 2/5, Loss: 0.007034842390567064\n",
      "Epoch: 2/5, Loss: 0.002032419666647911\n",
      "Epoch: 2/5, Loss: 0.04371614381670952\n",
      "Epoch: 2/5, Loss: 0.05424784496426582\n",
      "Epoch: 2/5, Loss: 0.045676734298467636\n",
      "Epoch: 2/5, Loss: 0.0492883026599884\n",
      "Epoch: 2/5, Loss: 0.05945338308811188\n",
      "Epoch: 2/5, Loss: 0.0015510254306718707\n",
      "Epoch: 2/5, Loss: 0.010262833908200264\n",
      "Epoch: 2/5, Loss: 0.007371279411017895\n",
      "Epoch: 2/5, Loss: 0.019863544031977654\n",
      "Epoch: 2/5, Loss: 0.06652626395225525\n",
      "Epoch: 2/5, Loss: 0.02334907092154026\n",
      "Epoch: 2/5, Loss: 0.07005777209997177\n",
      "Epoch: 2/5, Loss: 0.034869059920310974\n",
      "Epoch: 2/5, Loss: 0.030661791563034058\n",
      "Epoch: 2/5, Loss: 0.018882500007748604\n",
      "Epoch: 2/5, Loss: 0.016991520300507545\n",
      "Epoch: 2/5, Loss: 0.037668824195861816\n",
      "Epoch: 2/5, Loss: 0.040687721222639084\n",
      "Epoch: 2/5, Loss: 0.040842730551958084\n",
      "Epoch: 2/5, Loss: 0.0065350341610610485\n",
      "Epoch: 2/5, Loss: 0.016959834843873978\n",
      "Epoch: 2/5, Loss: 0.0266585573554039\n",
      "Epoch: 2/5, Loss: 0.01481121126562357\n",
      "Epoch: 2/5, Loss: 0.02929399162530899\n",
      "Epoch: 2/5, Loss: 0.006690249778330326\n",
      "Epoch: 2/5, Loss: 0.004429493099451065\n",
      "Epoch: 2/5, Loss: 0.0015237032203003764\n",
      "Epoch: 2/5, Loss: 0.03217778354883194\n",
      "Epoch: 2/5, Loss: 0.02992703951895237\n",
      "Epoch: 2/5, Loss: 0.02575821802020073\n",
      "Epoch: 2/5, Loss: 0.01429965253919363\n",
      "Epoch: 2/5, Loss: 0.05311025679111481\n",
      "Epoch: 2/5, Loss: 0.0008441900135949254\n",
      "Epoch: 2/5, Loss: 0.018146265298128128\n",
      "Epoch: 2/5, Loss: 0.05786918103694916\n",
      "Epoch: 2/5, Loss: 0.029731061309576035\n",
      "Epoch: 2/5, Loss: 0.004493404179811478\n",
      "Epoch: 2/5, Loss: 0.03934630751609802\n",
      "Epoch: 2/5, Loss: 0.12127827107906342\n",
      "Epoch: 2/5, Loss: 0.021726172417402267\n",
      "Epoch: 2/5, Loss: 0.05150572210550308\n",
      "Epoch: 2/5, Loss: 0.022771913558244705\n",
      "Epoch: 2/5, Loss: 0.05502461642026901\n",
      "Epoch: 2/5, Loss: 0.033080849796533585\n",
      "Epoch: 2/5, Loss: 0.009177105501294136\n",
      "Epoch: 2/5, Loss: 0.039018478244543076\n",
      "Epoch: 2/5, Loss: 0.04340985044836998\n",
      "Epoch: 2/5, Loss: 0.08054202795028687\n",
      "Epoch: 2/5, Loss: 0.019521383568644524\n",
      "Epoch: 2/5, Loss: 0.0011859738733619452\n",
      "Epoch: 2/5, Loss: 0.005217564292252064\n",
      "Epoch: 2/5, Loss: 0.08739595860242844\n",
      "Epoch: 2/5, Loss: 0.034159060567617416\n",
      "Epoch: 2/5, Loss: 0.01368004735559225\n",
      "Epoch: 2/5, Loss: 0.009523537941277027\n",
      "Epoch: 2/5, Loss: 0.008736860007047653\n",
      "Epoch: 2/5, Loss: 0.007866625674068928\n",
      "Epoch: 2/5, Loss: 0.01924356445670128\n",
      "Epoch: 2/5, Loss: 0.014013607054948807\n",
      "Epoch: 2/5, Loss: 0.020520133897662163\n",
      "Epoch: 2/5, Loss: 0.05882975459098816\n",
      "Epoch: 2/5, Loss: 0.054265283048152924\n",
      "Epoch: 2/5, Loss: 0.015953533351421356\n",
      "Epoch: 2/5, Loss: 0.022302987053990364\n",
      "Epoch: 2/5, Loss: 0.03024039790034294\n",
      "Epoch: 2/5, Loss: 0.006566103547811508\n",
      "Epoch: 2/5, Loss: 0.02080247551202774\n",
      "Epoch: 2/5, Loss: 0.03480931371450424\n",
      "Epoch: 2/5, Loss: 0.022546928375959396\n",
      "Epoch: 2/5, Loss: 0.023007795214653015\n",
      "Epoch: 2/5, Loss: 0.01506527978926897\n",
      "Epoch: 2/5, Loss: 0.04428789019584656\n",
      "Epoch: 2/5, Loss: 0.005582680460065603\n",
      "Epoch: 2/5, Loss: 0.07862469553947449\n",
      "Epoch: 2/5, Loss: 0.014425121247768402\n",
      "Epoch: 2/5, Loss: 0.030026812106370926\n",
      "Epoch: 2/5, Loss: 0.023736508563160896\n",
      "Epoch: 2/5, Loss: 0.03662703186273575\n",
      "Epoch: 2/5, Loss: 0.030903134495019913\n",
      "Epoch: 2/5, Loss: 0.030704259872436523\n",
      "Epoch: 2/5, Loss: 0.005273343063890934\n",
      "Epoch: 2/5, Loss: 0.04592519253492355\n",
      "Epoch: 2/5, Loss: 0.016898546367883682\n",
      "Epoch: 2/5, Loss: 0.02296569012105465\n",
      "Epoch: 2/5, Loss: 0.021623020991683006\n",
      "Epoch: 2/5, Loss: 0.04917820915579796\n",
      "Epoch: 2/5, Loss: 0.030862104147672653\n",
      "Epoch: 2/5, Loss: 0.011030871421098709\n",
      "Epoch: 2/5, Loss: 0.02408137544989586\n",
      "Epoch: 2/5, Loss: 0.021137095987796783\n",
      "Epoch: 2/5, Loss: 0.039729464799165726\n",
      "Epoch: 2/5, Loss: 0.061563413590192795\n",
      "Epoch: 2/5, Loss: 0.030946556478738785\n",
      "Epoch: 2/5, Loss: 0.05954036861658096\n",
      "Epoch: 2/5, Loss: 0.016673196107149124\n",
      "Epoch: 2/5, Loss: 0.02649572119116783\n",
      "Epoch: 2/5, Loss: 0.011920460499823093\n",
      "Epoch: 2/5, Loss: 0.018434036523103714\n",
      "Epoch: 2/5, Loss: 0.013682583346962929\n",
      "Epoch: 2/5, Loss: 0.030932852998375893\n",
      "Epoch: 2/5, Loss: 0.006231372244656086\n",
      "Epoch: 2/5, Loss: 0.03836791589856148\n",
      "Epoch: 2/5, Loss: 0.04592585563659668\n",
      "Epoch: 2/5, Loss: 0.03161964938044548\n",
      "Epoch: 2/5, Loss: 0.015555480495095253\n",
      "Epoch: 2/5, Loss: 0.015834497287869453\n",
      "Epoch: 2/5, Loss: 0.02547704614698887\n",
      "Epoch: 2/5, Loss: 0.020413540303707123\n",
      "Epoch: 2/5, Loss: 0.030531123280525208\n",
      "Epoch: 2/5, Loss: 0.034284573048353195\n",
      "Epoch: 2/5, Loss: 0.01523862686008215\n",
      "Epoch: 2/5, Loss: 0.023729946464300156\n",
      "Epoch: 2/5, Loss: 0.03996365889906883\n",
      "Epoch: 2/5, Loss: 0.009573808871209621\n",
      "Epoch: 2/5, Loss: 0.016863785684108734\n",
      "Epoch: 2/5, Loss: 0.00658026710152626\n",
      "Epoch: 2/5, Loss: 0.010527140460908413\n",
      "Epoch: 2/5, Loss: 0.0374755784869194\n",
      "Epoch: 2/5, Loss: 0.011220325715839863\n",
      "Epoch: 2/5, Loss: 0.03760325908660889\n",
      "Epoch: 2/5, Loss: 0.014952324330806732\n",
      "Epoch: 2/5, Loss: 0.22342048585414886\n",
      "Epoch: 2/5, Loss: 0.06370414793491364\n",
      "Epoch: 2/5, Loss: 0.04064353555440903\n",
      "Epoch: 2/5, Loss: 0.018948476761579514\n",
      "Epoch: 2/5, Loss: 0.020398037508130074\n",
      "Epoch: 2/5, Loss: 0.06510521471500397\n",
      "Epoch: 2/5, Loss: 0.022024638950824738\n",
      "Epoch: 2/5, Loss: 0.015451228246092796\n",
      "Epoch: 2/5, Loss: 0.023853402584791183\n",
      "Epoch: 2/5, Loss: 0.06127186119556427\n",
      "Epoch: 2/5, Loss: 0.03024962730705738\n",
      "Epoch: 2/5, Loss: 0.024877479299902916\n",
      "Epoch: 2/5, Loss: 0.029553299769759178\n",
      "Epoch: 2/5, Loss: 0.018600033596158028\n",
      "Epoch: 2/5, Loss: 0.029487185180187225\n",
      "Epoch: 2/5, Loss: 0.012564842589199543\n",
      "Epoch: 2/5, Loss: 0.02057504840195179\n",
      "Epoch: 2/5, Loss: 0.003274272894486785\n",
      "Epoch: 2/5, Loss: 0.01980622485280037\n",
      "Epoch: 2/5, Loss: 0.024559544399380684\n",
      "Epoch: 2/5, Loss: 0.04890307039022446\n",
      "Epoch: 2/5, Loss: 0.04021994769573212\n",
      "Epoch: 2/5, Loss: 0.05221018195152283\n",
      "Epoch: 2/5, Loss: 0.023226551711559296\n",
      "Epoch: 2/5, Loss: 0.04068579524755478\n",
      "Epoch: 2/5, Loss: 0.006881410256028175\n",
      "Epoch: 2/5, Loss: 0.02062900923192501\n",
      "Epoch: 2/5, Loss: 0.002062785206362605\n",
      "Epoch: 2/5, Loss: 0.03247026726603508\n",
      "Epoch: 2/5, Loss: 0.009428087621927261\n",
      "Epoch: 2/5, Loss: 0.014602789655327797\n",
      "Epoch: 2/5, Loss: 0.05143529549241066\n",
      "Epoch: 2/5, Loss: 0.022099515423178673\n",
      "Epoch: 2/5, Loss: 0.04316502436995506\n",
      "Epoch: 2/5, Loss: 0.03363846614956856\n",
      "Epoch: 2/5, Loss: 0.0265444777905941\n",
      "Epoch: 2/5, Loss: 0.03194674476981163\n",
      "Epoch: 2/5, Loss: 0.027518775314092636\n",
      "Epoch: 2/5, Loss: 0.005019183270633221\n",
      "Epoch: 2/5, Loss: 0.0439523383975029\n",
      "Epoch: 2/5, Loss: 0.13424427807331085\n",
      "Epoch: 2/5, Loss: 0.04346733167767525\n",
      "Epoch: 2/5, Loss: 0.0806766152381897\n",
      "Epoch: 2/5, Loss: 0.060042742639780045\n",
      "Epoch: 2/5, Loss: 0.04448079317808151\n",
      "Epoch: 2/5, Loss: 0.02496335469186306\n",
      "Epoch: 2/5, Loss: 0.017522092908620834\n",
      "Epoch: 2/5, Loss: 0.018926136195659637\n",
      "Epoch: 2/5, Loss: 0.033747073262929916\n",
      "Epoch: 2/5, Loss: 0.017189260572195053\n",
      "Epoch: 2/5, Loss: 0.02349335327744484\n",
      "Epoch: 2/5, Loss: 0.11363974958658218\n",
      "Epoch: 2/5, Loss: 0.019370751455426216\n",
      "Epoch: 2/5, Loss: 0.018037021160125732\n",
      "Epoch: 2/5, Loss: 0.010709531605243683\n",
      "Epoch: 2/5, Loss: 0.018382111564278603\n",
      "Epoch: 2/5, Loss: 0.025965020060539246\n",
      "Epoch: 2/5, Loss: 0.010987005196511745\n",
      "Epoch: 2/5, Loss: 0.02980670891702175\n",
      "Epoch: 2/5, Loss: 0.024545986205339432\n",
      "Epoch: 2/5, Loss: 0.006722977850586176\n",
      "Epoch: 2/5, Loss: 0.01564839296042919\n",
      "Epoch: 2/5, Loss: 0.028125690296292305\n",
      "Epoch: 2/5, Loss: 0.05040112882852554\n",
      "Epoch: 2/5, Loss: 0.02652570977807045\n",
      "Epoch: 2/5, Loss: 0.06981931626796722\n",
      "Epoch: 2/5, Loss: 0.0340551882982254\n",
      "Epoch: 2/5, Loss: 0.01862950250506401\n",
      "Epoch: 2/5, Loss: 0.006133624352514744\n",
      "Epoch: 2/5, Loss: 0.010166289284825325\n",
      "Epoch: 2/5, Loss: 0.02399669587612152\n",
      "Epoch: 2/5, Loss: 0.02377699688076973\n",
      "Epoch: 2/5, Loss: 0.023186130449175835\n",
      "Epoch: 2/5, Loss: 0.028050988912582397\n",
      "Epoch: 2/5, Loss: 0.022476159036159515\n",
      "Epoch: 2/5, Loss: 0.029235580936074257\n",
      "Epoch: 2/5, Loss: 0.005955479573458433\n",
      "Epoch: 2/5, Loss: 0.009019874967634678\n",
      "Epoch: 2/5, Loss: 0.03971527889370918\n",
      "Epoch: 2/5, Loss: 0.011128737591207027\n",
      "Epoch: 2/5, Loss: 0.009212597273290157\n",
      "Epoch: 2/5, Loss: 0.06735888868570328\n",
      "Epoch: 2/5, Loss: 0.02267610840499401\n",
      "Epoch: 2/5, Loss: 0.0038025749381631613\n",
      "Epoch: 2/5, Loss: 0.04343068599700928\n",
      "Epoch: 2/5, Loss: 0.03842424601316452\n",
      "Epoch: 2/5, Loss: 0.01486875768750906\n",
      "Epoch: 2/5, Loss: 0.026996897533535957\n",
      "Epoch: 2/5, Loss: 0.027211342006921768\n",
      "Epoch: 2/5, Loss: 0.017756681889295578\n",
      "Epoch: 2/5, Loss: 0.022616850212216377\n",
      "Epoch: 2/5, Loss: 0.02782423608005047\n",
      "Epoch: 2/5, Loss: 0.005993623286485672\n",
      "Epoch: 2/5, Loss: 0.01081888098269701\n",
      "Epoch: 2/5, Loss: 0.02548879384994507\n",
      "Epoch: 2/5, Loss: 0.036988936364650726\n",
      "Epoch: 2/5, Loss: 0.014815343543887138\n",
      "Epoch: 2/5, Loss: 0.02886863611638546\n",
      "Epoch: 2/5, Loss: 0.013289906084537506\n",
      "Epoch: 2/5, Loss: 0.026269469410181046\n",
      "Epoch: 2/5, Loss: 0.041376203298568726\n",
      "Epoch: 2/5, Loss: 0.05213334038853645\n",
      "Epoch: 2/5, Loss: 0.03191058710217476\n",
      "Epoch: 2/5, Loss: 0.027907168492674828\n",
      "Epoch: 2/5, Loss: 0.013675814494490623\n",
      "Epoch: 2/5, Loss: 0.016831036657094955\n",
      "Epoch: 2/5, Loss: 0.012253856286406517\n",
      "Epoch: 2/5, Loss: 0.034032028168439865\n",
      "Epoch: 2/5, Loss: 0.017366094514727592\n",
      "Epoch: 2/5, Loss: 0.0286719873547554\n",
      "Epoch: 2/5, Loss: 0.049990370869636536\n",
      "Epoch: 2/5, Loss: 0.01205271016806364\n",
      "Epoch: 2/5, Loss: 0.06563983112573624\n",
      "Epoch: 2/5, Loss: 0.0024215069133788347\n",
      "Epoch: 2/5, Loss: 0.028555572032928467\n",
      "Epoch: 2/5, Loss: 0.004947818350046873\n",
      "Epoch: 2/5, Loss: 0.03372140973806381\n",
      "Epoch: 2/5, Loss: 0.01737877167761326\n",
      "Epoch: 2/5, Loss: 0.024453969672322273\n",
      "Epoch: 2/5, Loss: 0.008761228062212467\n",
      "Epoch: 2/5, Loss: 0.05749049037694931\n",
      "Epoch: 2/5, Loss: 0.019267020747065544\n",
      "Epoch: 2/5, Loss: 0.003100058762356639\n",
      "Epoch: 2/5, Loss: 0.020136196166276932\n",
      "Epoch: 2/5, Loss: 0.010914118029177189\n",
      "Epoch: 2/5, Loss: 0.032206594944000244\n",
      "Epoch: 2/5, Loss: 0.04735458269715309\n",
      "Epoch: 2/5, Loss: 0.11355775594711304\n",
      "Epoch: 2/5, Loss: 0.011836498975753784\n",
      "Epoch: 2/5, Loss: 0.018844662234187126\n",
      "Epoch: 2/5, Loss: 0.017566833645105362\n",
      "Epoch: 2/5, Loss: 0.004085092339664698\n",
      "Epoch: 2/5, Loss: 0.029013141989707947\n",
      "Epoch: 2/5, Loss: 0.014802288264036179\n",
      "Epoch: 2/5, Loss: 0.018389394506812096\n",
      "Epoch: 2/5, Loss: 0.01300793793052435\n",
      "Epoch: 2/5, Loss: 0.04397014155983925\n",
      "Epoch: 2/5, Loss: 0.031869400292634964\n",
      "Epoch: 2/5, Loss: 0.02928728424012661\n",
      "Epoch: 2/5, Loss: 0.02192896604537964\n",
      "Epoch: 2/5, Loss: 0.004733172710984945\n",
      "Epoch: 2/5, Loss: 0.03447669744491577\n",
      "Epoch: 2/5, Loss: 0.017063738778233528\n",
      "Epoch: 2/5, Loss: 0.020392820239067078\n",
      "Epoch: 2/5, Loss: 0.028766712173819542\n",
      "Epoch: 2/5, Loss: 0.022709909826517105\n",
      "Epoch: 2/5, Loss: 0.018978077918291092\n",
      "Epoch: 2/5, Loss: 0.026010364294052124\n",
      "Epoch: 2/5, Loss: 0.017589354887604713\n",
      "Epoch: 2/5, Loss: 0.050002068281173706\n",
      "Epoch: 2/5, Loss: 0.04169091582298279\n",
      "Epoch: 2/5, Loss: 0.003709549317136407\n",
      "Epoch: 2/5, Loss: 0.012680266052484512\n",
      "Epoch: 2/5, Loss: 0.012166198343038559\n",
      "Epoch: 2/5, Loss: 0.004141508135944605\n",
      "Epoch: 2/5, Loss: 0.019157592207193375\n",
      "Epoch: 2/5, Loss: 0.09863962978124619\n",
      "Epoch: 2/5, Loss: 0.011377711780369282\n",
      "Epoch: 2/5, Loss: 0.01538266520947218\n",
      "Epoch: 2/5, Loss: 0.017405396327376366\n",
      "Epoch: 2/5, Loss: 0.02048095501959324\n",
      "Epoch: 2/5, Loss: 0.02287302166223526\n",
      "Epoch: 2/5, Loss: 0.016429439187049866\n",
      "Epoch: 2/5, Loss: 0.038769397884607315\n",
      "Epoch: 2/5, Loss: 0.0261076632887125\n",
      "Epoch: 2/5, Loss: 0.019784599542617798\n",
      "Epoch: 2/5, Loss: 0.028595833107829094\n",
      "Epoch: 2/5, Loss: 0.018355630338191986\n",
      "Epoch: 2/5, Loss: 0.012550202198326588\n",
      "Epoch: 2/5, Loss: 0.04293694347143173\n",
      "Epoch: 2/5, Loss: 0.030629295855760574\n",
      "Epoch: 2/5, Loss: 0.024527333676815033\n",
      "Epoch: 2/5, Loss: 0.025108885020017624\n",
      "Epoch: 2/5, Loss: 0.0072532049380242825\n",
      "Epoch: 2/5, Loss: 0.02976967953145504\n",
      "Epoch: 2/5, Loss: 0.015389903448522091\n",
      "Epoch: 2/5, Loss: 0.017041480168700218\n",
      "Epoch: 2/5, Loss: 0.035698097199201584\n",
      "Epoch: 2/5, Loss: 0.0020041177049279213\n",
      "Epoch: 2/5, Loss: 0.010794335044920444\n",
      "Epoch: 2/5, Loss: 0.008066916838288307\n",
      "Epoch: 2/5, Loss: 0.004689136054366827\n",
      "Epoch: 2/5, Loss: 0.013696221634745598\n",
      "Epoch: 2/5, Loss: 0.013139540329575539\n",
      "Epoch: 2/5, Loss: 0.015465421602129936\n",
      "Epoch: 2/5, Loss: 0.008609185926616192\n",
      "Epoch: 2/5, Loss: 0.034250762313604355\n",
      "Epoch: 2/5, Loss: 0.017922135069966316\n",
      "Epoch: 2/5, Loss: 0.0038118103984743357\n",
      "Epoch: 2/5, Loss: 0.028465809300541878\n",
      "Epoch: 2/5, Loss: 0.026419498026371002\n",
      "Epoch: 2/5, Loss: 0.054189205169677734\n",
      "Epoch: 2/5, Loss: 0.044527798891067505\n",
      "Epoch: 2/5, Loss: 0.025725461542606354\n",
      "Epoch: 2/5, Loss: 0.06947290152311325\n",
      "Epoch: 2/5, Loss: 0.0376809686422348\n",
      "Epoch: 2/5, Loss: 0.0032616532407701015\n",
      "Epoch: 2/5, Loss: 0.056701526045799255\n",
      "Epoch: 2/5, Loss: 0.03103429079055786\n",
      "Epoch: 2/5, Loss: 0.016391130164265633\n",
      "Epoch: 2/5, Loss: 0.01755468361079693\n",
      "Epoch: 2/5, Loss: 0.005620719399303198\n",
      "Epoch: 2/5, Loss: 0.02634122408926487\n",
      "Epoch: 2/5, Loss: 0.013636291027069092\n",
      "Epoch: 2/5, Loss: 0.010950427502393723\n",
      "Epoch: 2/5, Loss: 0.010666128247976303\n",
      "Epoch: 2/5, Loss: 0.005039142444729805\n",
      "Epoch: 2/5, Loss: 0.09568333625793457\n",
      "Epoch: 2/5, Loss: 0.039425261318683624\n",
      "Epoch: 2/5, Loss: 0.023751046508550644\n",
      "Epoch: 2/5, Loss: 0.005515847355127335\n",
      "Epoch: 2/5, Loss: 0.032145414501428604\n",
      "Epoch: 2/5, Loss: 0.009556267410516739\n",
      "Epoch: 2/5, Loss: 0.013580220751464367\n",
      "Epoch: 2/5, Loss: 0.006033209152519703\n",
      "Epoch: 2/5, Loss: 0.008821433410048485\n",
      "Epoch: 2/5, Loss: 0.020185625180602074\n",
      "Epoch: 2/5, Loss: 0.04245045781135559\n",
      "Epoch: 2/5, Loss: 0.005286697298288345\n",
      "Epoch: 2/5, Loss: 0.004456673748791218\n",
      "Epoch: 2/5, Loss: 0.011701528914272785\n",
      "Epoch: 2/5, Loss: 0.0026480117812752724\n",
      "Epoch: 2/5, Loss: 0.01419470552355051\n",
      "Epoch: 2/5, Loss: 0.010473408736288548\n",
      "Epoch: 2/5, Loss: 0.0018917291890829802\n",
      "Epoch: 2/5, Loss: 0.014307077042758465\n",
      "Epoch: 2/5, Loss: 0.008980641141533852\n",
      "Epoch: 2/5, Loss: 0.012532586231827736\n",
      "Epoch: 2/5, Loss: 0.0395062193274498\n",
      "Epoch: 2/5, Loss: 0.04799206554889679\n",
      "Epoch: 2/5, Loss: 0.008929332718253136\n",
      "Epoch: 2/5, Loss: 0.004511232487857342\n",
      "Epoch: 2/5, Loss: 0.009872127324342728\n",
      "Epoch: 2/5, Loss: 0.03933611512184143\n",
      "Epoch: 2/5, Loss: 0.05802636966109276\n",
      "Epoch: 2/5, Loss: 0.02280798926949501\n",
      "Epoch: 2/5, Loss: 0.020511791110038757\n",
      "Epoch: 2/5, Loss: 0.04467739537358284\n",
      "Epoch: 2/5, Loss: 0.04198762774467468\n",
      "Epoch: 2/5, Loss: 0.009920276701450348\n",
      "Epoch: 2/5, Loss: 0.026217076927423477\n",
      "Epoch: 2/5, Loss: 0.014746509492397308\n",
      "Epoch: 2/5, Loss: 0.02484164386987686\n",
      "Epoch: 2/5, Loss: 0.027359738945961\n",
      "Epoch: 2/5, Loss: 0.04239191859960556\n",
      "Epoch: 2/5, Loss: 0.04717996343970299\n",
      "Epoch: 2/5, Loss: 0.01594517193734646\n",
      "Epoch: 2/5, Loss: 0.0225334744900465\n",
      "Epoch: 2/5, Loss: 0.053447771817445755\n",
      "Epoch: 2/5, Loss: 0.03603770583868027\n",
      "Epoch: 2/5, Loss: 0.02413870580494404\n",
      "Epoch: 2/5, Loss: 0.020045921206474304\n",
      "Epoch: 2/5, Loss: 0.061428580433130264\n",
      "Epoch: 2/5, Loss: 0.08101236075162888\n",
      "Epoch: 2/5, Loss: 0.04245623201131821\n",
      "Epoch: 2/5, Loss: 0.015582073479890823\n",
      "Epoch: 2/5, Loss: 0.05511096864938736\n",
      "Epoch: 2/5, Loss: 0.013372018933296204\n",
      "Epoch: 2/5, Loss: 0.09186846017837524\n",
      "Epoch: 2/5, Loss: 0.006006903015077114\n",
      "Epoch: 2/5, Loss: 0.03433145582675934\n",
      "Epoch: 2/5, Loss: 0.020094146952033043\n",
      "Epoch: 2/5, Loss: 0.03158864006400108\n",
      "Epoch: 2/5, Loss: 0.014825969934463501\n",
      "Epoch: 2/5, Loss: 0.022204486653208733\n",
      "Epoch: 2/5, Loss: 0.02674677222967148\n",
      "Epoch: 2/5, Loss: 0.005310836713761091\n",
      "Epoch: 2/5, Loss: 0.043829552829265594\n",
      "Epoch: 2/5, Loss: 0.008560460060834885\n",
      "Epoch: 2/5, Loss: 0.026573508977890015\n",
      "Epoch: 2/5, Loss: 0.020704098045825958\n",
      "Epoch: 2/5, Loss: 0.02262825518846512\n",
      "Epoch: 2/5, Loss: 0.031091168522834778\n",
      "Epoch: 2/5, Loss: 0.038477376103401184\n",
      "Epoch: 2/5, Loss: 0.03290083259344101\n",
      "Epoch: 2/5, Loss: 0.0036449634935706854\n",
      "Epoch: 2/5, Loss: 0.02890291064977646\n",
      "Epoch: 2/5, Loss: 0.0258888341486454\n",
      "Epoch: 2/5, Loss: 0.06982432305812836\n",
      "Epoch: 2/5, Loss: 0.04623040184378624\n",
      "Epoch: 2/5, Loss: 0.003973169717937708\n",
      "Epoch: 2/5, Loss: 0.07178257405757904\n",
      "Epoch: 2/5, Loss: 0.010030495934188366\n",
      "Epoch: 2/5, Loss: 0.016979074105620384\n",
      "Epoch: 2/5, Loss: 0.028030145913362503\n",
      "Epoch: 2/5, Loss: 0.02596890926361084\n",
      "Epoch: 2/5, Loss: 0.003571281675249338\n",
      "Epoch: 2/5, Loss: 0.030254993587732315\n",
      "Epoch: 2/5, Loss: 0.005839633755385876\n",
      "Epoch: 2/5, Loss: 0.02036500908434391\n",
      "Epoch: 2/5, Loss: 0.015015779063105583\n",
      "Epoch: 2/5, Loss: 0.014578776434063911\n",
      "Epoch: 2/5, Loss: 0.03420095890760422\n",
      "Epoch: 2/5, Loss: 0.03265316039323807\n",
      "Epoch: 2/5, Loss: 0.013333805836737156\n",
      "Epoch: 2/5, Loss: 0.041899122297763824\n",
      "Epoch: 2/5, Loss: 0.04556547850370407\n",
      "Epoch: 2/5, Loss: 0.026638949289917946\n",
      "Epoch: 2/5, Loss: 0.003138831118121743\n",
      "Epoch: 2/5, Loss: 0.06358522921800613\n",
      "Epoch: 2/5, Loss: 0.002169564366340637\n",
      "Epoch: 2/5, Loss: 0.04481402784585953\n",
      "Epoch: 2/5, Loss: 0.010299982503056526\n",
      "Epoch: 2/5, Loss: 0.002153382869437337\n",
      "Epoch: 2/5, Loss: 0.06568121910095215\n",
      "Epoch: 2/5, Loss: 0.037222303450107574\n",
      "Epoch: 2/5, Loss: 0.02474694885313511\n",
      "Epoch: 2/5, Loss: 0.05474155396223068\n",
      "Epoch: 2/5, Loss: 0.008185319602489471\n",
      "Epoch: 2/5, Loss: 0.01912654936313629\n",
      "Epoch: 2/5, Loss: 0.026257488876581192\n",
      "Epoch: 2/5, Loss: 0.054951783269643784\n",
      "Epoch: 2/5, Loss: 0.013819154351949692\n",
      "Epoch: 2/5, Loss: 0.023913156241178513\n",
      "Epoch: 2/5, Loss: 0.06491904705762863\n",
      "Epoch: 2/5, Loss: 0.03202039748430252\n",
      "Epoch: 2/5, Loss: 0.03459981083869934\n",
      "Epoch: 2/5, Loss: 0.023932069540023804\n",
      "Epoch: 2/5, Loss: 0.015427200123667717\n",
      "Epoch: 2/5, Loss: 0.04838632792234421\n",
      "Epoch: 2/5, Loss: 0.016320347785949707\n",
      "Epoch: 2/5, Loss: 0.05347176268696785\n",
      "Epoch: 2/5, Loss: 0.04340130463242531\n",
      "Epoch: 2/5, Loss: 0.009043248370289803\n",
      "Epoch: 2/5, Loss: 0.01011011004447937\n",
      "Epoch: 2/5, Loss: 0.03461625799536705\n",
      "Epoch: 2/5, Loss: 0.042487386614084244\n",
      "Epoch: 2/5, Loss: 0.025233007967472076\n",
      "Epoch: 2/5, Loss: 0.02342652715742588\n",
      "Epoch: 2/5, Loss: 0.022116467356681824\n",
      "Epoch: 2/5, Loss: 0.031211864203214645\n",
      "Epoch: 2/5, Loss: 0.07406871765851974\n",
      "Epoch: 2/5, Loss: 0.008706517517566681\n",
      "Epoch: 2/5, Loss: 0.035772114992141724\n",
      "Epoch: 2/5, Loss: 0.014592338353395462\n",
      "Epoch: 2/5, Loss: 0.023764949291944504\n",
      "Epoch: 2/5, Loss: 0.002069374080747366\n",
      "Epoch: 2/5, Loss: 0.03980139270424843\n",
      "Epoch: 3/5, Loss: 0.031868889927864075\n",
      "Epoch: 3/5, Loss: 0.05094457417726517\n",
      "Epoch: 3/5, Loss: 0.022763732820749283\n",
      "Epoch: 3/5, Loss: 0.038164954632520676\n",
      "Epoch: 3/5, Loss: 0.06138605996966362\n",
      "Epoch: 3/5, Loss: 0.050167638808488846\n",
      "Epoch: 3/5, Loss: 0.01802537962794304\n",
      "Epoch: 3/5, Loss: 0.003706208197399974\n",
      "Epoch: 3/5, Loss: 0.02481752634048462\n",
      "Epoch: 3/5, Loss: 0.03740888461470604\n",
      "Epoch: 3/5, Loss: 0.08850295096635818\n",
      "Epoch: 3/5, Loss: 0.01635124906897545\n",
      "Epoch: 3/5, Loss: 0.049693040549755096\n",
      "Epoch: 3/5, Loss: 0.04716873914003372\n",
      "Epoch: 3/5, Loss: 0.020358499139547348\n",
      "Epoch: 3/5, Loss: 0.012352622114121914\n",
      "Epoch: 3/5, Loss: 0.013363230973482132\n",
      "Epoch: 3/5, Loss: 0.034536510705947876\n",
      "Epoch: 3/5, Loss: 0.02989386022090912\n",
      "Epoch: 3/5, Loss: 0.010601567104458809\n",
      "Epoch: 3/5, Loss: 0.0167058277875185\n",
      "Epoch: 3/5, Loss: 0.02023858204483986\n",
      "Epoch: 3/5, Loss: 0.011717850342392921\n",
      "Epoch: 3/5, Loss: 0.023862916976213455\n",
      "Epoch: 3/5, Loss: 0.019530626013875008\n",
      "Epoch: 3/5, Loss: 0.07162165641784668\n",
      "Epoch: 3/5, Loss: 0.008196487091481686\n",
      "Epoch: 3/5, Loss: 0.01036057434976101\n",
      "Epoch: 3/5, Loss: 0.03069939836859703\n",
      "Epoch: 3/5, Loss: 0.01362678688019514\n",
      "Epoch: 3/5, Loss: 0.03901324048638344\n",
      "Epoch: 3/5, Loss: 0.027395382523536682\n",
      "Epoch: 3/5, Loss: 0.025969084352254868\n",
      "Epoch: 3/5, Loss: 0.023612890392541885\n",
      "Epoch: 3/5, Loss: 0.0692453682422638\n",
      "Epoch: 3/5, Loss: 0.0016778985736891627\n",
      "Epoch: 3/5, Loss: 0.02546367235481739\n",
      "Epoch: 3/5, Loss: 0.008658726699650288\n",
      "Epoch: 3/5, Loss: 0.0208481065928936\n",
      "Epoch: 3/5, Loss: 0.017552120611071587\n",
      "Epoch: 3/5, Loss: 0.05220314487814903\n",
      "Epoch: 3/5, Loss: 0.037782952189445496\n",
      "Epoch: 3/5, Loss: 0.04262808710336685\n",
      "Epoch: 3/5, Loss: 0.006152408197522163\n",
      "Epoch: 3/5, Loss: 0.015624276362359524\n",
      "Epoch: 3/5, Loss: 0.001309937797486782\n",
      "Epoch: 3/5, Loss: 0.012506412342190742\n",
      "Epoch: 3/5, Loss: 0.027894362807273865\n",
      "Epoch: 3/5, Loss: 0.02375190146267414\n",
      "Epoch: 3/5, Loss: 0.020945154130458832\n",
      "Epoch: 3/5, Loss: 0.0049294037744402885\n",
      "Epoch: 3/5, Loss: 0.06135886535048485\n",
      "Epoch: 3/5, Loss: 0.0647466778755188\n",
      "Epoch: 3/5, Loss: 0.08507293462753296\n",
      "Epoch: 3/5, Loss: 0.015612578950822353\n",
      "Epoch: 3/5, Loss: 0.03495269641280174\n",
      "Epoch: 3/5, Loss: 0.0375555120408535\n",
      "Epoch: 3/5, Loss: 0.019137557595968246\n",
      "Epoch: 3/5, Loss: 0.06355779618024826\n",
      "Epoch: 3/5, Loss: 0.009358844719827175\n",
      "Epoch: 3/5, Loss: 0.0039031002670526505\n",
      "Epoch: 3/5, Loss: 0.005891289561986923\n",
      "Epoch: 3/5, Loss: 0.02271440252661705\n",
      "Epoch: 3/5, Loss: 0.027371032163500786\n",
      "Epoch: 3/5, Loss: 0.03361796587705612\n",
      "Epoch: 3/5, Loss: 0.02708093822002411\n",
      "Epoch: 3/5, Loss: 0.06341998279094696\n",
      "Epoch: 3/5, Loss: 0.017476415261626244\n",
      "Epoch: 3/5, Loss: 0.055779483169317245\n",
      "Epoch: 3/5, Loss: 0.03435644507408142\n",
      "Epoch: 3/5, Loss: 0.012241850607097149\n",
      "Epoch: 3/5, Loss: 0.02598276548087597\n",
      "Epoch: 3/5, Loss: 0.008477815426886082\n",
      "Epoch: 3/5, Loss: 0.05431404709815979\n",
      "Epoch: 3/5, Loss: 0.002711072564125061\n",
      "Epoch: 3/5, Loss: 0.05180738493800163\n",
      "Epoch: 3/5, Loss: 0.02484486997127533\n",
      "Epoch: 3/5, Loss: 0.040060367435216904\n",
      "Epoch: 3/5, Loss: 0.04357727989554405\n",
      "Epoch: 3/5, Loss: 0.038850296288728714\n",
      "Epoch: 3/5, Loss: 0.027480900287628174\n",
      "Epoch: 3/5, Loss: 0.025060437619686127\n",
      "Epoch: 3/5, Loss: 0.037521883845329285\n",
      "Epoch: 3/5, Loss: 0.027200771495699883\n",
      "Epoch: 3/5, Loss: 0.029411915689706802\n",
      "Epoch: 3/5, Loss: 0.011551273986697197\n",
      "Epoch: 3/5, Loss: 0.09488409757614136\n",
      "Epoch: 3/5, Loss: 0.034252192825078964\n",
      "Epoch: 3/5, Loss: 0.05083540454506874\n",
      "Epoch: 3/5, Loss: 0.025521431118249893\n",
      "Epoch: 3/5, Loss: 0.03296441584825516\n",
      "Epoch: 3/5, Loss: 0.11304809898138046\n",
      "Epoch: 3/5, Loss: 0.02529708296060562\n",
      "Epoch: 3/5, Loss: 0.0457371361553669\n",
      "Epoch: 3/5, Loss: 0.0017595626413822174\n",
      "Epoch: 3/5, Loss: 0.03507884219288826\n",
      "Epoch: 3/5, Loss: 0.012505251914262772\n",
      "Epoch: 3/5, Loss: 0.010722044855356216\n",
      "Epoch: 3/5, Loss: 0.06375259160995483\n",
      "Epoch: 3/5, Loss: 0.020709995180368423\n",
      "Epoch: 3/5, Loss: 0.031766362488269806\n",
      "Epoch: 3/5, Loss: 0.03686174377799034\n",
      "Epoch: 3/5, Loss: 0.03264002874493599\n",
      "Epoch: 3/5, Loss: 0.0537702813744545\n",
      "Epoch: 3/5, Loss: 0.007840040139853954\n",
      "Epoch: 3/5, Loss: 0.0016477028839290142\n",
      "Epoch: 3/5, Loss: 0.06049241125583649\n",
      "Epoch: 3/5, Loss: 0.04017990827560425\n",
      "Epoch: 3/5, Loss: 0.008042383939027786\n",
      "Epoch: 3/5, Loss: 0.027152594178915024\n",
      "Epoch: 3/5, Loss: 0.04938589781522751\n",
      "Epoch: 3/5, Loss: 0.009656943380832672\n",
      "Epoch: 3/5, Loss: 0.03549939766526222\n",
      "Epoch: 3/5, Loss: 0.026893246918916702\n",
      "Epoch: 3/5, Loss: 0.03129478543996811\n",
      "Epoch: 3/5, Loss: 0.005518585443496704\n",
      "Epoch: 3/5, Loss: 0.015764355659484863\n",
      "Epoch: 3/5, Loss: 0.0415620282292366\n",
      "Epoch: 3/5, Loss: 0.023647692054510117\n",
      "Epoch: 3/5, Loss: 0.01832904852926731\n",
      "Epoch: 3/5, Loss: 0.012398726306855679\n",
      "Epoch: 3/5, Loss: 0.007507624104619026\n",
      "Epoch: 3/5, Loss: 0.033406127244234085\n",
      "Epoch: 3/5, Loss: 0.01600971445441246\n",
      "Epoch: 3/5, Loss: 0.01784530095756054\n",
      "Epoch: 3/5, Loss: 0.013793068006634712\n",
      "Epoch: 3/5, Loss: 0.06305673718452454\n",
      "Epoch: 3/5, Loss: 0.01639346033334732\n",
      "Epoch: 3/5, Loss: 0.04819662868976593\n",
      "Epoch: 3/5, Loss: 0.00793396309018135\n",
      "Epoch: 3/5, Loss: 0.0256061814725399\n",
      "Epoch: 3/5, Loss: 0.01925884559750557\n",
      "Epoch: 3/5, Loss: 0.00334951956756413\n",
      "Epoch: 3/5, Loss: 0.06569790840148926\n",
      "Epoch: 3/5, Loss: 0.012641316279768944\n",
      "Epoch: 3/5, Loss: 0.025695154443383217\n",
      "Epoch: 3/5, Loss: 0.015991002321243286\n",
      "Epoch: 3/5, Loss: 0.06864181160926819\n",
      "Epoch: 3/5, Loss: 0.030355487018823624\n",
      "Epoch: 3/5, Loss: 0.011434325017035007\n",
      "Epoch: 3/5, Loss: 0.023162467405200005\n",
      "Epoch: 3/5, Loss: 0.03320948779582977\n",
      "Epoch: 3/5, Loss: 0.0205620676279068\n",
      "Epoch: 3/5, Loss: 0.015514307655394077\n",
      "Epoch: 3/5, Loss: 0.00953635573387146\n",
      "Epoch: 3/5, Loss: 0.019249416887760162\n",
      "Epoch: 3/5, Loss: 0.022300193086266518\n",
      "Epoch: 3/5, Loss: 0.009129095822572708\n",
      "Epoch: 3/5, Loss: 0.014518436044454575\n",
      "Epoch: 3/5, Loss: 0.021504878997802734\n",
      "Epoch: 3/5, Loss: 0.031850434839725494\n",
      "Epoch: 3/5, Loss: 0.008613888174295425\n",
      "Epoch: 3/5, Loss: 0.009624038822948933\n",
      "Epoch: 3/5, Loss: 0.017943542450666428\n",
      "Epoch: 3/5, Loss: 0.017136801034212112\n",
      "Epoch: 3/5, Loss: 0.028063111007213593\n",
      "Epoch: 3/5, Loss: 0.02616017870604992\n",
      "Epoch: 3/5, Loss: 0.019087810069322586\n",
      "Epoch: 3/5, Loss: 0.021248534321784973\n",
      "Epoch: 3/5, Loss: 0.014723049476742744\n",
      "Epoch: 3/5, Loss: 0.015235617756843567\n",
      "Epoch: 3/5, Loss: 0.009280446916818619\n",
      "Epoch: 3/5, Loss: 0.016815539449453354\n",
      "Epoch: 3/5, Loss: 0.039816975593566895\n",
      "Epoch: 3/5, Loss: 0.0065066395327448845\n",
      "Epoch: 3/5, Loss: 0.07128889113664627\n",
      "Epoch: 3/5, Loss: 0.037844669073820114\n",
      "Epoch: 3/5, Loss: 0.009649579413235188\n",
      "Epoch: 3/5, Loss: 0.023278316482901573\n",
      "Epoch: 3/5, Loss: 0.025631936267018318\n",
      "Epoch: 3/5, Loss: 0.02479209564626217\n",
      "Epoch: 3/5, Loss: 0.03730453550815582\n",
      "Epoch: 3/5, Loss: 0.009604895487427711\n",
      "Epoch: 3/5, Loss: 0.020121140405535698\n",
      "Epoch: 3/5, Loss: 0.03395049646496773\n",
      "Epoch: 3/5, Loss: 0.01387198455631733\n",
      "Epoch: 3/5, Loss: 0.02712267078459263\n",
      "Epoch: 3/5, Loss: 0.004678691737353802\n",
      "Epoch: 3/5, Loss: 0.005414349492639303\n",
      "Epoch: 3/5, Loss: 0.03075198456645012\n",
      "Epoch: 3/5, Loss: 0.01628335751593113\n",
      "Epoch: 3/5, Loss: 0.015534784644842148\n",
      "Epoch: 3/5, Loss: 0.05164746195077896\n",
      "Epoch: 3/5, Loss: 0.05175430700182915\n",
      "Epoch: 3/5, Loss: 0.01541417371481657\n",
      "Epoch: 3/5, Loss: 0.03366534411907196\n",
      "Epoch: 3/5, Loss: 0.008938889019191265\n",
      "Epoch: 3/5, Loss: 0.007967320270836353\n",
      "Epoch: 3/5, Loss: 0.012741154991090298\n",
      "Epoch: 3/5, Loss: 0.008962172083556652\n",
      "Epoch: 3/5, Loss: 0.026332831010222435\n",
      "Epoch: 3/5, Loss: 0.0131281279027462\n",
      "Epoch: 3/5, Loss: 0.03529562056064606\n",
      "Epoch: 3/5, Loss: 0.00919212494045496\n",
      "Epoch: 3/5, Loss: 0.058727558702230453\n",
      "Epoch: 3/5, Loss: 0.008586674928665161\n",
      "Epoch: 3/5, Loss: 0.02278807945549488\n",
      "Epoch: 3/5, Loss: 0.021886853501200676\n",
      "Epoch: 3/5, Loss: 0.045751553028821945\n",
      "Epoch: 3/5, Loss: 0.01576233096420765\n",
      "Epoch: 3/5, Loss: 0.02220473438501358\n",
      "Epoch: 3/5, Loss: 0.013013279996812344\n",
      "Epoch: 3/5, Loss: 0.007876605726778507\n",
      "Epoch: 3/5, Loss: 0.013901772908866405\n",
      "Epoch: 3/5, Loss: 0.013037145137786865\n",
      "Epoch: 3/5, Loss: 0.007311077322810888\n",
      "Epoch: 3/5, Loss: 0.03168593347072601\n",
      "Epoch: 3/5, Loss: 0.017597004771232605\n",
      "Epoch: 3/5, Loss: 0.10571546852588654\n",
      "Epoch: 3/5, Loss: 0.026442280039191246\n",
      "Epoch: 3/5, Loss: 0.02671021781861782\n",
      "Epoch: 3/5, Loss: 0.005147008690983057\n",
      "Epoch: 3/5, Loss: 0.003908609040081501\n",
      "Epoch: 3/5, Loss: 0.025181844830513\n",
      "Epoch: 3/5, Loss: 0.047825902700424194\n",
      "Epoch: 3/5, Loss: 0.0030389127787202597\n",
      "Epoch: 3/5, Loss: 0.009958888404071331\n",
      "Epoch: 3/5, Loss: 0.014695527032017708\n",
      "Epoch: 3/5, Loss: 0.01787608675658703\n",
      "Epoch: 3/5, Loss: 0.006510231178253889\n",
      "Epoch: 3/5, Loss: 0.04375223442912102\n",
      "Epoch: 3/5, Loss: 0.0261133573949337\n",
      "Epoch: 3/5, Loss: 0.034355394542217255\n",
      "Epoch: 3/5, Loss: 0.00555406603962183\n",
      "Epoch: 3/5, Loss: 0.006546401884406805\n",
      "Epoch: 3/5, Loss: 0.008210983127355576\n",
      "Epoch: 3/5, Loss: 0.033455464988946915\n",
      "Epoch: 3/5, Loss: 0.05071501433849335\n",
      "Epoch: 3/5, Loss: 0.02014267072081566\n",
      "Epoch: 3/5, Loss: 0.020236685872077942\n",
      "Epoch: 3/5, Loss: 0.020100489258766174\n",
      "Epoch: 3/5, Loss: 0.0045808241702616215\n",
      "Epoch: 3/5, Loss: 0.025664562359452248\n",
      "Epoch: 3/5, Loss: 0.01723019778728485\n",
      "Epoch: 3/5, Loss: 0.02156180702149868\n",
      "Epoch: 3/5, Loss: 0.02171238325536251\n",
      "Epoch: 3/5, Loss: 0.020978055894374847\n",
      "Epoch: 3/5, Loss: 0.03383428230881691\n",
      "Epoch: 3/5, Loss: 0.016462823376059532\n",
      "Epoch: 3/5, Loss: 0.008378337137401104\n",
      "Epoch: 3/5, Loss: 0.07301915436983109\n",
      "Epoch: 3/5, Loss: 0.02769213728606701\n",
      "Epoch: 3/5, Loss: 0.01146343257278204\n",
      "Epoch: 3/5, Loss: 0.006704089231789112\n",
      "Epoch: 3/5, Loss: 0.005294523201882839\n",
      "Epoch: 3/5, Loss: 0.04098585993051529\n",
      "Epoch: 3/5, Loss: 0.011366463266313076\n",
      "Epoch: 3/5, Loss: 0.012863991782069206\n",
      "Epoch: 3/5, Loss: 0.014252116903662682\n",
      "Epoch: 3/5, Loss: 0.02131042256951332\n",
      "Epoch: 3/5, Loss: 0.026813268661499023\n",
      "Epoch: 3/5, Loss: 0.017704900354146957\n",
      "Epoch: 3/5, Loss: 0.02381567656993866\n",
      "Epoch: 3/5, Loss: 0.07893721014261246\n",
      "Epoch: 3/5, Loss: 0.025656839832663536\n",
      "Epoch: 3/5, Loss: 0.008148785680532455\n",
      "Epoch: 3/5, Loss: 0.06497222185134888\n",
      "Epoch: 3/5, Loss: 0.01655084826052189\n",
      "Epoch: 3/5, Loss: 0.07420042157173157\n",
      "Epoch: 3/5, Loss: 0.022193627431988716\n",
      "Epoch: 3/5, Loss: 0.12583407759666443\n",
      "Epoch: 3/5, Loss: 0.0012255482142791152\n",
      "Epoch: 3/5, Loss: 0.009944562800228596\n",
      "Epoch: 3/5, Loss: 0.033686354756355286\n",
      "Epoch: 3/5, Loss: 0.05859329178929329\n",
      "Epoch: 3/5, Loss: 0.04379045218229294\n",
      "Epoch: 3/5, Loss: 0.024490581825375557\n",
      "Epoch: 3/5, Loss: 0.01770010218024254\n",
      "Epoch: 3/5, Loss: 0.004659725818783045\n",
      "Epoch: 3/5, Loss: 0.012003314681351185\n",
      "Epoch: 3/5, Loss: 0.022093255072832108\n",
      "Epoch: 3/5, Loss: 0.029888790100812912\n",
      "Epoch: 3/5, Loss: 0.00034064508508890867\n",
      "Epoch: 3/5, Loss: 0.0415179617702961\n",
      "Epoch: 3/5, Loss: 0.027153857052326202\n",
      "Epoch: 3/5, Loss: 0.022112557664513588\n",
      "Epoch: 3/5, Loss: 0.02512224018573761\n",
      "Epoch: 3/5, Loss: 0.017830342054367065\n",
      "Epoch: 3/5, Loss: 0.12746667861938477\n",
      "Epoch: 3/5, Loss: 0.01885966770350933\n",
      "Epoch: 3/5, Loss: 0.047857243567705154\n",
      "Epoch: 3/5, Loss: 0.025958510115742683\n",
      "Epoch: 3/5, Loss: 0.014122765511274338\n",
      "Epoch: 3/5, Loss: 0.047730281949043274\n",
      "Epoch: 3/5, Loss: 0.013423658907413483\n",
      "Epoch: 3/5, Loss: 0.054109953343868256\n",
      "Epoch: 3/5, Loss: 0.002778412774205208\n",
      "Epoch: 3/5, Loss: 0.02260134369134903\n",
      "Epoch: 3/5, Loss: 0.02866131067276001\n",
      "Epoch: 3/5, Loss: 0.028034105896949768\n",
      "Epoch: 3/5, Loss: 0.023951958864927292\n",
      "Epoch: 3/5, Loss: 0.02613164111971855\n",
      "Epoch: 3/5, Loss: 0.031550053507089615\n",
      "Epoch: 3/5, Loss: 0.010369213297963142\n",
      "Epoch: 3/5, Loss: 0.026836548000574112\n",
      "Epoch: 3/5, Loss: 0.03660096600651741\n",
      "Epoch: 3/5, Loss: 0.01896759122610092\n",
      "Epoch: 3/5, Loss: 0.005246027372777462\n",
      "Epoch: 3/5, Loss: 0.008851866237819195\n",
      "Epoch: 3/5, Loss: 0.019685981795191765\n",
      "Epoch: 3/5, Loss: 0.013666082173585892\n",
      "Epoch: 3/5, Loss: 0.06390988081693649\n",
      "Epoch: 3/5, Loss: 0.005431928671896458\n",
      "Epoch: 3/5, Loss: 0.04081718623638153\n",
      "Epoch: 3/5, Loss: 0.002389807254076004\n",
      "Epoch: 3/5, Loss: 0.045861970633268356\n",
      "Epoch: 3/5, Loss: 0.02067391946911812\n",
      "Epoch: 3/5, Loss: 0.015512299723923206\n",
      "Epoch: 3/5, Loss: 0.00637888815253973\n",
      "Epoch: 3/5, Loss: 0.02853495627641678\n",
      "Epoch: 3/5, Loss: 0.015187217853963375\n",
      "Epoch: 3/5, Loss: 0.03831742703914642\n",
      "Epoch: 3/5, Loss: 0.01295650377869606\n",
      "Epoch: 3/5, Loss: 0.008259570226073265\n",
      "Epoch: 3/5, Loss: 0.020297789946198463\n",
      "Epoch: 3/5, Loss: 0.03245805948972702\n",
      "Epoch: 3/5, Loss: 0.009846294298768044\n",
      "Epoch: 3/5, Loss: 0.025115272030234337\n",
      "Epoch: 3/5, Loss: 0.029074201360344887\n",
      "Epoch: 3/5, Loss: 0.023977287113666534\n",
      "Epoch: 3/5, Loss: 0.014053608290851116\n",
      "Epoch: 3/5, Loss: 0.023986363783478737\n",
      "Epoch: 3/5, Loss: 0.006272431463003159\n",
      "Epoch: 3/5, Loss: 0.026196876540780067\n",
      "Epoch: 3/5, Loss: 0.01090412586927414\n",
      "Epoch: 3/5, Loss: 0.06323642283678055\n",
      "Epoch: 3/5, Loss: 0.005971574690192938\n",
      "Epoch: 3/5, Loss: 0.026054123416543007\n",
      "Epoch: 3/5, Loss: 0.06767967343330383\n",
      "Epoch: 3/5, Loss: 0.02073713205754757\n",
      "Epoch: 3/5, Loss: 0.022855278104543686\n",
      "Epoch: 3/5, Loss: 0.05072520300745964\n",
      "Epoch: 3/5, Loss: 0.028255630284547806\n",
      "Epoch: 3/5, Loss: 0.04549099877476692\n",
      "Epoch: 3/5, Loss: 0.025186307728290558\n",
      "Epoch: 3/5, Loss: 0.04715018719434738\n",
      "Epoch: 3/5, Loss: 0.033662099391222\n",
      "Epoch: 3/5, Loss: 0.023042112588882446\n",
      "Epoch: 3/5, Loss: 0.053915686905384064\n",
      "Epoch: 3/5, Loss: 0.02064437046647072\n",
      "Epoch: 3/5, Loss: 0.012312492355704308\n",
      "Epoch: 3/5, Loss: 0.056192971765995026\n",
      "Epoch: 3/5, Loss: 0.015639765188097954\n",
      "Epoch: 3/5, Loss: 0.02525125816464424\n",
      "Epoch: 3/5, Loss: 0.025219999253749847\n",
      "Epoch: 3/5, Loss: 0.04403745383024216\n",
      "Epoch: 3/5, Loss: 0.02005717344582081\n",
      "Epoch: 3/5, Loss: 0.04465432092547417\n",
      "Epoch: 3/5, Loss: 0.009229513816535473\n",
      "Epoch: 3/5, Loss: 0.015508132986724377\n",
      "Epoch: 3/5, Loss: 0.00961730070412159\n",
      "Epoch: 3/5, Loss: 0.017920343205332756\n",
      "Epoch: 3/5, Loss: 0.009806827642023563\n",
      "Epoch: 3/5, Loss: 0.009903243742883205\n",
      "Epoch: 3/5, Loss: 0.02283078245818615\n",
      "Epoch: 3/5, Loss: 0.0199589841067791\n",
      "Epoch: 3/5, Loss: 0.027722259983420372\n",
      "Epoch: 3/5, Loss: 0.006942376960068941\n",
      "Epoch: 3/5, Loss: 0.03268679976463318\n",
      "Epoch: 3/5, Loss: 0.029967766255140305\n",
      "Epoch: 3/5, Loss: 0.005809429567307234\n",
      "Epoch: 3/5, Loss: 0.011588059365749359\n",
      "Epoch: 3/5, Loss: 0.009111398831009865\n",
      "Epoch: 3/5, Loss: 0.0231475830078125\n",
      "Epoch: 3/5, Loss: 0.007974320091307163\n",
      "Epoch: 3/5, Loss: 0.023295696824789047\n",
      "Epoch: 3/5, Loss: 0.030418314039707184\n",
      "Epoch: 3/5, Loss: 0.0074609979055821896\n",
      "Epoch: 3/5, Loss: 0.011978603899478912\n",
      "Epoch: 3/5, Loss: 0.024167915806174278\n",
      "Epoch: 3/5, Loss: 0.02933542989194393\n",
      "Epoch: 3/5, Loss: 0.0077263121493160725\n",
      "Epoch: 3/5, Loss: 0.04924212396144867\n",
      "Epoch: 3/5, Loss: 0.03263606131076813\n",
      "Epoch: 3/5, Loss: 0.0027581246104091406\n",
      "Epoch: 3/5, Loss: 0.01928788051009178\n",
      "Epoch: 3/5, Loss: 0.022776523604989052\n",
      "Epoch: 3/5, Loss: 0.007381116971373558\n",
      "Epoch: 3/5, Loss: 0.01616550236940384\n",
      "Epoch: 3/5, Loss: 0.021325301378965378\n",
      "Epoch: 3/5, Loss: 0.0426395907998085\n",
      "Epoch: 3/5, Loss: 0.01369263045489788\n",
      "Epoch: 3/5, Loss: 0.034989405423402786\n",
      "Epoch: 3/5, Loss: 0.0048990496434271336\n",
      "Epoch: 3/5, Loss: 0.010847281664609909\n",
      "Epoch: 3/5, Loss: 0.04849971458315849\n",
      "Epoch: 3/5, Loss: 0.019942719489336014\n",
      "Epoch: 3/5, Loss: 0.002425690181553364\n",
      "Epoch: 3/5, Loss: 0.008266406133770943\n",
      "Epoch: 3/5, Loss: 0.030869897454977036\n",
      "Epoch: 3/5, Loss: 0.017828579992055893\n",
      "Epoch: 3/5, Loss: 0.039383772760629654\n",
      "Epoch: 3/5, Loss: 0.009172935970127583\n",
      "Epoch: 3/5, Loss: 0.031659938395023346\n",
      "Epoch: 3/5, Loss: 0.014536051079630852\n",
      "Epoch: 3/5, Loss: 0.07098714262247086\n",
      "Epoch: 3/5, Loss: 0.024029817432165146\n",
      "Epoch: 3/5, Loss: 0.012813394889235497\n",
      "Epoch: 3/5, Loss: 0.04997130483388901\n",
      "Epoch: 3/5, Loss: 0.05942193418741226\n",
      "Epoch: 3/5, Loss: 0.0085879135876894\n",
      "Epoch: 3/5, Loss: 0.017790203914046288\n",
      "Epoch: 3/5, Loss: 0.04984032362699509\n",
      "Epoch: 3/5, Loss: 0.026046106591820717\n",
      "Epoch: 3/5, Loss: 0.04819117486476898\n",
      "Epoch: 3/5, Loss: 0.027857203036546707\n",
      "Epoch: 3/5, Loss: 0.011596432887017727\n",
      "Epoch: 3/5, Loss: 0.010549427010118961\n",
      "Epoch: 3/5, Loss: 0.04001191258430481\n",
      "Epoch: 3/5, Loss: 0.015133759006857872\n",
      "Epoch: 3/5, Loss: 0.03686082735657692\n",
      "Epoch: 3/5, Loss: 0.022619368508458138\n",
      "Epoch: 3/5, Loss: 0.020775875076651573\n",
      "Epoch: 3/5, Loss: 0.004861229099333286\n",
      "Epoch: 3/5, Loss: 0.0007953649619594216\n",
      "Epoch: 3/5, Loss: 0.011814333498477936\n",
      "Epoch: 3/5, Loss: 0.031088002026081085\n",
      "Epoch: 3/5, Loss: 0.054590098559856415\n",
      "Epoch: 3/5, Loss: 0.011674724519252777\n",
      "Epoch: 3/5, Loss: 0.039006903767585754\n",
      "Epoch: 3/5, Loss: 0.08547050505876541\n",
      "Epoch: 3/5, Loss: 0.07425650209188461\n",
      "Epoch: 3/5, Loss: 0.04752352088689804\n",
      "Epoch: 3/5, Loss: 0.014703478664159775\n",
      "Epoch: 3/5, Loss: 0.02666730061173439\n",
      "Epoch: 3/5, Loss: 0.006242402829229832\n",
      "Epoch: 3/5, Loss: 0.015662292018532753\n",
      "Epoch: 3/5, Loss: 0.11062242090702057\n",
      "Epoch: 3/5, Loss: 0.03205323964357376\n",
      "Epoch: 3/5, Loss: 0.021001271903514862\n",
      "Epoch: 3/5, Loss: 0.02734699845314026\n",
      "Epoch: 3/5, Loss: 0.04630431532859802\n",
      "Epoch: 3/5, Loss: 0.039059463888406754\n",
      "Epoch: 3/5, Loss: 0.028842555359005928\n",
      "Epoch: 3/5, Loss: 0.04766098037362099\n",
      "Epoch: 3/5, Loss: 0.04319653660058975\n",
      "Epoch: 3/5, Loss: 0.06719382852315903\n",
      "Epoch: 3/5, Loss: 0.03212391957640648\n",
      "Epoch: 3/5, Loss: 0.0362793430685997\n",
      "Epoch: 3/5, Loss: 0.17518563568592072\n",
      "Epoch: 3/5, Loss: 0.017604965716600418\n",
      "Epoch: 3/5, Loss: 0.012471863999962807\n",
      "Epoch: 3/5, Loss: 0.06545145809650421\n",
      "Epoch: 3/5, Loss: 0.0050247712060809135\n",
      "Epoch: 3/5, Loss: 0.00887972116470337\n",
      "Epoch: 3/5, Loss: 0.013097488321363926\n",
      "Epoch: 3/5, Loss: 0.014284024015069008\n",
      "Epoch: 3/5, Loss: 0.0078008477576076984\n",
      "Epoch: 3/5, Loss: 0.02126023918390274\n",
      "Epoch: 3/5, Loss: 0.009608638472855091\n",
      "Epoch: 3/5, Loss: 0.050915662199258804\n",
      "Epoch: 3/5, Loss: 0.03085721656680107\n",
      "Epoch: 3/5, Loss: 0.01654924638569355\n",
      "Epoch: 3/5, Loss: 0.007867246866226196\n",
      "Epoch: 3/5, Loss: 0.05294639617204666\n",
      "Epoch: 3/5, Loss: 0.0558004230260849\n",
      "Epoch: 3/5, Loss: 0.027447568252682686\n",
      "Epoch: 3/5, Loss: 0.0063573881052434444\n",
      "Epoch: 3/5, Loss: 0.0069213449023664\n",
      "Epoch: 3/5, Loss: 0.02188432589173317\n",
      "Epoch: 3/5, Loss: 0.02817671000957489\n",
      "Epoch: 3/5, Loss: 0.020135650411248207\n",
      "Epoch: 3/5, Loss: 0.017541812732815742\n",
      "Epoch: 3/5, Loss: 0.014918006956577301\n",
      "Epoch: 3/5, Loss: 0.002123242011293769\n",
      "Epoch: 3/5, Loss: 0.020843319594860077\n",
      "Epoch: 3/5, Loss: 0.02008139342069626\n",
      "Epoch: 3/5, Loss: 0.009208118543028831\n",
      "Epoch: 3/5, Loss: 0.007725206203758717\n",
      "Epoch: 3/5, Loss: 0.023108048364520073\n",
      "Epoch: 3/5, Loss: 0.012990984134376049\n",
      "Epoch: 3/5, Loss: 0.019153345376253128\n",
      "Epoch: 3/5, Loss: 0.010629859752953053\n",
      "Epoch: 3/5, Loss: 0.013161873444914818\n",
      "Epoch: 3/5, Loss: 0.061063915491104126\n",
      "Epoch: 3/5, Loss: 0.01896314136683941\n",
      "Epoch: 3/5, Loss: 0.13228128850460052\n",
      "Epoch: 3/5, Loss: 0.007319350261241198\n",
      "Epoch: 3/5, Loss: 0.009257924742996693\n",
      "Epoch: 3/5, Loss: 0.030238807201385498\n",
      "Epoch: 3/5, Loss: 0.03876134753227234\n",
      "Epoch: 3/5, Loss: 0.059737544506788254\n",
      "Epoch: 3/5, Loss: 0.033937402069568634\n",
      "Epoch: 3/5, Loss: 0.04384336248040199\n",
      "Epoch: 3/5, Loss: 0.06206078827381134\n",
      "Epoch: 3/5, Loss: 0.018771938979625702\n",
      "Epoch: 3/5, Loss: 0.09158651530742645\n",
      "Epoch: 3/5, Loss: 0.03338298574090004\n",
      "Epoch: 3/5, Loss: 0.01576809398829937\n",
      "Epoch: 3/5, Loss: 0.062111128121614456\n",
      "Epoch: 3/5, Loss: 0.019937247037887573\n",
      "Epoch: 3/5, Loss: 0.021157296374440193\n",
      "Epoch: 3/5, Loss: 0.030395854264497757\n",
      "Epoch: 3/5, Loss: 0.007766613736748695\n",
      "Epoch: 3/5, Loss: 0.05746694654226303\n",
      "Epoch: 3/5, Loss: 0.022388914600014687\n",
      "Epoch: 3/5, Loss: 0.06536257266998291\n",
      "Epoch: 3/5, Loss: 0.06296470761299133\n",
      "Epoch: 3/5, Loss: 0.009557786397635937\n",
      "Epoch: 3/5, Loss: 0.006738313473761082\n",
      "Epoch: 3/5, Loss: 0.011695723049342632\n",
      "Epoch: 3/5, Loss: 0.0016312745865434408\n",
      "Epoch: 3/5, Loss: 0.02910733036696911\n",
      "Epoch: 3/5, Loss: 0.02635842375457287\n",
      "Epoch: 3/5, Loss: 0.033431753516197205\n",
      "Epoch: 3/5, Loss: 0.008231380954384804\n",
      "Epoch: 3/5, Loss: 0.0302022323012352\n",
      "Epoch: 3/5, Loss: 0.03258641064167023\n",
      "Epoch: 3/5, Loss: 0.03551550954580307\n",
      "Epoch: 3/5, Loss: 0.018847785890102386\n",
      "Epoch: 3/5, Loss: 0.01801748387515545\n",
      "Epoch: 3/5, Loss: 0.033124152570962906\n",
      "Epoch: 3/5, Loss: 0.024429744109511375\n",
      "Epoch: 3/5, Loss: 0.011325996369123459\n",
      "Epoch: 3/5, Loss: 0.027131233364343643\n",
      "Epoch: 3/5, Loss: 0.04400615021586418\n",
      "Epoch: 3/5, Loss: 0.020431041717529297\n",
      "Epoch: 3/5, Loss: 0.01849549636244774\n",
      "Epoch: 3/5, Loss: 0.03598596900701523\n",
      "Epoch: 3/5, Loss: 0.014836408197879791\n",
      "Epoch: 3/5, Loss: 0.08048538863658905\n",
      "Epoch: 3/5, Loss: 0.033619921654462814\n",
      "Epoch: 3/5, Loss: 0.003999644890427589\n",
      "Epoch: 3/5, Loss: 0.010983625426888466\n",
      "Epoch: 3/5, Loss: 0.037714000791311264\n",
      "Epoch: 3/5, Loss: 0.013636474497616291\n",
      "Epoch: 3/5, Loss: 0.08200611174106598\n",
      "Epoch: 3/5, Loss: 0.0345601961016655\n",
      "Epoch: 3/5, Loss: 0.011457003653049469\n",
      "Epoch: 3/5, Loss: 0.04243343695998192\n",
      "Epoch: 3/5, Loss: 0.019006667658686638\n",
      "Epoch: 3/5, Loss: 0.038242533802986145\n",
      "Epoch: 3/5, Loss: 0.019474171102046967\n",
      "Epoch: 3/5, Loss: 0.008896002545952797\n",
      "Epoch: 3/5, Loss: 0.007617677561938763\n",
      "Epoch: 3/5, Loss: 0.014514020644128323\n",
      "Epoch: 3/5, Loss: 0.00515972962602973\n",
      "Epoch: 3/5, Loss: 0.054620809853076935\n",
      "Epoch: 3/5, Loss: 0.029809385538101196\n",
      "Epoch: 3/5, Loss: 0.13905437290668488\n",
      "Epoch: 3/5, Loss: 0.019215965643525124\n",
      "Epoch: 3/5, Loss: 0.013049948960542679\n",
      "Epoch: 3/5, Loss: 0.040593471378088\n",
      "Epoch: 3/5, Loss: 0.0345473550260067\n",
      "Epoch: 3/5, Loss: 0.021328160539269447\n",
      "Epoch: 3/5, Loss: 0.026620611548423767\n",
      "Epoch: 3/5, Loss: 0.03053593635559082\n",
      "Epoch: 3/5, Loss: 0.11930429935455322\n",
      "Epoch: 3/5, Loss: 0.014317033812403679\n",
      "Epoch: 3/5, Loss: 0.007662179414182901\n",
      "Epoch: 3/5, Loss: 0.04758061468601227\n",
      "Epoch: 3/5, Loss: 0.004301036708056927\n",
      "Epoch: 3/5, Loss: 0.012078744359314442\n",
      "Epoch: 3/5, Loss: 0.05780189484357834\n",
      "Epoch: 3/5, Loss: 0.0319475494325161\n",
      "Epoch: 3/5, Loss: 0.0162262711673975\n",
      "Epoch: 3/5, Loss: 0.04141819477081299\n",
      "Epoch: 3/5, Loss: 0.005859535653144121\n",
      "Epoch: 3/5, Loss: 0.04352103918790817\n",
      "Epoch: 3/5, Loss: 0.017665863037109375\n",
      "Epoch: 3/5, Loss: 0.0070065599866211414\n",
      "Epoch: 3/5, Loss: 0.0011035571806132793\n",
      "Epoch: 3/5, Loss: 0.006791761610656977\n",
      "Epoch: 3/5, Loss: 0.013002047315239906\n",
      "Epoch: 3/5, Loss: 0.06868544220924377\n",
      "Epoch: 3/5, Loss: 0.029963882640004158\n",
      "Epoch: 3/5, Loss: 0.027402661740779877\n",
      "Epoch: 3/5, Loss: 0.019918248057365417\n",
      "Epoch: 3/5, Loss: 0.05464162677526474\n",
      "Epoch: 3/5, Loss: 0.010848543606698513\n",
      "Epoch: 3/5, Loss: 0.07797535508871078\n",
      "Epoch: 3/5, Loss: 0.00954478420317173\n",
      "Epoch: 3/5, Loss: 0.04273909702897072\n",
      "Epoch: 3/5, Loss: 0.00200314586982131\n",
      "Epoch: 3/5, Loss: 0.02713686227798462\n",
      "Epoch: 3/5, Loss: 0.009647592902183533\n",
      "Epoch: 3/5, Loss: 0.02198674902319908\n",
      "Epoch: 3/5, Loss: 0.04596381261944771\n",
      "Epoch: 3/5, Loss: 0.00430025439709425\n",
      "Epoch: 3/5, Loss: 0.04652467370033264\n",
      "Epoch: 3/5, Loss: 0.02195143513381481\n",
      "Epoch: 3/5, Loss: 0.03557802736759186\n",
      "Epoch: 3/5, Loss: 0.033643338829278946\n",
      "Epoch: 3/5, Loss: 0.024209007620811462\n",
      "Epoch: 3/5, Loss: 0.01740158349275589\n",
      "Epoch: 3/5, Loss: 0.006087139248847961\n",
      "Epoch: 3/5, Loss: 0.01023236196488142\n",
      "Epoch: 3/5, Loss: 0.022771017625927925\n",
      "Epoch: 3/5, Loss: 0.009548980742692947\n",
      "Epoch: 3/5, Loss: 0.00396300945430994\n",
      "Epoch: 3/5, Loss: 0.03904309496283531\n",
      "Epoch: 3/5, Loss: 0.018111132085323334\n",
      "Epoch: 3/5, Loss: 0.002955250209197402\n",
      "Epoch: 3/5, Loss: 0.006467848084867001\n",
      "Epoch: 3/5, Loss: 0.021690702065825462\n",
      "Epoch: 3/5, Loss: 0.015026210807263851\n",
      "Epoch: 3/5, Loss: 0.006005968898534775\n",
      "Epoch: 3/5, Loss: 0.02731771394610405\n",
      "Epoch: 3/5, Loss: 0.02586228959262371\n",
      "Epoch: 3/5, Loss: 0.018334222957491875\n",
      "Epoch: 3/5, Loss: 0.026278072968125343\n",
      "Epoch: 3/5, Loss: 0.0189119353890419\n",
      "Epoch: 3/5, Loss: 0.0033740829676389694\n",
      "Epoch: 3/5, Loss: 0.021905910223722458\n",
      "Epoch: 3/5, Loss: 0.013783284462988377\n",
      "Epoch: 3/5, Loss: 0.0067655425518751144\n",
      "Epoch: 3/5, Loss: 0.0014906873693689704\n",
      "Epoch: 3/5, Loss: 0.006158930715173483\n",
      "Epoch: 3/5, Loss: 0.027493881061673164\n",
      "Epoch: 3/5, Loss: 0.026549017056822777\n",
      "Epoch: 3/5, Loss: 0.015638545155525208\n",
      "Epoch: 3/5, Loss: 0.03342039883136749\n",
      "Epoch: 3/5, Loss: 0.01262488029897213\n",
      "Epoch: 3/5, Loss: 0.03334139660000801\n",
      "Epoch: 3/5, Loss: 0.058843545615673065\n",
      "Epoch: 3/5, Loss: 0.0352240689098835\n",
      "Epoch: 3/5, Loss: 0.03560515120625496\n",
      "Epoch: 3/5, Loss: 0.02003692276775837\n",
      "Epoch: 3/5, Loss: 0.005333118140697479\n",
      "Epoch: 3/5, Loss: 0.044139593839645386\n",
      "Epoch: 3/5, Loss: 0.020793307572603226\n",
      "Epoch: 3/5, Loss: 0.010343940928578377\n",
      "Epoch: 3/5, Loss: 0.00508637772873044\n",
      "Epoch: 3/5, Loss: 0.05372391641139984\n",
      "Epoch: 3/5, Loss: 0.015201556496322155\n",
      "Epoch: 3/5, Loss: 0.005875878501683474\n",
      "Epoch: 3/5, Loss: 0.01071840524673462\n",
      "Epoch: 3/5, Loss: 0.014746121130883694\n",
      "Epoch: 3/5, Loss: 0.030173590406775475\n",
      "Epoch: 3/5, Loss: 0.015630746260285378\n",
      "Epoch: 3/5, Loss: 0.023446766659617424\n",
      "Epoch: 3/5, Loss: 0.03409118577837944\n",
      "Epoch: 3/5, Loss: 0.02959819883108139\n",
      "Epoch: 3/5, Loss: 0.003241236787289381\n",
      "Epoch: 3/5, Loss: 0.014183912426233292\n",
      "Epoch: 3/5, Loss: 0.04733025282621384\n",
      "Epoch: 3/5, Loss: 0.04166183993220329\n",
      "Epoch: 3/5, Loss: 0.008538370952010155\n",
      "Epoch: 3/5, Loss: 0.023807279765605927\n",
      "Epoch: 3/5, Loss: 0.02353253960609436\n",
      "Epoch: 3/5, Loss: 0.15121319890022278\n",
      "Epoch: 3/5, Loss: 0.001705699018202722\n",
      "Epoch: 3/5, Loss: 0.019545432180166245\n",
      "Epoch: 3/5, Loss: 0.05518774688243866\n",
      "Epoch: 3/5, Loss: 0.05866573005914688\n",
      "Epoch: 3/5, Loss: 0.01775284670293331\n",
      "Epoch: 3/5, Loss: 0.008089450187981129\n",
      "Epoch: 3/5, Loss: 0.02426069602370262\n",
      "Epoch: 3/5, Loss: 0.0020547674503177404\n",
      "Epoch: 3/5, Loss: 0.04658620432019234\n",
      "Epoch: 3/5, Loss: 0.0363331064581871\n",
      "Epoch: 3/5, Loss: 0.010300487279891968\n",
      "Epoch: 3/5, Loss: 0.057392191141843796\n",
      "Epoch: 3/5, Loss: 0.08141745626926422\n",
      "Epoch: 3/5, Loss: 0.009749852120876312\n",
      "Epoch: 3/5, Loss: 0.04749435931444168\n",
      "Epoch: 3/5, Loss: 0.057826701551675797\n",
      "Epoch: 3/5, Loss: 0.018853824585676193\n",
      "Epoch: 3/5, Loss: 0.03286634013056755\n",
      "Epoch: 3/5, Loss: 0.012872928753495216\n",
      "Epoch: 3/5, Loss: 0.005193750374019146\n",
      "Epoch: 3/5, Loss: 0.014381354674696922\n",
      "Epoch: 3/5, Loss: 0.01964942179620266\n",
      "Epoch: 3/5, Loss: 0.007413923274725676\n",
      "Epoch: 3/5, Loss: 0.028492944315075874\n",
      "Epoch: 3/5, Loss: 0.027151282876729965\n",
      "Epoch: 3/5, Loss: 0.016151953488588333\n",
      "Epoch: 3/5, Loss: 0.1747310310602188\n",
      "Epoch: 3/5, Loss: 0.02553432248532772\n",
      "Epoch: 3/5, Loss: 0.03813977539539337\n",
      "Epoch: 3/5, Loss: 0.02465604990720749\n",
      "Epoch: 3/5, Loss: 0.017714472487568855\n",
      "Epoch: 3/5, Loss: 0.019541852176189423\n",
      "Epoch: 3/5, Loss: 0.010716430842876434\n",
      "Epoch: 3/5, Loss: 0.008350910618901253\n",
      "Epoch: 3/5, Loss: 0.029460148885846138\n",
      "Epoch: 3/5, Loss: 0.012875042855739594\n",
      "Epoch: 3/5, Loss: 0.002483513904735446\n",
      "Epoch: 3/5, Loss: 0.04087674617767334\n",
      "Epoch: 3/5, Loss: 0.016413910314440727\n",
      "Epoch: 3/5, Loss: 0.017214106395840645\n",
      "Epoch: 3/5, Loss: 0.003305608406662941\n",
      "Epoch: 3/5, Loss: 0.015146244317293167\n",
      "Epoch: 3/5, Loss: 0.02519933320581913\n",
      "Epoch: 3/5, Loss: 0.0420168936252594\n",
      "Epoch: 3/5, Loss: 0.010010108351707458\n",
      "Epoch: 3/5, Loss: 0.010335404425859451\n",
      "Epoch: 3/5, Loss: 0.009939425624907017\n",
      "Epoch: 3/5, Loss: 0.0046662455424666405\n",
      "Epoch: 3/5, Loss: 0.027029508724808693\n",
      "Epoch: 3/5, Loss: 0.013731615617871284\n",
      "Epoch: 3/5, Loss: 0.0073804124258458614\n",
      "Epoch: 3/5, Loss: 0.004531382583081722\n",
      "Epoch: 3/5, Loss: 0.010830329731106758\n",
      "Epoch: 3/5, Loss: 0.005604854319244623\n",
      "Epoch: 3/5, Loss: 0.037499263882637024\n",
      "Epoch: 3/5, Loss: 0.021419020369648933\n",
      "Epoch: 3/5, Loss: 0.07284974306821823\n",
      "Epoch: 3/5, Loss: 0.004815111868083477\n",
      "Epoch: 3/5, Loss: 0.026289047673344612\n",
      "Epoch: 3/5, Loss: 0.019437897950410843\n",
      "Epoch: 3/5, Loss: 0.015357466414570808\n",
      "Epoch: 3/5, Loss: 0.01380927488207817\n",
      "Epoch: 3/5, Loss: 0.007804696913808584\n",
      "Epoch: 3/5, Loss: 0.029391836374998093\n",
      "Epoch: 3/5, Loss: 0.03880934417247772\n",
      "Epoch: 3/5, Loss: 0.029701249673962593\n",
      "Epoch: 3/5, Loss: 0.015548797324299812\n",
      "Epoch: 3/5, Loss: 0.07235679030418396\n",
      "Epoch: 3/5, Loss: 0.011545228771865368\n",
      "Epoch: 3/5, Loss: 0.03810282051563263\n",
      "Epoch: 3/5, Loss: 0.02586487866938114\n",
      "Epoch: 3/5, Loss: 0.04600026458501816\n",
      "Epoch: 3/5, Loss: 0.019076962023973465\n",
      "Epoch: 3/5, Loss: 0.0072602638974785805\n",
      "Epoch: 3/5, Loss: 0.08749823272228241\n",
      "Epoch: 3/5, Loss: 0.003218689700588584\n",
      "Epoch: 3/5, Loss: 0.014660104177892208\n",
      "Epoch: 3/5, Loss: 0.06666651368141174\n",
      "Epoch: 3/5, Loss: 0.04001506417989731\n",
      "Epoch: 3/5, Loss: 0.01088720466941595\n",
      "Epoch: 3/5, Loss: 0.04481958970427513\n",
      "Epoch: 3/5, Loss: 0.01242006104439497\n",
      "Epoch: 3/5, Loss: 0.006232446059584618\n",
      "Epoch: 3/5, Loss: 0.018537987023591995\n",
      "Epoch: 3/5, Loss: 0.012394078075885773\n",
      "Epoch: 3/5, Loss: 0.005429761949926615\n",
      "Epoch: 3/5, Loss: 0.027051368728280067\n",
      "Epoch: 3/5, Loss: 0.011524039320647717\n",
      "Epoch: 3/5, Loss: 0.08294515311717987\n",
      "Epoch: 3/5, Loss: 0.0178457573056221\n",
      "Epoch: 3/5, Loss: 0.0012142406776547432\n",
      "Epoch: 3/5, Loss: 0.013147306628525257\n",
      "Epoch: 3/5, Loss: 0.07768336683511734\n",
      "Epoch: 3/5, Loss: 0.007302064914256334\n",
      "Epoch: 3/5, Loss: 0.02843138761818409\n",
      "Epoch: 3/5, Loss: 0.051790088415145874\n",
      "Epoch: 3/5, Loss: 0.01044672541320324\n",
      "Epoch: 3/5, Loss: 0.020637601613998413\n",
      "Epoch: 3/5, Loss: 0.04368225485086441\n",
      "Epoch: 3/5, Loss: 0.009305611252784729\n",
      "Epoch: 3/5, Loss: 0.03879149258136749\n",
      "Epoch: 3/5, Loss: 0.0018859587144106627\n",
      "Epoch: 3/5, Loss: 0.030554594472050667\n",
      "Epoch: 3/5, Loss: 0.038198187947273254\n",
      "Epoch: 3/5, Loss: 0.043022871017456055\n",
      "Epoch: 3/5, Loss: 0.011838487349450588\n",
      "Epoch: 3/5, Loss: 0.05537291616201401\n",
      "Epoch: 3/5, Loss: 0.005375416949391365\n",
      "Epoch: 3/5, Loss: 0.00801389105618\n",
      "Epoch: 3/5, Loss: 0.03627248480916023\n",
      "Epoch: 3/5, Loss: 0.015355980023741722\n",
      "Epoch: 3/5, Loss: 0.04193267226219177\n",
      "Epoch: 3/5, Loss: 0.007405849173665047\n",
      "Epoch: 3/5, Loss: 0.05317651107907295\n",
      "Epoch: 3/5, Loss: 0.1071045994758606\n",
      "Epoch: 3/5, Loss: 0.0015948574291542172\n",
      "Epoch: 3/5, Loss: 0.007401124108582735\n",
      "Epoch: 3/5, Loss: 0.02628127858042717\n",
      "Epoch: 3/5, Loss: 0.015554584562778473\n",
      "Epoch: 3/5, Loss: 0.062342945486307144\n",
      "Epoch: 3/5, Loss: 0.02261686883866787\n",
      "Epoch: 3/5, Loss: 0.05581457540392876\n",
      "Epoch: 3/5, Loss: 0.047831080853939056\n",
      "Epoch: 3/5, Loss: 0.05541324242949486\n",
      "Epoch: 3/5, Loss: 0.00502813933417201\n",
      "Epoch: 3/5, Loss: 0.008979096077382565\n",
      "Epoch: 3/5, Loss: 0.03292832523584366\n",
      "Epoch: 3/5, Loss: 0.012486670166254044\n",
      "Epoch: 3/5, Loss: 0.023562561720609665\n",
      "Epoch: 3/5, Loss: 0.010197845287621021\n",
      "Epoch: 3/5, Loss: 0.055035289376974106\n",
      "Epoch: 3/5, Loss: 0.04747221618890762\n",
      "Epoch: 3/5, Loss: 0.020658371970057487\n",
      "Epoch: 3/5, Loss: 0.03071705996990204\n",
      "Epoch: 3/5, Loss: 0.02294536493718624\n",
      "Epoch: 3/5, Loss: 0.029792094603180885\n",
      "Epoch: 3/5, Loss: 0.00991421565413475\n",
      "Epoch: 3/5, Loss: 0.016443580389022827\n",
      "Epoch: 3/5, Loss: 0.10895092040300369\n",
      "Epoch: 3/5, Loss: 0.016723178327083588\n",
      "Epoch: 3/5, Loss: 0.008914152160286903\n",
      "Epoch: 3/5, Loss: 0.037238188087940216\n",
      "Epoch: 3/5, Loss: 0.035757143050432205\n",
      "Epoch: 3/5, Loss: 0.001189969596453011\n",
      "Epoch: 3/5, Loss: 0.014894354157149792\n",
      "Epoch: 3/5, Loss: 0.029847895726561546\n",
      "Epoch: 3/5, Loss: 0.057741157710552216\n",
      "Epoch: 3/5, Loss: 0.03098820149898529\n",
      "Epoch: 3/5, Loss: 0.027478957548737526\n",
      "Epoch: 3/5, Loss: 0.006144672632217407\n",
      "Epoch: 3/5, Loss: 0.053087636828422546\n",
      "Epoch: 3/5, Loss: 0.02386999875307083\n",
      "Epoch: 3/5, Loss: 0.04804577678442001\n",
      "Epoch: 3/5, Loss: 0.03473285585641861\n",
      "Epoch: 3/5, Loss: 0.02149788662791252\n",
      "Epoch: 3/5, Loss: 0.013770760968327522\n",
      "Epoch: 3/5, Loss: 0.0031356788240373135\n",
      "Epoch: 3/5, Loss: 0.05365698039531708\n",
      "Epoch: 3/5, Loss: 0.018625250086188316\n",
      "Epoch: 3/5, Loss: 0.021433835849165916\n",
      "Epoch: 3/5, Loss: 0.028660260140895844\n",
      "Epoch: 3/5, Loss: 0.005721160676330328\n",
      "Epoch: 3/5, Loss: 0.019855916500091553\n",
      "Epoch: 3/5, Loss: 0.02193615958094597\n",
      "Epoch: 3/5, Loss: 0.02643660455942154\n",
      "Epoch: 3/5, Loss: 0.07347280532121658\n",
      "Epoch: 3/5, Loss: 0.011700885370373726\n",
      "Epoch: 3/5, Loss: 0.005973878316581249\n",
      "Epoch: 3/5, Loss: 0.0028854552656412125\n",
      "Epoch: 3/5, Loss: 0.04876051843166351\n",
      "Epoch: 3/5, Loss: 0.04449709877371788\n",
      "Epoch: 3/5, Loss: 0.04807973653078079\n",
      "Epoch: 3/5, Loss: 0.008653156459331512\n",
      "Epoch: 3/5, Loss: 0.027605446055531502\n",
      "Epoch: 3/5, Loss: 0.01255881693214178\n",
      "Epoch: 3/5, Loss: 0.008940580300986767\n",
      "Epoch: 3/5, Loss: 0.021662626415491104\n",
      "Epoch: 3/5, Loss: 0.02130211889743805\n",
      "Epoch: 3/5, Loss: 0.031128115952014923\n",
      "Epoch: 3/5, Loss: 0.00348849524743855\n",
      "Epoch: 3/5, Loss: 0.015111962333321571\n",
      "Epoch: 3/5, Loss: 0.013057708740234375\n",
      "Epoch: 3/5, Loss: 0.035514943301677704\n",
      "Epoch: 3/5, Loss: 0.02488897368311882\n",
      "Epoch: 3/5, Loss: 0.019872482866048813\n",
      "Epoch: 3/5, Loss: 0.016146128997206688\n",
      "Epoch: 3/5, Loss: 0.015550589188933372\n",
      "Epoch: 3/5, Loss: 0.004022722598165274\n",
      "Epoch: 3/5, Loss: 0.015842372551560402\n",
      "Epoch: 3/5, Loss: 0.027794305235147476\n",
      "Epoch: 3/5, Loss: 0.0063188523054122925\n",
      "Epoch: 3/5, Loss: 0.0197578314691782\n",
      "Epoch: 3/5, Loss: 0.019382840022444725\n",
      "Epoch: 3/5, Loss: 0.008352145552635193\n",
      "Epoch: 3/5, Loss: 0.020742006599903107\n",
      "Epoch: 3/5, Loss: 0.018452754244208336\n",
      "Epoch: 3/5, Loss: 0.018680119886994362\n",
      "Epoch: 3/5, Loss: 0.013124467805027962\n",
      "Epoch: 3/5, Loss: 0.007046140730381012\n",
      "Epoch: 3/5, Loss: 0.005389946047216654\n",
      "Epoch: 3/5, Loss: 0.01100582629442215\n",
      "Epoch: 3/5, Loss: 0.0210161954164505\n",
      "Epoch: 3/5, Loss: 0.05740116164088249\n",
      "Epoch: 3/5, Loss: 0.018241772428154945\n",
      "Epoch: 3/5, Loss: 0.04153085872530937\n",
      "Epoch: 3/5, Loss: 0.0519072562456131\n",
      "Epoch: 3/5, Loss: 0.004944587126374245\n",
      "Epoch: 3/5, Loss: 0.047960784286260605\n",
      "Epoch: 3/5, Loss: 0.003724838839843869\n",
      "Epoch: 3/5, Loss: 0.02216918021440506\n",
      "Epoch: 3/5, Loss: 0.030267661437392235\n",
      "Epoch: 3/5, Loss: 0.008653528057038784\n",
      "Epoch: 3/5, Loss: 0.013698610477149487\n",
      "Epoch: 3/5, Loss: 0.012809360399842262\n",
      "Epoch: 3/5, Loss: 0.00842670351266861\n",
      "Epoch: 3/5, Loss: 0.03390221670269966\n",
      "Epoch: 3/5, Loss: 0.052685804665088654\n",
      "Epoch: 3/5, Loss: 0.014827745966613293\n",
      "Epoch: 3/5, Loss: 0.03015996143221855\n",
      "Epoch: 3/5, Loss: 0.015614397823810577\n",
      "Epoch: 3/5, Loss: 0.005029744002968073\n",
      "Epoch: 3/5, Loss: 0.015402525663375854\n",
      "Epoch: 3/5, Loss: 0.016011033207178116\n",
      "Epoch: 3/5, Loss: 0.04821544140577316\n",
      "Epoch: 3/5, Loss: 0.0028383166063576937\n",
      "Epoch: 3/5, Loss: 0.004426244180649519\n",
      "Epoch: 3/5, Loss: 0.02792203426361084\n",
      "Epoch: 3/5, Loss: 0.037584058940410614\n",
      "Epoch: 3/5, Loss: 0.021376004442572594\n",
      "Epoch: 3/5, Loss: 0.07922938466072083\n",
      "Epoch: 3/5, Loss: 0.004787841811776161\n",
      "Epoch: 3/5, Loss: 0.02588513121008873\n",
      "Epoch: 3/5, Loss: 0.015725811943411827\n",
      "Epoch: 3/5, Loss: 0.04012427106499672\n",
      "Epoch: 3/5, Loss: 0.017149630934000015\n",
      "Epoch: 3/5, Loss: 0.014691726304590702\n",
      "Epoch: 3/5, Loss: 0.007175971753895283\n",
      "Epoch: 3/5, Loss: 0.011204937472939491\n",
      "Epoch: 3/5, Loss: 0.02240654267370701\n",
      "Epoch: 3/5, Loss: 0.0021204634103924036\n",
      "Epoch: 3/5, Loss: 0.008626537397503853\n",
      "Epoch: 3/5, Loss: 0.019238300621509552\n",
      "Epoch: 3/5, Loss: 0.017375346273183823\n",
      "Epoch: 3/5, Loss: 0.0633583813905716\n",
      "Epoch: 3/5, Loss: 0.0017120258416980505\n",
      "Epoch: 3/5, Loss: 0.014135997742414474\n",
      "Epoch: 3/5, Loss: 0.012123147025704384\n",
      "Epoch: 3/5, Loss: 0.06242848187685013\n",
      "Epoch: 3/5, Loss: 0.043890759348869324\n",
      "Epoch: 3/5, Loss: 0.04637018218636513\n",
      "Epoch: 3/5, Loss: 0.006989382207393646\n",
      "Epoch: 3/5, Loss: 0.01690690778195858\n",
      "Epoch: 3/5, Loss: 0.009340072050690651\n",
      "Epoch: 3/5, Loss: 0.008030503056943417\n",
      "Epoch: 3/5, Loss: 0.006617872975766659\n",
      "Epoch: 3/5, Loss: 0.01653176173567772\n",
      "Epoch: 3/5, Loss: 0.004429742228239775\n",
      "Epoch: 3/5, Loss: 0.005944431759417057\n",
      "Epoch: 3/5, Loss: 0.014365916140377522\n",
      "Epoch: 3/5, Loss: 0.018576648086309433\n",
      "Epoch: 3/5, Loss: 0.009552533738315105\n",
      "Epoch: 3/5, Loss: 0.01418650895357132\n",
      "Epoch: 3/5, Loss: 0.01981792040169239\n",
      "Epoch: 3/5, Loss: 0.003962002694606781\n",
      "Epoch: 3/5, Loss: 0.029212292283773422\n",
      "Epoch: 3/5, Loss: 0.011579700745642185\n",
      "Epoch: 3/5, Loss: 0.02431427128612995\n",
      "Epoch: 3/5, Loss: 0.03288571909070015\n",
      "Epoch: 3/5, Loss: 0.02031685598194599\n",
      "Epoch: 3/5, Loss: 0.018446777015924454\n",
      "Epoch: 3/5, Loss: 0.01145180780440569\n",
      "Epoch: 3/5, Loss: 0.02092224359512329\n",
      "Epoch: 3/5, Loss: 0.018301628530025482\n",
      "Epoch: 3/5, Loss: 0.011821120046079159\n",
      "Epoch: 3/5, Loss: 0.0062735918909311295\n",
      "Epoch: 3/5, Loss: 0.05838708207011223\n",
      "Epoch: 3/5, Loss: 0.023617226630449295\n",
      "Epoch: 3/5, Loss: 0.026984255760908127\n",
      "Epoch: 3/5, Loss: 0.024131152778863907\n",
      "Epoch: 3/5, Loss: 0.025924693793058395\n",
      "Epoch: 3/5, Loss: 0.0053045726381242275\n",
      "Epoch: 3/5, Loss: 0.008826584555208683\n",
      "Epoch: 3/5, Loss: 0.007930091582238674\n",
      "Epoch: 3/5, Loss: 0.01709027588367462\n",
      "Epoch: 3/5, Loss: 0.014539774507284164\n",
      "Epoch: 3/5, Loss: 0.0057349540293216705\n",
      "Epoch: 3/5, Loss: 0.018774567171931267\n",
      "Epoch: 3/5, Loss: 0.04492427036166191\n",
      "Epoch: 3/5, Loss: 0.05760075896978378\n",
      "Epoch: 3/5, Loss: 0.0016945530660450459\n",
      "Epoch: 3/5, Loss: 0.018693726509809494\n",
      "Epoch: 3/5, Loss: 0.007426152937114239\n",
      "Epoch: 3/5, Loss: 0.012590067461133003\n",
      "Epoch: 3/5, Loss: 0.0054150959476828575\n",
      "Epoch: 3/5, Loss: 0.006304222624748945\n",
      "Epoch: 3/5, Loss: 0.00572827085852623\n",
      "Epoch: 3/5, Loss: 0.008616090752184391\n",
      "Epoch: 3/5, Loss: 0.01957254856824875\n",
      "Epoch: 4/5, Loss: 0.005830562207847834\n",
      "Epoch: 4/5, Loss: 0.008146245032548904\n",
      "Epoch: 4/5, Loss: 0.0312143936753273\n",
      "Epoch: 4/5, Loss: 0.01750532165169716\n",
      "Epoch: 4/5, Loss: 0.021952573210000992\n",
      "Epoch: 4/5, Loss: 0.006746420171111822\n",
      "Epoch: 4/5, Loss: 0.024690566584467888\n",
      "Epoch: 4/5, Loss: 0.004377000033855438\n",
      "Epoch: 4/5, Loss: 0.011843396350741386\n",
      "Epoch: 4/5, Loss: 0.010504077188670635\n",
      "Epoch: 4/5, Loss: 0.014746366068720818\n",
      "Epoch: 4/5, Loss: 0.05325024202466011\n",
      "Epoch: 4/5, Loss: 0.013183163478970528\n",
      "Epoch: 4/5, Loss: 0.01500074565410614\n",
      "Epoch: 4/5, Loss: 0.06834421306848526\n",
      "Epoch: 4/5, Loss: 0.019387030974030495\n",
      "Epoch: 4/5, Loss: 0.030208751559257507\n",
      "Epoch: 4/5, Loss: 0.02534490078687668\n",
      "Epoch: 4/5, Loss: 0.028434375301003456\n",
      "Epoch: 4/5, Loss: 0.07541204988956451\n",
      "Epoch: 4/5, Loss: 0.024671506136655807\n",
      "Epoch: 4/5, Loss: 0.019357725977897644\n",
      "Epoch: 4/5, Loss: 0.016845090314745903\n",
      "Epoch: 4/5, Loss: 0.029789863154292107\n",
      "Epoch: 4/5, Loss: 0.08727972209453583\n",
      "Epoch: 4/5, Loss: 0.01262563094496727\n",
      "Epoch: 4/5, Loss: 0.018429536372423172\n",
      "Epoch: 4/5, Loss: 0.0030816635116934776\n",
      "Epoch: 4/5, Loss: 0.010253128595650196\n",
      "Epoch: 4/5, Loss: 0.023809202015399933\n",
      "Epoch: 4/5, Loss: 0.02638166956603527\n",
      "Epoch: 4/5, Loss: 0.021548675373196602\n",
      "Epoch: 4/5, Loss: 0.022145939990878105\n",
      "Epoch: 4/5, Loss: 0.008799639530479908\n",
      "Epoch: 4/5, Loss: 0.00923091173171997\n",
      "Epoch: 4/5, Loss: 0.012791264802217484\n",
      "Epoch: 4/5, Loss: 0.03283742070198059\n",
      "Epoch: 4/5, Loss: 0.04598582535982132\n",
      "Epoch: 4/5, Loss: 0.024918003007769585\n",
      "Epoch: 4/5, Loss: 0.03627803921699524\n",
      "Epoch: 4/5, Loss: 0.0025648800656199455\n",
      "Epoch: 4/5, Loss: 0.01157666277140379\n",
      "Epoch: 4/5, Loss: 0.00937619898468256\n",
      "Epoch: 4/5, Loss: 0.05618700385093689\n",
      "Epoch: 4/5, Loss: 0.019997768104076385\n",
      "Epoch: 4/5, Loss: 0.018793655559420586\n",
      "Epoch: 4/5, Loss: 0.07540477812290192\n",
      "Epoch: 4/5, Loss: 0.02741433121263981\n",
      "Epoch: 4/5, Loss: 0.027356887236237526\n",
      "Epoch: 4/5, Loss: 0.013480398803949356\n",
      "Epoch: 4/5, Loss: 0.02725965343415737\n",
      "Epoch: 4/5, Loss: 0.05087922513484955\n",
      "Epoch: 4/5, Loss: 0.063233882188797\n",
      "Epoch: 4/5, Loss: 0.031474336981773376\n",
      "Epoch: 4/5, Loss: 0.039048366248607635\n",
      "Epoch: 4/5, Loss: 0.022474966943264008\n",
      "Epoch: 4/5, Loss: 0.02264290675520897\n",
      "Epoch: 4/5, Loss: 0.031101863831281662\n",
      "Epoch: 4/5, Loss: 0.036884866654872894\n",
      "Epoch: 4/5, Loss: 0.020090917125344276\n",
      "Epoch: 4/5, Loss: 0.0629906877875328\n",
      "Epoch: 4/5, Loss: 0.03728070110082626\n",
      "Epoch: 4/5, Loss: 0.03274969756603241\n",
      "Epoch: 4/5, Loss: 0.004926104564219713\n",
      "Epoch: 4/5, Loss: 0.027651969343423843\n",
      "Epoch: 4/5, Loss: 0.008903891779482365\n",
      "Epoch: 4/5, Loss: 0.045954879373311996\n",
      "Epoch: 4/5, Loss: 0.014708043076097965\n",
      "Epoch: 4/5, Loss: 0.03878701105713844\n",
      "Epoch: 4/5, Loss: 0.020884167402982712\n",
      "Epoch: 4/5, Loss: 0.020256375893950462\n",
      "Epoch: 4/5, Loss: 0.026150822639465332\n",
      "Epoch: 4/5, Loss: 0.020525459200143814\n",
      "Epoch: 4/5, Loss: 0.024222496896982193\n",
      "Epoch: 4/5, Loss: 0.011297793127596378\n",
      "Epoch: 4/5, Loss: 0.03350191190838814\n",
      "Epoch: 4/5, Loss: 0.006116265896707773\n",
      "Epoch: 4/5, Loss: 0.03471539542078972\n",
      "Epoch: 4/5, Loss: 0.009738638065755367\n",
      "Epoch: 4/5, Loss: 0.03703676909208298\n",
      "Epoch: 4/5, Loss: 0.012904276140034199\n",
      "Epoch: 4/5, Loss: 0.046932704746723175\n",
      "Epoch: 4/5, Loss: 0.017010316252708435\n",
      "Epoch: 4/5, Loss: 0.022972680628299713\n",
      "Epoch: 4/5, Loss: 0.017596587538719177\n",
      "Epoch: 4/5, Loss: 0.013226518407464027\n",
      "Epoch: 4/5, Loss: 0.00934162549674511\n",
      "Epoch: 4/5, Loss: 0.0019325248431414366\n",
      "Epoch: 4/5, Loss: 0.008566824719309807\n",
      "Epoch: 4/5, Loss: 0.006144235841929913\n",
      "Epoch: 4/5, Loss: 0.005622170399874449\n",
      "Epoch: 4/5, Loss: 0.011565147899091244\n",
      "Epoch: 4/5, Loss: 0.01736309938132763\n",
      "Epoch: 4/5, Loss: 0.05118396133184433\n",
      "Epoch: 4/5, Loss: 0.005824621766805649\n",
      "Epoch: 4/5, Loss: 0.0017990584019571543\n",
      "Epoch: 4/5, Loss: 0.0006620436906814575\n",
      "Epoch: 4/5, Loss: 0.009841494262218475\n",
      "Epoch: 4/5, Loss: 0.035862475633621216\n",
      "Epoch: 4/5, Loss: 0.039901603013277054\n",
      "Epoch: 4/5, Loss: 0.029744183644652367\n",
      "Epoch: 4/5, Loss: 0.011617970652878284\n",
      "Epoch: 4/5, Loss: 0.028237177059054375\n",
      "Epoch: 4/5, Loss: 0.0014307103119790554\n",
      "Epoch: 4/5, Loss: 0.044420573860406876\n",
      "Epoch: 4/5, Loss: 0.1121525764465332\n",
      "Epoch: 4/5, Loss: 0.07075578719377518\n",
      "Epoch: 4/5, Loss: 0.05000349134206772\n",
      "Epoch: 4/5, Loss: 0.022165954113006592\n",
      "Epoch: 4/5, Loss: 0.011843118816614151\n",
      "Epoch: 4/5, Loss: 0.04772350564599037\n",
      "Epoch: 4/5, Loss: 0.06521482765674591\n",
      "Epoch: 4/5, Loss: 0.03517398238182068\n",
      "Epoch: 4/5, Loss: 0.019286612048745155\n",
      "Epoch: 4/5, Loss: 0.03559871017932892\n",
      "Epoch: 4/5, Loss: 0.025520892813801765\n",
      "Epoch: 4/5, Loss: 0.0013266189489513636\n",
      "Epoch: 4/5, Loss: 0.028199343010783195\n",
      "Epoch: 4/5, Loss: 0.03995373472571373\n",
      "Epoch: 4/5, Loss: 0.0003723906702362001\n",
      "Epoch: 4/5, Loss: 0.03580229729413986\n",
      "Epoch: 4/5, Loss: 0.011635075323283672\n",
      "Epoch: 4/5, Loss: 0.01241082139313221\n",
      "Epoch: 4/5, Loss: 0.011989885941147804\n",
      "Epoch: 4/5, Loss: 0.0055162981152534485\n",
      "Epoch: 4/5, Loss: 0.009077093563973904\n",
      "Epoch: 4/5, Loss: 0.017523452639579773\n",
      "Epoch: 4/5, Loss: 0.029613474383950233\n",
      "Epoch: 4/5, Loss: 0.016844555735588074\n",
      "Epoch: 4/5, Loss: 0.00970262847840786\n",
      "Epoch: 4/5, Loss: 0.023267194628715515\n",
      "Epoch: 4/5, Loss: 0.037684984505176544\n",
      "Epoch: 4/5, Loss: 0.005928334780037403\n",
      "Epoch: 4/5, Loss: 0.04285701364278793\n",
      "Epoch: 4/5, Loss: 0.002994619542732835\n",
      "Epoch: 4/5, Loss: 0.009033940732479095\n",
      "Epoch: 4/5, Loss: 0.007046432234346867\n",
      "Epoch: 4/5, Loss: 0.005604545120149851\n",
      "Epoch: 4/5, Loss: 0.013693943619728088\n",
      "Epoch: 4/5, Loss: 0.021863307803869247\n",
      "Epoch: 4/5, Loss: 0.01526583917438984\n",
      "Epoch: 4/5, Loss: 0.019010748714208603\n",
      "Epoch: 4/5, Loss: 0.0687192752957344\n",
      "Epoch: 4/5, Loss: 0.07739130407571793\n",
      "Epoch: 4/5, Loss: 0.027921579778194427\n",
      "Epoch: 4/5, Loss: 0.17728689312934875\n",
      "Epoch: 4/5, Loss: 0.019051913172006607\n",
      "Epoch: 4/5, Loss: 0.0211954303085804\n",
      "Epoch: 4/5, Loss: 0.050983939319849014\n",
      "Epoch: 4/5, Loss: 0.007122387178242207\n",
      "Epoch: 4/5, Loss: 0.008864516392350197\n",
      "Epoch: 4/5, Loss: 0.00901707261800766\n",
      "Epoch: 4/5, Loss: 0.030309278517961502\n",
      "Epoch: 4/5, Loss: 0.021500639617443085\n",
      "Epoch: 4/5, Loss: 0.0011196266859769821\n",
      "Epoch: 4/5, Loss: 0.03076848015189171\n",
      "Epoch: 4/5, Loss: 0.018143372610211372\n",
      "Epoch: 4/5, Loss: 0.011441817507147789\n",
      "Epoch: 4/5, Loss: 0.03492553532123566\n",
      "Epoch: 4/5, Loss: 0.07993823289871216\n",
      "Epoch: 4/5, Loss: 0.04443209618330002\n",
      "Epoch: 4/5, Loss: 0.039431486278772354\n",
      "Epoch: 4/5, Loss: 0.036376018077135086\n",
      "Epoch: 4/5, Loss: 0.02019442245364189\n",
      "Epoch: 4/5, Loss: 0.027174126356840134\n",
      "Epoch: 4/5, Loss: 0.020184753462672234\n",
      "Epoch: 4/5, Loss: 0.036400359123945236\n",
      "Epoch: 4/5, Loss: 0.009077098220586777\n",
      "Epoch: 4/5, Loss: 0.02764386124908924\n",
      "Epoch: 4/5, Loss: 0.010846181772649288\n",
      "Epoch: 4/5, Loss: 0.05666102468967438\n",
      "Epoch: 4/5, Loss: 0.003269864246249199\n",
      "Epoch: 4/5, Loss: 0.007513727992773056\n",
      "Epoch: 4/5, Loss: 0.028707562014460564\n",
      "Epoch: 4/5, Loss: 0.05702430009841919\n",
      "Epoch: 4/5, Loss: 0.013700264506042004\n",
      "Epoch: 4/5, Loss: 0.00890360027551651\n",
      "Epoch: 4/5, Loss: 0.035015929490327835\n",
      "Epoch: 4/5, Loss: 0.01154234353452921\n",
      "Epoch: 4/5, Loss: 0.03853445500135422\n",
      "Epoch: 4/5, Loss: 0.023012647405266762\n",
      "Epoch: 4/5, Loss: 0.035951826721429825\n",
      "Epoch: 4/5, Loss: 0.028443356975913048\n",
      "Epoch: 4/5, Loss: 0.047586727887392044\n",
      "Epoch: 4/5, Loss: 0.02223520167171955\n",
      "Epoch: 4/5, Loss: 0.0170346200466156\n",
      "Epoch: 4/5, Loss: 0.02984589710831642\n",
      "Epoch: 4/5, Loss: 0.03830868750810623\n",
      "Epoch: 4/5, Loss: 0.02979518473148346\n",
      "Epoch: 4/5, Loss: 0.02730553224682808\n",
      "Epoch: 4/5, Loss: 0.040317945182323456\n",
      "Epoch: 4/5, Loss: 0.034246787428855896\n",
      "Epoch: 4/5, Loss: 0.010903753340244293\n",
      "Epoch: 4/5, Loss: 0.016451116651296616\n",
      "Epoch: 4/5, Loss: 0.01980615220963955\n",
      "Epoch: 4/5, Loss: 0.016284450888633728\n",
      "Epoch: 4/5, Loss: 0.0146161038428545\n",
      "Epoch: 4/5, Loss: 0.0233862716704607\n",
      "Epoch: 4/5, Loss: 0.006614974234253168\n",
      "Epoch: 4/5, Loss: 0.028335312381386757\n",
      "Epoch: 4/5, Loss: 0.011333384551107883\n",
      "Epoch: 4/5, Loss: 0.008762517012655735\n",
      "Epoch: 4/5, Loss: 0.007787757553160191\n",
      "Epoch: 4/5, Loss: 0.009381648153066635\n",
      "Epoch: 4/5, Loss: 0.004775450564920902\n",
      "Epoch: 4/5, Loss: 0.009216691367328167\n",
      "Epoch: 4/5, Loss: 0.03328154608607292\n",
      "Epoch: 4/5, Loss: 0.015944039449095726\n",
      "Epoch: 4/5, Loss: 0.02601027861237526\n",
      "Epoch: 4/5, Loss: 0.020249053835868835\n",
      "Epoch: 4/5, Loss: 0.008015287108719349\n",
      "Epoch: 4/5, Loss: 0.02440870925784111\n",
      "Epoch: 4/5, Loss: 0.06176392734050751\n",
      "Epoch: 4/5, Loss: 0.026772916316986084\n",
      "Epoch: 4/5, Loss: 0.03697791323065758\n",
      "Epoch: 4/5, Loss: 0.00674732169136405\n",
      "Epoch: 4/5, Loss: 0.0033593717962503433\n",
      "Epoch: 4/5, Loss: 0.01985703408718109\n",
      "Epoch: 4/5, Loss: 0.0143575519323349\n",
      "Epoch: 4/5, Loss: 0.02116115391254425\n",
      "Epoch: 4/5, Loss: 0.0712076872587204\n",
      "Epoch: 4/5, Loss: 0.03851410374045372\n",
      "Epoch: 4/5, Loss: 0.008723764680325985\n",
      "Epoch: 4/5, Loss: 0.020056704059243202\n",
      "Epoch: 4/5, Loss: 0.023807039484381676\n",
      "Epoch: 4/5, Loss: 0.012796678580343723\n",
      "Epoch: 4/5, Loss: 0.013919565826654434\n",
      "Epoch: 4/5, Loss: 0.0308157317340374\n",
      "Epoch: 4/5, Loss: 0.03645452857017517\n",
      "Epoch: 4/5, Loss: 0.04944964125752449\n",
      "Epoch: 4/5, Loss: 0.030394118279218674\n",
      "Epoch: 4/5, Loss: 0.039156824350357056\n",
      "Epoch: 4/5, Loss: 0.008714495226740837\n",
      "Epoch: 4/5, Loss: 0.020739881321787834\n",
      "Epoch: 4/5, Loss: 0.0627741664648056\n",
      "Epoch: 4/5, Loss: 0.05428451672196388\n",
      "Epoch: 4/5, Loss: 0.0010802621254697442\n",
      "Epoch: 4/5, Loss: 0.002128296298906207\n",
      "Epoch: 4/5, Loss: 0.006999960634857416\n",
      "Epoch: 4/5, Loss: 0.05468079447746277\n",
      "Epoch: 4/5, Loss: 0.031970370560884476\n",
      "Epoch: 4/5, Loss: 0.03535020351409912\n",
      "Epoch: 4/5, Loss: 0.003091273130849004\n",
      "Epoch: 4/5, Loss: 0.014237899333238602\n",
      "Epoch: 4/5, Loss: 0.02300255373120308\n",
      "Epoch: 4/5, Loss: 0.0024540885351598263\n",
      "Epoch: 4/5, Loss: 0.0036412295885384083\n",
      "Epoch: 4/5, Loss: 0.009836500510573387\n",
      "Epoch: 4/5, Loss: 0.010655926540493965\n",
      "Epoch: 4/5, Loss: 0.012409265153110027\n",
      "Epoch: 4/5, Loss: 0.03285782039165497\n",
      "Epoch: 4/5, Loss: 0.018778417259454727\n",
      "Epoch: 4/5, Loss: 0.03297388553619385\n",
      "Epoch: 4/5, Loss: 0.04599890485405922\n",
      "Epoch: 4/5, Loss: 0.03364726901054382\n",
      "Epoch: 4/5, Loss: 0.02892024628818035\n",
      "Epoch: 4/5, Loss: 0.031116360798478127\n",
      "Epoch: 4/5, Loss: 0.009527996182441711\n",
      "Epoch: 4/5, Loss: 0.010756906121969223\n",
      "Epoch: 4/5, Loss: 0.004235468804836273\n",
      "Epoch: 4/5, Loss: 0.015699392184615135\n",
      "Epoch: 4/5, Loss: 0.004727866966277361\n",
      "Epoch: 4/5, Loss: 0.019058508798480034\n",
      "Epoch: 4/5, Loss: 0.03909645602107048\n",
      "Epoch: 4/5, Loss: 0.008100099861621857\n",
      "Epoch: 4/5, Loss: 0.06643026322126389\n",
      "Epoch: 4/5, Loss: 0.0524422712624073\n",
      "Epoch: 4/5, Loss: 0.03345232829451561\n",
      "Epoch: 4/5, Loss: 0.020287776365876198\n",
      "Epoch: 4/5, Loss: 0.06200474128127098\n",
      "Epoch: 4/5, Loss: 0.009734245017170906\n",
      "Epoch: 4/5, Loss: 0.044914767146110535\n",
      "Epoch: 4/5, Loss: 0.045011162757873535\n",
      "Epoch: 4/5, Loss: 0.10826520621776581\n",
      "Epoch: 4/5, Loss: 0.01911086216568947\n",
      "Epoch: 4/5, Loss: 0.019388185814023018\n",
      "Epoch: 4/5, Loss: 0.04801183193922043\n",
      "Epoch: 4/5, Loss: 0.007859766483306885\n",
      "Epoch: 4/5, Loss: 0.007834218442440033\n",
      "Epoch: 4/5, Loss: 0.01669175550341606\n",
      "Epoch: 4/5, Loss: 0.006884390022605658\n",
      "Epoch: 4/5, Loss: 0.012094440869987011\n",
      "Epoch: 4/5, Loss: 0.02640174701809883\n",
      "Epoch: 4/5, Loss: 0.025914451107382774\n",
      "Epoch: 4/5, Loss: 0.03792314603924751\n",
      "Epoch: 4/5, Loss: 0.031042596325278282\n",
      "Epoch: 4/5, Loss: 0.02230662666261196\n",
      "Epoch: 4/5, Loss: 0.008860070258378983\n",
      "Epoch: 4/5, Loss: 0.030103251338005066\n",
      "Epoch: 4/5, Loss: 0.004200337454676628\n",
      "Epoch: 4/5, Loss: 0.07893984019756317\n",
      "Epoch: 4/5, Loss: 0.005889556370675564\n",
      "Epoch: 4/5, Loss: 0.025049222633242607\n",
      "Epoch: 4/5, Loss: 0.008949248120188713\n",
      "Epoch: 4/5, Loss: 0.02638023905456066\n",
      "Epoch: 4/5, Loss: 0.012572197243571281\n",
      "Epoch: 4/5, Loss: 0.03766707703471184\n",
      "Epoch: 4/5, Loss: 0.019247131422162056\n",
      "Epoch: 4/5, Loss: 0.024568144232034683\n",
      "Epoch: 4/5, Loss: 0.0314738005399704\n",
      "Epoch: 4/5, Loss: 0.18696820735931396\n",
      "Epoch: 4/5, Loss: 0.004135799594223499\n",
      "Epoch: 4/5, Loss: 0.004036104306578636\n",
      "Epoch: 4/5, Loss: 0.05072842538356781\n",
      "Epoch: 4/5, Loss: 0.050059713423252106\n",
      "Epoch: 4/5, Loss: 0.018084494397044182\n",
      "Epoch: 4/5, Loss: 0.010247905738651752\n",
      "Epoch: 4/5, Loss: 0.008040420711040497\n",
      "Epoch: 4/5, Loss: 0.006510524079203606\n",
      "Epoch: 4/5, Loss: 0.03457372635602951\n",
      "Epoch: 4/5, Loss: 0.04375499486923218\n",
      "Epoch: 4/5, Loss: 0.0011342274956405163\n",
      "Epoch: 4/5, Loss: 0.04358037933707237\n",
      "Epoch: 4/5, Loss: 0.045346178114414215\n",
      "Epoch: 4/5, Loss: 0.05028032138943672\n",
      "Epoch: 4/5, Loss: 0.03602957725524902\n",
      "Epoch: 4/5, Loss: 0.011756811290979385\n",
      "Epoch: 4/5, Loss: 0.022414904087781906\n",
      "Epoch: 4/5, Loss: 0.0029808352701365948\n",
      "Epoch: 4/5, Loss: 0.004505530931055546\n",
      "Epoch: 4/5, Loss: 0.006515503861010075\n",
      "Epoch: 4/5, Loss: 0.03512837365269661\n",
      "Epoch: 4/5, Loss: 0.00531673664227128\n",
      "Epoch: 4/5, Loss: 0.11679540574550629\n",
      "Epoch: 4/5, Loss: 0.0010684028966352344\n",
      "Epoch: 4/5, Loss: 0.11778626590967178\n",
      "Epoch: 4/5, Loss: 0.012129761278629303\n",
      "Epoch: 4/5, Loss: 0.0074837105348706245\n",
      "Epoch: 4/5, Loss: 0.013874093070626259\n",
      "Epoch: 4/5, Loss: 0.00989833939820528\n",
      "Epoch: 4/5, Loss: 0.019692102447152138\n",
      "Epoch: 4/5, Loss: 0.0658470094203949\n",
      "Epoch: 4/5, Loss: 0.027039574459195137\n",
      "Epoch: 4/5, Loss: 0.026667609810829163\n",
      "Epoch: 4/5, Loss: 0.01118797343224287\n",
      "Epoch: 4/5, Loss: 0.027319837361574173\n",
      "Epoch: 4/5, Loss: 0.13247190415859222\n",
      "Epoch: 4/5, Loss: 0.01535043679177761\n",
      "Epoch: 4/5, Loss: 0.00701227318495512\n",
      "Epoch: 4/5, Loss: 0.06348057091236115\n",
      "Epoch: 4/5, Loss: 0.019166383892297745\n",
      "Epoch: 4/5, Loss: 0.014996296726167202\n",
      "Epoch: 4/5, Loss: 0.023137375712394714\n",
      "Epoch: 4/5, Loss: 0.03693287819623947\n",
      "Epoch: 4/5, Loss: 0.050263285636901855\n",
      "Epoch: 4/5, Loss: 0.037813734263181686\n",
      "Epoch: 4/5, Loss: 0.042195506393909454\n",
      "Epoch: 4/5, Loss: 0.01400148868560791\n",
      "Epoch: 4/5, Loss: 0.0025965620297938585\n",
      "Epoch: 4/5, Loss: 0.03805338591337204\n",
      "Epoch: 4/5, Loss: 0.022366752848029137\n",
      "Epoch: 4/5, Loss: 0.017393026500940323\n",
      "Epoch: 4/5, Loss: 0.027969766408205032\n",
      "Epoch: 4/5, Loss: 0.0113994050770998\n",
      "Epoch: 4/5, Loss: 0.013798489235341549\n",
      "Epoch: 4/5, Loss: 0.03330199420452118\n",
      "Epoch: 4/5, Loss: 0.04679208993911743\n",
      "Epoch: 4/5, Loss: 0.021519433706998825\n",
      "Epoch: 4/5, Loss: 0.0057624755427241325\n",
      "Epoch: 4/5, Loss: 0.028503738343715668\n",
      "Epoch: 4/5, Loss: 0.0287545807659626\n",
      "Epoch: 4/5, Loss: 0.027899518609046936\n",
      "Epoch: 4/5, Loss: 0.02794545516371727\n",
      "Epoch: 4/5, Loss: 0.018054915592074394\n",
      "Epoch: 4/5, Loss: 0.007440661545842886\n",
      "Epoch: 4/5, Loss: 0.013711776584386826\n",
      "Epoch: 4/5, Loss: 0.009609618224203587\n",
      "Epoch: 4/5, Loss: 0.04005732387304306\n",
      "Epoch: 4/5, Loss: 0.06682965159416199\n",
      "Epoch: 4/5, Loss: 0.05721728131175041\n",
      "Epoch: 4/5, Loss: 0.012478712946176529\n",
      "Epoch: 4/5, Loss: 0.013109087012708187\n",
      "Epoch: 4/5, Loss: 0.015583026222884655\n",
      "Epoch: 4/5, Loss: 0.0011865843553096056\n",
      "Epoch: 4/5, Loss: 0.015000976622104645\n",
      "Epoch: 4/5, Loss: 0.01690506376326084\n",
      "Epoch: 4/5, Loss: 0.017883427441120148\n",
      "Epoch: 4/5, Loss: 0.021777911111712456\n",
      "Epoch: 4/5, Loss: 0.012860291637480259\n",
      "Epoch: 4/5, Loss: 0.01677468977868557\n",
      "Epoch: 4/5, Loss: 0.03564091771841049\n",
      "Epoch: 4/5, Loss: 0.04278895631432533\n",
      "Epoch: 4/5, Loss: 0.015929626300930977\n",
      "Epoch: 4/5, Loss: 0.0037942335475236177\n",
      "Epoch: 4/5, Loss: 0.07944907248020172\n",
      "Epoch: 4/5, Loss: 0.0385049469769001\n",
      "Epoch: 4/5, Loss: 0.012241910211741924\n",
      "Epoch: 4/5, Loss: 0.018533384427428246\n",
      "Epoch: 4/5, Loss: 0.014389853924512863\n",
      "Epoch: 4/5, Loss: 0.02358802780508995\n",
      "Epoch: 4/5, Loss: 0.014048109762370586\n",
      "Epoch: 4/5, Loss: 0.030486896634101868\n",
      "Epoch: 4/5, Loss: 0.00534319831058383\n",
      "Epoch: 4/5, Loss: 0.0155637813732028\n",
      "Epoch: 4/5, Loss: 0.02305426448583603\n",
      "Epoch: 4/5, Loss: 0.003066997043788433\n",
      "Epoch: 4/5, Loss: 0.015255102887749672\n",
      "Epoch: 4/5, Loss: 0.010670095682144165\n",
      "Epoch: 4/5, Loss: 0.024569937959313393\n",
      "Epoch: 4/5, Loss: 0.0022813472896814346\n",
      "Epoch: 4/5, Loss: 0.026695426553487778\n",
      "Epoch: 4/5, Loss: 0.039495356380939484\n",
      "Epoch: 4/5, Loss: 0.014773488976061344\n",
      "Epoch: 4/5, Loss: 0.013376850634813309\n",
      "Epoch: 4/5, Loss: 0.030079999938607216\n",
      "Epoch: 4/5, Loss: 0.010706530883908272\n",
      "Epoch: 4/5, Loss: 0.0295567624270916\n",
      "Epoch: 4/5, Loss: 0.02844642847776413\n",
      "Epoch: 4/5, Loss: 0.005184439476579428\n",
      "Epoch: 4/5, Loss: 0.04527220129966736\n",
      "Epoch: 4/5, Loss: 0.05161169916391373\n",
      "Epoch: 4/5, Loss: 0.015797888860106468\n",
      "Epoch: 4/5, Loss: 0.008000887930393219\n",
      "Epoch: 4/5, Loss: 0.01154322735965252\n",
      "Epoch: 4/5, Loss: 0.003262682119384408\n",
      "Epoch: 4/5, Loss: 0.02516770176589489\n",
      "Epoch: 4/5, Loss: 0.04276148974895477\n",
      "Epoch: 4/5, Loss: 0.01300301868468523\n",
      "Epoch: 4/5, Loss: 0.04309568181633949\n",
      "Epoch: 4/5, Loss: 0.015719246119260788\n",
      "Epoch: 4/5, Loss: 0.010980339720845222\n",
      "Epoch: 4/5, Loss: 0.009626897983253002\n",
      "Epoch: 4/5, Loss: 0.009547079913318157\n",
      "Epoch: 4/5, Loss: 0.008220032788813114\n",
      "Epoch: 4/5, Loss: 0.01423061266541481\n",
      "Epoch: 4/5, Loss: 0.028949083760380745\n",
      "Epoch: 4/5, Loss: 0.07053130865097046\n",
      "Epoch: 4/5, Loss: 0.017447158694267273\n",
      "Epoch: 4/5, Loss: 0.009350712411105633\n",
      "Epoch: 4/5, Loss: 0.014528403989970684\n",
      "Epoch: 4/5, Loss: 0.01608196645975113\n",
      "Epoch: 4/5, Loss: 0.05159929394721985\n",
      "Epoch: 4/5, Loss: 0.015390763059258461\n",
      "Epoch: 4/5, Loss: 0.029774673283100128\n",
      "Epoch: 4/5, Loss: 0.057106152176856995\n",
      "Epoch: 4/5, Loss: 0.006157918833196163\n",
      "Epoch: 4/5, Loss: 0.015720967203378677\n",
      "Epoch: 4/5, Loss: 0.007145959883928299\n",
      "Epoch: 4/5, Loss: 0.0232361052185297\n",
      "Epoch: 4/5, Loss: 0.009958191774785519\n",
      "Epoch: 4/5, Loss: 0.01856343448162079\n",
      "Epoch: 4/5, Loss: 0.04434361308813095\n",
      "Epoch: 4/5, Loss: 0.0107674989849329\n",
      "Epoch: 4/5, Loss: 0.01002756878733635\n",
      "Epoch: 4/5, Loss: 0.011772220022976398\n",
      "Epoch: 4/5, Loss: 0.015207765623927116\n",
      "Epoch: 4/5, Loss: 0.0052121784538030624\n",
      "Epoch: 4/5, Loss: 0.018864430487155914\n",
      "Epoch: 4/5, Loss: 0.05354326218366623\n",
      "Epoch: 4/5, Loss: 0.011835254728794098\n",
      "Epoch: 4/5, Loss: 0.01249496266245842\n",
      "Epoch: 4/5, Loss: 0.010973215103149414\n",
      "Epoch: 4/5, Loss: 0.027597488835453987\n",
      "Epoch: 4/5, Loss: 0.025736408308148384\n",
      "Epoch: 4/5, Loss: 0.0029112985357642174\n",
      "Epoch: 4/5, Loss: 0.012973446398973465\n",
      "Epoch: 4/5, Loss: 0.0061731962487101555\n",
      "Epoch: 4/5, Loss: 0.021564122289419174\n",
      "Epoch: 4/5, Loss: 0.07026252150535583\n",
      "Epoch: 4/5, Loss: 0.013068466447293758\n",
      "Epoch: 4/5, Loss: 0.02909942716360092\n",
      "Epoch: 4/5, Loss: 0.011362900957465172\n",
      "Epoch: 4/5, Loss: 0.03847669064998627\n",
      "Epoch: 4/5, Loss: 0.0485776923596859\n",
      "Epoch: 4/5, Loss: 0.006681323517113924\n",
      "Epoch: 4/5, Loss: 0.015846680849790573\n",
      "Epoch: 4/5, Loss: 0.014953142032027245\n",
      "Epoch: 4/5, Loss: 0.00971866212785244\n",
      "Epoch: 4/5, Loss: 0.03358714282512665\n",
      "Epoch: 4/5, Loss: 0.008010397665202618\n",
      "Epoch: 4/5, Loss: 0.01297684758901596\n",
      "Epoch: 4/5, Loss: 0.016287174075841904\n",
      "Epoch: 4/5, Loss: 0.043882694095373154\n",
      "Epoch: 4/5, Loss: 0.0031218677759170532\n",
      "Epoch: 4/5, Loss: 0.015013463795185089\n",
      "Epoch: 4/5, Loss: 0.00660853972658515\n",
      "Epoch: 4/5, Loss: 0.03255856782197952\n",
      "Epoch: 4/5, Loss: 0.01081174984574318\n",
      "Epoch: 4/5, Loss: 0.055059079080820084\n",
      "Epoch: 4/5, Loss: 0.0011181229492649436\n",
      "Epoch: 4/5, Loss: 0.016243357211351395\n",
      "Epoch: 4/5, Loss: 0.029130833223462105\n",
      "Epoch: 4/5, Loss: 0.007834075018763542\n",
      "Epoch: 4/5, Loss: 0.01927114650607109\n",
      "Epoch: 4/5, Loss: 0.026718389242887497\n",
      "Epoch: 4/5, Loss: 0.007065172772854567\n",
      "Epoch: 4/5, Loss: 0.033479198813438416\n",
      "Epoch: 4/5, Loss: 0.09681746363639832\n",
      "Epoch: 4/5, Loss: 0.006066866219043732\n",
      "Epoch: 4/5, Loss: 0.03535157069563866\n",
      "Epoch: 4/5, Loss: 0.006294306367635727\n",
      "Epoch: 4/5, Loss: 0.044292550534009933\n",
      "Epoch: 4/5, Loss: 0.017719483003020287\n",
      "Epoch: 4/5, Loss: 0.019860409200191498\n",
      "Epoch: 4/5, Loss: 0.038997549563646317\n",
      "Epoch: 4/5, Loss: 0.06627277284860611\n",
      "Epoch: 4/5, Loss: 0.04426176846027374\n",
      "Epoch: 4/5, Loss: 0.00574132613837719\n",
      "Epoch: 4/5, Loss: 0.0079598817974329\n",
      "Epoch: 4/5, Loss: 0.020101502537727356\n",
      "Epoch: 4/5, Loss: 0.037681952118873596\n",
      "Epoch: 4/5, Loss: 0.0739118829369545\n",
      "Epoch: 4/5, Loss: 0.02925163507461548\n",
      "Epoch: 4/5, Loss: 0.007578974589705467\n",
      "Epoch: 4/5, Loss: 0.009603079408407211\n",
      "Epoch: 4/5, Loss: 0.026801154017448425\n",
      "Epoch: 4/5, Loss: 0.04298607259988785\n",
      "Epoch: 4/5, Loss: 0.03823767602443695\n",
      "Epoch: 4/5, Loss: 0.00803397223353386\n",
      "Epoch: 4/5, Loss: 0.025805676355957985\n",
      "Epoch: 4/5, Loss: 0.013979765586555004\n",
      "Epoch: 4/5, Loss: 0.01445889100432396\n",
      "Epoch: 4/5, Loss: 0.0028133257292211056\n",
      "Epoch: 4/5, Loss: 0.005114870145916939\n",
      "Epoch: 4/5, Loss: 0.005761238746345043\n",
      "Epoch: 4/5, Loss: 0.02824387513101101\n",
      "Epoch: 4/5, Loss: 0.015332289971411228\n",
      "Epoch: 4/5, Loss: 0.010478636249899864\n",
      "Epoch: 4/5, Loss: 0.06829480081796646\n",
      "Epoch: 4/5, Loss: 0.02234901860356331\n",
      "Epoch: 4/5, Loss: 0.011075802147388458\n",
      "Epoch: 4/5, Loss: 0.02998800203204155\n",
      "Epoch: 4/5, Loss: 0.008605485782027245\n",
      "Epoch: 4/5, Loss: 0.026758145540952682\n",
      "Epoch: 4/5, Loss: 0.01260532345622778\n",
      "Epoch: 4/5, Loss: 0.021639619022607803\n",
      "Epoch: 4/5, Loss: 0.03301585465669632\n",
      "Epoch: 4/5, Loss: 0.029760194942355156\n",
      "Epoch: 4/5, Loss: 0.009374166838824749\n",
      "Epoch: 4/5, Loss: 0.0426584929227829\n",
      "Epoch: 4/5, Loss: 0.0021681240759789944\n",
      "Epoch: 4/5, Loss: 0.010471858084201813\n",
      "Epoch: 4/5, Loss: 0.05163789168000221\n",
      "Epoch: 4/5, Loss: 0.006261770147830248\n",
      "Epoch: 4/5, Loss: 0.031124074012041092\n",
      "Epoch: 4/5, Loss: 0.06555618345737457\n",
      "Epoch: 4/5, Loss: 0.029690945520997047\n",
      "Epoch: 4/5, Loss: 0.008987801149487495\n",
      "Epoch: 4/5, Loss: 0.04899788275361061\n",
      "Epoch: 4/5, Loss: 0.016855869442224503\n",
      "Epoch: 4/5, Loss: 0.0672912448644638\n",
      "Epoch: 4/5, Loss: 0.020544923841953278\n",
      "Epoch: 4/5, Loss: 0.03274073079228401\n",
      "Epoch: 4/5, Loss: 0.009199334308505058\n",
      "Epoch: 4/5, Loss: 0.050357747822999954\n",
      "Epoch: 4/5, Loss: 0.060671284794807434\n",
      "Epoch: 4/5, Loss: 0.00594666413962841\n",
      "Epoch: 4/5, Loss: 0.015623098239302635\n",
      "Epoch: 4/5, Loss: 0.026385823264718056\n",
      "Epoch: 4/5, Loss: 0.007597746327519417\n",
      "Epoch: 4/5, Loss: 0.04485367611050606\n",
      "Epoch: 4/5, Loss: 0.011419985443353653\n",
      "Epoch: 4/5, Loss: 0.06620398163795471\n",
      "Epoch: 4/5, Loss: 0.02803882397711277\n",
      "Epoch: 4/5, Loss: 0.06663671880960464\n",
      "Epoch: 4/5, Loss: 0.0376458615064621\n",
      "Epoch: 4/5, Loss: 0.018389547243714333\n",
      "Epoch: 4/5, Loss: 0.0028035903815180063\n",
      "Epoch: 4/5, Loss: 0.013045835308730602\n",
      "Epoch: 4/5, Loss: 0.03760705143213272\n",
      "Epoch: 4/5, Loss: 0.02541784942150116\n",
      "Epoch: 4/5, Loss: 0.005546792410314083\n",
      "Epoch: 4/5, Loss: 0.005273450165987015\n",
      "Epoch: 4/5, Loss: 0.032291390001773834\n",
      "Epoch: 4/5, Loss: 0.011300517246127129\n",
      "Epoch: 4/5, Loss: 0.01343192532658577\n",
      "Epoch: 4/5, Loss: 0.010412799194455147\n",
      "Epoch: 4/5, Loss: 0.031174689531326294\n",
      "Epoch: 4/5, Loss: 0.015612040646374226\n",
      "Epoch: 4/5, Loss: 0.026149481534957886\n",
      "Epoch: 4/5, Loss: 0.053761981427669525\n",
      "Epoch: 4/5, Loss: 0.009734636172652245\n",
      "Epoch: 4/5, Loss: 0.023669175803661346\n",
      "Epoch: 4/5, Loss: 0.03360560163855553\n",
      "Epoch: 4/5, Loss: 0.03055114485323429\n",
      "Epoch: 4/5, Loss: 0.027288217097520828\n",
      "Epoch: 4/5, Loss: 0.026989798992872238\n",
      "Epoch: 4/5, Loss: 0.016986358910799026\n",
      "Epoch: 4/5, Loss: 0.03558559715747833\n",
      "Epoch: 4/5, Loss: 0.025580286979675293\n",
      "Epoch: 4/5, Loss: 0.007070242892950773\n",
      "Epoch: 4/5, Loss: 0.010584142059087753\n",
      "Epoch: 4/5, Loss: 0.022371303290128708\n",
      "Epoch: 4/5, Loss: 0.013971105217933655\n",
      "Epoch: 4/5, Loss: 0.021362528204917908\n",
      "Epoch: 4/5, Loss: 0.01323741301894188\n",
      "Epoch: 4/5, Loss: 0.036563653498888016\n",
      "Epoch: 4/5, Loss: 0.010536296293139458\n",
      "Epoch: 4/5, Loss: 0.0062241824343800545\n",
      "Epoch: 4/5, Loss: 0.03670015186071396\n",
      "Epoch: 4/5, Loss: 0.010580198839306831\n",
      "Epoch: 4/5, Loss: 0.024847881868481636\n",
      "Epoch: 4/5, Loss: 0.005743809975683689\n",
      "Epoch: 4/5, Loss: 0.016082443296909332\n",
      "Epoch: 4/5, Loss: 0.05267196521162987\n",
      "Epoch: 4/5, Loss: 0.04882999509572983\n",
      "Epoch: 4/5, Loss: 0.006439081393182278\n",
      "Epoch: 4/5, Loss: 0.025741906836628914\n",
      "Epoch: 4/5, Loss: 0.06268054246902466\n",
      "Epoch: 4/5, Loss: 0.028400450944900513\n",
      "Epoch: 4/5, Loss: 0.020471885800361633\n",
      "Epoch: 4/5, Loss: 0.024806000292301178\n",
      "Epoch: 4/5, Loss: 0.01144916657358408\n",
      "Epoch: 4/5, Loss: 0.021763410419225693\n",
      "Epoch: 4/5, Loss: 0.09008917212486267\n",
      "Epoch: 4/5, Loss: 0.009321117773652077\n",
      "Epoch: 4/5, Loss: 0.034199535846710205\n",
      "Epoch: 4/5, Loss: 0.007403579540550709\n",
      "Epoch: 4/5, Loss: 0.12177755683660507\n",
      "Epoch: 4/5, Loss: 0.05963493138551712\n",
      "Epoch: 4/5, Loss: 0.0033500257413834333\n",
      "Epoch: 4/5, Loss: 0.007320741191506386\n",
      "Epoch: 4/5, Loss: 0.005412070546299219\n",
      "Epoch: 4/5, Loss: 0.008283426985144615\n",
      "Epoch: 4/5, Loss: 0.005804852582514286\n",
      "Epoch: 4/5, Loss: 0.05662034451961517\n",
      "Epoch: 4/5, Loss: 0.009774752892553806\n",
      "Epoch: 4/5, Loss: 0.0392751581966877\n",
      "Epoch: 4/5, Loss: 0.0014143986627459526\n",
      "Epoch: 4/5, Loss: 0.01551674585789442\n",
      "Epoch: 4/5, Loss: 0.05241934210062027\n",
      "Epoch: 4/5, Loss: 0.05821448564529419\n",
      "Epoch: 4/5, Loss: 0.008765880018472672\n",
      "Epoch: 4/5, Loss: 0.01305916253477335\n",
      "Epoch: 4/5, Loss: 0.011654035188257694\n",
      "Epoch: 4/5, Loss: 0.015886295586824417\n",
      "Epoch: 4/5, Loss: 0.046091482043266296\n",
      "Epoch: 4/5, Loss: 0.022023260593414307\n",
      "Epoch: 4/5, Loss: 0.0006852146470919251\n",
      "Epoch: 4/5, Loss: 0.04417794942855835\n",
      "Epoch: 4/5, Loss: 0.012388801202178001\n",
      "Epoch: 4/5, Loss: 0.04240782558917999\n",
      "Epoch: 4/5, Loss: 0.07818655669689178\n",
      "Epoch: 4/5, Loss: 0.05108005180954933\n",
      "Epoch: 4/5, Loss: 0.041147518903017044\n",
      "Epoch: 4/5, Loss: 0.026524730026721954\n",
      "Epoch: 4/5, Loss: 0.017386743798851967\n",
      "Epoch: 4/5, Loss: 0.016869276762008667\n",
      "Epoch: 4/5, Loss: 0.008773285895586014\n",
      "Epoch: 4/5, Loss: 0.00970222894102335\n",
      "Epoch: 4/5, Loss: 0.010328186675906181\n",
      "Epoch: 4/5, Loss: 0.012862729839980602\n",
      "Epoch: 4/5, Loss: 0.028215773403644562\n",
      "Epoch: 4/5, Loss: 0.02816060557961464\n",
      "Epoch: 4/5, Loss: 0.029804689809679985\n",
      "Epoch: 4/5, Loss: 0.037104494869709015\n",
      "Epoch: 4/5, Loss: 0.0403798371553421\n",
      "Epoch: 4/5, Loss: 0.01813560165464878\n",
      "Epoch: 4/5, Loss: 0.060228317975997925\n",
      "Epoch: 4/5, Loss: 0.005980722140520811\n",
      "Epoch: 4/5, Loss: 0.018724091351032257\n",
      "Epoch: 4/5, Loss: 0.011371193453669548\n",
      "Epoch: 4/5, Loss: 0.0055968319065868855\n",
      "Epoch: 4/5, Loss: 0.05317088961601257\n",
      "Epoch: 4/5, Loss: 0.02525462582707405\n",
      "Epoch: 4/5, Loss: 0.013331342488527298\n",
      "Epoch: 4/5, Loss: 0.014948599971830845\n",
      "Epoch: 4/5, Loss: 0.007854224182665348\n",
      "Epoch: 4/5, Loss: 0.023318734019994736\n",
      "Epoch: 4/5, Loss: 0.02349887788295746\n",
      "Epoch: 4/5, Loss: 0.025803634896874428\n",
      "Epoch: 4/5, Loss: 0.059292323887348175\n",
      "Epoch: 4/5, Loss: 0.0260524433106184\n",
      "Epoch: 4/5, Loss: 0.03127555921673775\n",
      "Epoch: 4/5, Loss: 0.0186453964561224\n",
      "Epoch: 4/5, Loss: 0.02725428342819214\n",
      "Epoch: 4/5, Loss: 0.011004743166267872\n",
      "Epoch: 4/5, Loss: 0.012606420554220676\n",
      "Epoch: 4/5, Loss: 0.02400967851281166\n",
      "Epoch: 4/5, Loss: 0.02781521901488304\n",
      "Epoch: 4/5, Loss: 0.013142615556716919\n",
      "Epoch: 4/5, Loss: 0.030035115778446198\n",
      "Epoch: 4/5, Loss: 0.024133628234267235\n",
      "Epoch: 4/5, Loss: 0.028205815702676773\n",
      "Epoch: 4/5, Loss: 0.04537680372595787\n",
      "Epoch: 4/5, Loss: 0.008082754909992218\n",
      "Epoch: 4/5, Loss: 0.00842181034386158\n",
      "Epoch: 4/5, Loss: 0.020683588460087776\n",
      "Epoch: 4/5, Loss: 0.03443528711795807\n",
      "Epoch: 4/5, Loss: 0.0052150217816233635\n",
      "Epoch: 4/5, Loss: 0.04264506325125694\n",
      "Epoch: 4/5, Loss: 0.049344077706336975\n",
      "Epoch: 4/5, Loss: 0.0704268217086792\n",
      "Epoch: 4/5, Loss: 0.03937741741538048\n",
      "Epoch: 4/5, Loss: 0.016854407265782356\n",
      "Epoch: 4/5, Loss: 0.007142865564674139\n",
      "Epoch: 4/5, Loss: 0.006856062449514866\n",
      "Epoch: 4/5, Loss: 0.004478262271732092\n",
      "Epoch: 4/5, Loss: 0.03193933144211769\n",
      "Epoch: 4/5, Loss: 0.07323785871267319\n",
      "Epoch: 4/5, Loss: 0.050503920763731\n",
      "Epoch: 4/5, Loss: 0.022361859679222107\n",
      "Epoch: 4/5, Loss: 0.01891191676259041\n",
      "Epoch: 4/5, Loss: 0.11374974995851517\n",
      "Epoch: 4/5, Loss: 0.051187533885240555\n",
      "Epoch: 4/5, Loss: 0.024742111563682556\n",
      "Epoch: 4/5, Loss: 0.010519181378185749\n",
      "Epoch: 4/5, Loss: 0.03338804095983505\n",
      "Epoch: 4/5, Loss: 0.0015238970518112183\n",
      "Epoch: 4/5, Loss: 0.027112482115626335\n",
      "Epoch: 4/5, Loss: 0.007728454191237688\n",
      "Epoch: 4/5, Loss: 0.02755304053425789\n",
      "Epoch: 4/5, Loss: 0.008926796726882458\n",
      "Epoch: 4/5, Loss: 0.006350678391754627\n",
      "Epoch: 4/5, Loss: 0.008394061587750912\n",
      "Epoch: 4/5, Loss: 0.0062586357817053795\n",
      "Epoch: 4/5, Loss: 0.016164395958185196\n",
      "Epoch: 4/5, Loss: 0.0021814722567796707\n",
      "Epoch: 4/5, Loss: 0.043048325926065445\n",
      "Epoch: 4/5, Loss: 0.03127386048436165\n",
      "Epoch: 4/5, Loss: 0.01872529461979866\n",
      "Epoch: 4/5, Loss: 0.023998670279979706\n",
      "Epoch: 4/5, Loss: 0.031271129846572876\n",
      "Epoch: 4/5, Loss: 0.06774547696113586\n",
      "Epoch: 4/5, Loss: 0.02338971570134163\n",
      "Epoch: 4/5, Loss: 0.024135127663612366\n",
      "Epoch: 4/5, Loss: 0.026022734120488167\n",
      "Epoch: 4/5, Loss: 0.009400563314557076\n",
      "Epoch: 4/5, Loss: 0.009690792299807072\n",
      "Epoch: 4/5, Loss: 0.032713890075683594\n",
      "Epoch: 4/5, Loss: 0.041586749255657196\n",
      "Epoch: 4/5, Loss: 0.006766569800674915\n",
      "Epoch: 4/5, Loss: 0.038972944021224976\n",
      "Epoch: 4/5, Loss: 0.002312451135367155\n",
      "Epoch: 4/5, Loss: 0.023446423932909966\n",
      "Epoch: 4/5, Loss: 0.004959177225828171\n",
      "Epoch: 4/5, Loss: 0.01322818361222744\n",
      "Epoch: 4/5, Loss: 0.021711818873882294\n",
      "Epoch: 4/5, Loss: 0.008365003392100334\n",
      "Epoch: 4/5, Loss: 0.04383440315723419\n",
      "Epoch: 4/5, Loss: 0.015577954240143299\n",
      "Epoch: 4/5, Loss: 0.020517727360129356\n",
      "Epoch: 4/5, Loss: 0.014300174079835415\n",
      "Epoch: 4/5, Loss: 0.03700435534119606\n",
      "Epoch: 4/5, Loss: 0.013219354674220085\n",
      "Epoch: 4/5, Loss: 0.01983381062746048\n",
      "Epoch: 4/5, Loss: 0.01731056347489357\n",
      "Epoch: 4/5, Loss: 0.01779901050031185\n",
      "Epoch: 4/5, Loss: 0.08533523231744766\n",
      "Epoch: 4/5, Loss: 0.03301794454455376\n",
      "Epoch: 4/5, Loss: 0.014051804319024086\n",
      "Epoch: 4/5, Loss: 0.005704154260456562\n",
      "Epoch: 4/5, Loss: 0.02747809886932373\n",
      "Epoch: 4/5, Loss: 0.03120623156428337\n",
      "Epoch: 4/5, Loss: 0.1442500203847885\n",
      "Epoch: 4/5, Loss: 0.0103323208168149\n",
      "Epoch: 4/5, Loss: 0.016826163977384567\n",
      "Epoch: 4/5, Loss: 0.028519101440906525\n",
      "Epoch: 4/5, Loss: 0.08121190220117569\n",
      "Epoch: 4/5, Loss: 0.033050958067178726\n",
      "Epoch: 4/5, Loss: 0.07988336682319641\n",
      "Epoch: 4/5, Loss: 0.004880082327872515\n",
      "Epoch: 4/5, Loss: 0.0055768731981515884\n",
      "Epoch: 4/5, Loss: 0.0033345497213304043\n",
      "Epoch: 4/5, Loss: 0.04505332559347153\n",
      "Epoch: 4/5, Loss: 0.04117535427212715\n",
      "Epoch: 4/5, Loss: 0.024360833689570427\n",
      "Epoch: 4/5, Loss: 0.03681940212845802\n",
      "Epoch: 4/5, Loss: 0.04219461977481842\n",
      "Epoch: 4/5, Loss: 0.004311389289796352\n",
      "Epoch: 4/5, Loss: 0.040186453610658646\n",
      "Epoch: 4/5, Loss: 0.04053126648068428\n",
      "Epoch: 4/5, Loss: 0.018293026834726334\n",
      "Epoch: 4/5, Loss: 0.04003722220659256\n",
      "Epoch: 4/5, Loss: 0.013210357166826725\n",
      "Epoch: 4/5, Loss: 0.021736079826951027\n",
      "Epoch: 4/5, Loss: 0.013844423927366734\n",
      "Epoch: 4/5, Loss: 0.038515590131282806\n",
      "Epoch: 4/5, Loss: 0.011141291819512844\n",
      "Epoch: 4/5, Loss: 0.08673708140850067\n",
      "Epoch: 4/5, Loss: 0.015562565065920353\n",
      "Epoch: 4/5, Loss: 0.02932848036289215\n",
      "Epoch: 4/5, Loss: 0.021883290261030197\n",
      "Epoch: 4/5, Loss: 0.0018019722774624825\n",
      "Epoch: 4/5, Loss: 0.018193593248724937\n",
      "Epoch: 4/5, Loss: 0.027829861268401146\n",
      "Epoch: 4/5, Loss: 0.007376299239695072\n",
      "Epoch: 4/5, Loss: 0.04739907383918762\n",
      "Epoch: 4/5, Loss: 0.016945844516158104\n",
      "Epoch: 4/5, Loss: 0.027317233383655548\n",
      "Epoch: 4/5, Loss: 0.011861151084303856\n",
      "Epoch: 4/5, Loss: 0.032573189586400986\n",
      "Epoch: 4/5, Loss: 0.035456154495477676\n",
      "Epoch: 4/5, Loss: 0.009896674193441868\n",
      "Epoch: 4/5, Loss: 0.03775273635983467\n",
      "Epoch: 4/5, Loss: 0.005139289423823357\n",
      "Epoch: 4/5, Loss: 0.05262068286538124\n",
      "Epoch: 4/5, Loss: 0.00809453334659338\n",
      "Epoch: 4/5, Loss: 0.03904343396425247\n",
      "Epoch: 4/5, Loss: 0.006011645309627056\n",
      "Epoch: 4/5, Loss: 0.03474671393632889\n",
      "Epoch: 4/5, Loss: 0.06985101103782654\n",
      "Epoch: 4/5, Loss: 0.01107325591146946\n",
      "Epoch: 4/5, Loss: 0.006882563233375549\n",
      "Epoch: 4/5, Loss: 0.024204855784773827\n",
      "Epoch: 4/5, Loss: 0.02324383147060871\n",
      "Epoch: 4/5, Loss: 0.005403743591159582\n",
      "Epoch: 4/5, Loss: 0.011012550443410873\n",
      "Epoch: 4/5, Loss: 0.022758595645427704\n",
      "Epoch: 4/5, Loss: 0.04596753418445587\n",
      "Epoch: 4/5, Loss: 0.01174497976899147\n",
      "Epoch: 4/5, Loss: 0.014015885069966316\n",
      "Epoch: 4/5, Loss: 0.037131600081920624\n",
      "Epoch: 4/5, Loss: 0.006277073174715042\n",
      "Epoch: 4/5, Loss: 0.025770101696252823\n",
      "Epoch: 4/5, Loss: 0.018190689384937286\n",
      "Epoch: 4/5, Loss: 0.0005174190155230463\n",
      "Epoch: 4/5, Loss: 0.005854897201061249\n",
      "Epoch: 4/5, Loss: 0.00845063105225563\n",
      "Epoch: 4/5, Loss: 0.012659278698265553\n",
      "Epoch: 4/5, Loss: 0.036586642265319824\n",
      "Epoch: 4/5, Loss: 0.022466961294412613\n",
      "Epoch: 4/5, Loss: 0.02530907839536667\n",
      "Epoch: 4/5, Loss: 0.03290990740060806\n",
      "Epoch: 4/5, Loss: 0.006449433043599129\n",
      "Epoch: 4/5, Loss: 0.003496839664876461\n",
      "Epoch: 4/5, Loss: 0.01193690299987793\n",
      "Epoch: 4/5, Loss: 0.026686007156968117\n",
      "Epoch: 4/5, Loss: 0.02820613421499729\n",
      "Epoch: 4/5, Loss: 0.022130263969302177\n",
      "Epoch: 4/5, Loss: 0.002571025164797902\n",
      "Epoch: 4/5, Loss: 0.030827272683382034\n",
      "Epoch: 4/5, Loss: 0.007042144425213337\n",
      "Epoch: 4/5, Loss: 0.013178437948226929\n",
      "Epoch: 4/5, Loss: 0.02130243182182312\n",
      "Epoch: 4/5, Loss: 0.029795601963996887\n",
      "Epoch: 4/5, Loss: 0.016705069690942764\n",
      "Epoch: 4/5, Loss: 0.022556453943252563\n",
      "Epoch: 4/5, Loss: 0.017779741436243057\n",
      "Epoch: 4/5, Loss: 0.007428914308547974\n",
      "Epoch: 4/5, Loss: 0.012296083383262157\n",
      "Epoch: 4/5, Loss: 0.03445105627179146\n",
      "Epoch: 4/5, Loss: 0.04252094030380249\n",
      "Epoch: 4/5, Loss: 0.01148061640560627\n",
      "Epoch: 4/5, Loss: 0.0029255019035190344\n",
      "Epoch: 4/5, Loss: 0.02920888550579548\n",
      "Epoch: 4/5, Loss: 0.011019892059266567\n",
      "Epoch: 4/5, Loss: 0.0318722277879715\n",
      "Epoch: 4/5, Loss: 0.002580487634986639\n",
      "Epoch: 4/5, Loss: 0.01996995508670807\n",
      "Epoch: 4/5, Loss: 0.02525443583726883\n",
      "Epoch: 4/5, Loss: 0.025204742327332497\n",
      "Epoch: 4/5, Loss: 0.02803841605782509\n",
      "Epoch: 4/5, Loss: 0.019651710987091064\n",
      "Epoch: 4/5, Loss: 0.027422111481428146\n",
      "Epoch: 4/5, Loss: 0.024158740416169167\n",
      "Epoch: 4/5, Loss: 0.021616946905851364\n",
      "Epoch: 4/5, Loss: 0.02592899091541767\n",
      "Epoch: 4/5, Loss: 0.012759056873619556\n",
      "Epoch: 4/5, Loss: 0.009902267716825008\n",
      "Epoch: 4/5, Loss: 0.007515267468988895\n",
      "Epoch: 4/5, Loss: 0.0023307609371840954\n",
      "Epoch: 4/5, Loss: 0.008086522109806538\n",
      "Epoch: 4/5, Loss: 0.05691643804311752\n",
      "Epoch: 4/5, Loss: 0.051254719495773315\n",
      "Epoch: 4/5, Loss: 0.007871080189943314\n",
      "Epoch: 4/5, Loss: 0.013584334403276443\n",
      "Epoch: 4/5, Loss: 0.014733860269188881\n",
      "Epoch: 4/5, Loss: 0.02109145186841488\n",
      "Epoch: 4/5, Loss: 0.012351017445325851\n",
      "Epoch: 4/5, Loss: 0.015597854740917683\n",
      "Epoch: 4/5, Loss: 0.0020349440164864063\n",
      "Epoch: 4/5, Loss: 0.03260288015007973\n",
      "Epoch: 4/5, Loss: 0.022866664454340935\n",
      "Epoch: 4/5, Loss: 0.027003198862075806\n",
      "Epoch: 4/5, Loss: 0.020367491990327835\n",
      "Epoch: 4/5, Loss: 0.006889710668474436\n",
      "Epoch: 4/5, Loss: 0.011096347123384476\n",
      "Epoch: 4/5, Loss: 0.008559012785553932\n",
      "Epoch: 4/5, Loss: 0.012928629294037819\n",
      "Epoch: 4/5, Loss: 0.002211465500295162\n",
      "Epoch: 4/5, Loss: 0.047773972153663635\n",
      "Epoch: 4/5, Loss: 0.013628746382892132\n",
      "Epoch: 4/5, Loss: 0.03130344673991203\n",
      "Epoch: 4/5, Loss: 0.005278228782117367\n",
      "Epoch: 4/5, Loss: 0.010503441095352173\n",
      "Epoch: 4/5, Loss: 0.02471821941435337\n",
      "Epoch: 4/5, Loss: 0.014875911176204681\n",
      "Epoch: 4/5, Loss: 0.012704930268228054\n",
      "Epoch: 4/5, Loss: 0.0077239591628313065\n",
      "Epoch: 4/5, Loss: 0.0079432912170887\n",
      "Epoch: 4/5, Loss: 0.020059192553162575\n",
      "Epoch: 4/5, Loss: 0.020010702311992645\n",
      "Epoch: 4/5, Loss: 0.012284895405173302\n",
      "Epoch: 4/5, Loss: 0.031149303540587425\n",
      "Epoch: 4/5, Loss: 0.011384258046746254\n",
      "Epoch: 4/5, Loss: 0.005614364519715309\n",
      "Epoch: 4/5, Loss: 0.012452634051442146\n",
      "Epoch: 4/5, Loss: 0.04513835161924362\n",
      "Epoch: 4/5, Loss: 0.028180981054902077\n",
      "Epoch: 4/5, Loss: 0.007625439204275608\n",
      "Epoch: 4/5, Loss: 0.03841302916407585\n",
      "Epoch: 4/5, Loss: 0.013861606828868389\n",
      "Epoch: 4/5, Loss: 0.05604717880487442\n",
      "Epoch: 4/5, Loss: 0.010442697443068027\n",
      "Epoch: 4/5, Loss: 0.012926417402923107\n",
      "Epoch: 4/5, Loss: 0.023249397054314613\n",
      "Epoch: 4/5, Loss: 0.013783474452793598\n",
      "Epoch: 4/5, Loss: 0.021633531898260117\n",
      "Epoch: 4/5, Loss: 0.023569494485855103\n",
      "Epoch: 4/5, Loss: 0.02345750853419304\n",
      "Epoch: 4/5, Loss: 0.004507255740463734\n",
      "Epoch: 4/5, Loss: 0.030335623770952225\n",
      "Epoch: 4/5, Loss: 0.06696482747793198\n",
      "Epoch: 4/5, Loss: 0.019497539848089218\n",
      "Epoch: 4/5, Loss: 0.019105149433016777\n",
      "Epoch: 4/5, Loss: 0.003317544935271144\n",
      "Epoch: 4/5, Loss: 0.023250075057148933\n",
      "Epoch: 4/5, Loss: 0.019493907690048218\n",
      "Epoch: 4/5, Loss: 0.015752116218209267\n",
      "Epoch: 4/5, Loss: 0.006508733611553907\n",
      "Epoch: 4/5, Loss: 0.04166200011968613\n",
      "Epoch: 4/5, Loss: 0.046228159219026566\n",
      "Epoch: 4/5, Loss: 0.03601960092782974\n",
      "Epoch: 4/5, Loss: 0.0475628487765789\n",
      "Epoch: 4/5, Loss: 0.013388870283961296\n",
      "Epoch: 4/5, Loss: 0.03389456123113632\n",
      "Epoch: 4/5, Loss: 0.026703888550400734\n",
      "Epoch: 4/5, Loss: 0.009611890651285648\n",
      "Epoch: 4/5, Loss: 0.02483217790722847\n",
      "Epoch: 4/5, Loss: 0.005190979223698378\n",
      "Epoch: 4/5, Loss: 0.001260885619558394\n",
      "Epoch: 4/5, Loss: 0.028924554586410522\n",
      "Epoch: 4/5, Loss: 0.01104834582656622\n",
      "Epoch: 4/5, Loss: 0.015573743730783463\n",
      "Epoch: 4/5, Loss: 0.004412037320435047\n",
      "Epoch: 4/5, Loss: 0.016838766634464264\n",
      "Epoch: 4/5, Loss: 0.013727687299251556\n",
      "Epoch: 4/5, Loss: 0.10061284154653549\n",
      "Epoch: 4/5, Loss: 0.0027619122993201017\n",
      "Epoch: 4/5, Loss: 0.006249189842492342\n",
      "Epoch: 4/5, Loss: 0.04134473577141762\n",
      "Epoch: 4/5, Loss: 0.0032810342963784933\n",
      "Epoch: 4/5, Loss: 0.007519228383898735\n",
      "Epoch: 4/5, Loss: 0.03401646018028259\n",
      "Epoch: 4/5, Loss: 0.030331507325172424\n",
      "Epoch: 4/5, Loss: 0.025467101484537125\n",
      "Epoch: 4/5, Loss: 0.08822213113307953\n",
      "Epoch: 4/5, Loss: 0.026307685300707817\n",
      "Epoch: 5/5, Loss: 0.01420750841498375\n",
      "Epoch: 5/5, Loss: 0.0039071738719940186\n",
      "Epoch: 5/5, Loss: 0.034245848655700684\n",
      "Epoch: 5/5, Loss: 0.020078623667359352\n",
      "Epoch: 5/5, Loss: 0.012299471534788609\n",
      "Epoch: 5/5, Loss: 0.045480385422706604\n",
      "Epoch: 5/5, Loss: 0.005923029500991106\n",
      "Epoch: 5/5, Loss: 0.0219749566167593\n",
      "Epoch: 5/5, Loss: 0.01367112435400486\n",
      "Epoch: 5/5, Loss: 0.0033933513332158327\n",
      "Epoch: 5/5, Loss: 0.005346130579710007\n",
      "Epoch: 5/5, Loss: 0.006034442223608494\n",
      "Epoch: 5/5, Loss: 0.0032587661407887936\n",
      "Epoch: 5/5, Loss: 0.02698020450770855\n",
      "Epoch: 5/5, Loss: 0.03358074650168419\n",
      "Epoch: 5/5, Loss: 0.012491108849644661\n",
      "Epoch: 5/5, Loss: 0.05485246703028679\n",
      "Epoch: 5/5, Loss: 0.04268474504351616\n",
      "Epoch: 5/5, Loss: 0.02947491966187954\n",
      "Epoch: 5/5, Loss: 0.06200766563415527\n",
      "Epoch: 5/5, Loss: 0.032305870205163956\n",
      "Epoch: 5/5, Loss: 0.016698496416211128\n",
      "Epoch: 5/5, Loss: 0.018467597663402557\n",
      "Epoch: 5/5, Loss: 0.006085582077503204\n",
      "Epoch: 5/5, Loss: 0.010950954630970955\n",
      "Epoch: 5/5, Loss: 0.033489976078271866\n",
      "Epoch: 5/5, Loss: 0.035491909831762314\n",
      "Epoch: 5/5, Loss: 0.04480290412902832\n",
      "Epoch: 5/5, Loss: 0.027253935113549232\n",
      "Epoch: 5/5, Loss: 0.010610897094011307\n",
      "Epoch: 5/5, Loss: 0.05996610224246979\n",
      "Epoch: 5/5, Loss: 0.02485862374305725\n",
      "Epoch: 5/5, Loss: 0.012313101440668106\n",
      "Epoch: 5/5, Loss: 0.007921398617327213\n",
      "Epoch: 5/5, Loss: 0.013709879480302334\n",
      "Epoch: 5/5, Loss: 0.009186713956296444\n",
      "Epoch: 5/5, Loss: 0.02260849066078663\n",
      "Epoch: 5/5, Loss: 0.01897374540567398\n",
      "Epoch: 5/5, Loss: 0.02250550501048565\n",
      "Epoch: 5/5, Loss: 0.024774378165602684\n",
      "Epoch: 5/5, Loss: 0.02738167718052864\n",
      "Epoch: 5/5, Loss: 0.02406131476163864\n",
      "Epoch: 5/5, Loss: 0.039213962852954865\n",
      "Epoch: 5/5, Loss: 0.00547347217798233\n",
      "Epoch: 5/5, Loss: 0.032361991703510284\n",
      "Epoch: 5/5, Loss: 0.021479308605194092\n",
      "Epoch: 5/5, Loss: 0.010194162838160992\n",
      "Epoch: 5/5, Loss: 0.003547190921381116\n",
      "Epoch: 5/5, Loss: 0.025598974898457527\n",
      "Epoch: 5/5, Loss: 0.005094117484986782\n",
      "Epoch: 5/5, Loss: 0.00522090308368206\n",
      "Epoch: 5/5, Loss: 0.029730672016739845\n",
      "Epoch: 5/5, Loss: 0.010558893904089928\n",
      "Epoch: 5/5, Loss: 0.05307559669017792\n",
      "Epoch: 5/5, Loss: 0.0009686345001682639\n",
      "Epoch: 5/5, Loss: 0.016659094020724297\n",
      "Epoch: 5/5, Loss: 0.009219280444085598\n",
      "Epoch: 5/5, Loss: 0.01123738568276167\n",
      "Epoch: 5/5, Loss: 0.025026854127645493\n",
      "Epoch: 5/5, Loss: 0.006786084268242121\n",
      "Epoch: 5/5, Loss: 0.06705276668071747\n",
      "Epoch: 5/5, Loss: 0.01591525971889496\n",
      "Epoch: 5/5, Loss: 0.03917326405644417\n",
      "Epoch: 5/5, Loss: 0.01999690942466259\n",
      "Epoch: 5/5, Loss: 0.03513878583908081\n",
      "Epoch: 5/5, Loss: 0.013391652144491673\n",
      "Epoch: 5/5, Loss: 0.03375878185033798\n",
      "Epoch: 5/5, Loss: 0.015011435374617577\n",
      "Epoch: 5/5, Loss: 0.021537795662879944\n",
      "Epoch: 5/5, Loss: 0.021017979830503464\n",
      "Epoch: 5/5, Loss: 0.015230663120746613\n",
      "Epoch: 5/5, Loss: 0.004843252245336771\n",
      "Epoch: 5/5, Loss: 0.057255424559116364\n",
      "Epoch: 5/5, Loss: 0.016386892646551132\n",
      "Epoch: 5/5, Loss: 0.002974203322082758\n",
      "Epoch: 5/5, Loss: 0.010678747668862343\n",
      "Epoch: 5/5, Loss: 0.0066960277035832405\n",
      "Epoch: 5/5, Loss: 0.016778919845819473\n",
      "Epoch: 5/5, Loss: 0.0281966719776392\n",
      "Epoch: 5/5, Loss: 0.0028232720214873552\n",
      "Epoch: 5/5, Loss: 0.018794862553477287\n",
      "Epoch: 5/5, Loss: 0.01562648080289364\n",
      "Epoch: 5/5, Loss: 0.004215583670884371\n",
      "Epoch: 5/5, Loss: 0.01434146799147129\n",
      "Epoch: 5/5, Loss: 0.035380877554416656\n",
      "Epoch: 5/5, Loss: 0.044062454253435135\n",
      "Epoch: 5/5, Loss: 0.011789495125412941\n",
      "Epoch: 5/5, Loss: 0.009168999269604683\n",
      "Epoch: 5/5, Loss: 0.03238722309470177\n",
      "Epoch: 5/5, Loss: 0.0016153671313077211\n",
      "Epoch: 5/5, Loss: 0.013344185426831245\n",
      "Epoch: 5/5, Loss: 0.05213063955307007\n",
      "Epoch: 5/5, Loss: 0.030505258589982986\n",
      "Epoch: 5/5, Loss: 0.015561905689537525\n",
      "Epoch: 5/5, Loss: 0.012275302782654762\n",
      "Epoch: 5/5, Loss: 0.005618679337203503\n",
      "Epoch: 5/5, Loss: 0.018638040870428085\n",
      "Epoch: 5/5, Loss: 0.030167555436491966\n",
      "Epoch: 5/5, Loss: 0.03236209973692894\n",
      "Epoch: 5/5, Loss: 0.027570705860853195\n",
      "Epoch: 5/5, Loss: 0.0322202630341053\n",
      "Epoch: 5/5, Loss: 0.020351091399788857\n",
      "Epoch: 5/5, Loss: 0.012994910590350628\n",
      "Epoch: 5/5, Loss: 0.03606053441762924\n",
      "Epoch: 5/5, Loss: 0.002914403099566698\n",
      "Epoch: 5/5, Loss: 0.008713169023394585\n",
      "Epoch: 5/5, Loss: 0.0028555230237543583\n",
      "Epoch: 5/5, Loss: 0.016043372452259064\n",
      "Epoch: 5/5, Loss: 0.03146317973732948\n",
      "Epoch: 5/5, Loss: 0.01951494999229908\n",
      "Epoch: 5/5, Loss: 0.009483876638114452\n",
      "Epoch: 5/5, Loss: 0.04741417616605759\n",
      "Epoch: 5/5, Loss: 0.0073189823888242245\n",
      "Epoch: 5/5, Loss: 0.013889596797525883\n",
      "Epoch: 5/5, Loss: 0.007905155420303345\n",
      "Epoch: 5/5, Loss: 0.06306961178779602\n",
      "Epoch: 5/5, Loss: 0.021971432492136955\n",
      "Epoch: 5/5, Loss: 0.005318641196936369\n",
      "Epoch: 5/5, Loss: 0.05718773230910301\n",
      "Epoch: 5/5, Loss: 0.05309036746621132\n",
      "Epoch: 5/5, Loss: 0.03196180239319801\n",
      "Epoch: 5/5, Loss: 0.01687244325876236\n",
      "Epoch: 5/5, Loss: 0.02894560806453228\n",
      "Epoch: 5/5, Loss: 0.04208388552069664\n",
      "Epoch: 5/5, Loss: 0.009124028496444225\n",
      "Epoch: 5/5, Loss: 0.015169033780694008\n",
      "Epoch: 5/5, Loss: 0.02592017687857151\n",
      "Epoch: 5/5, Loss: 0.0034982587676495314\n",
      "Epoch: 5/5, Loss: 0.01640116237103939\n",
      "Epoch: 5/5, Loss: 0.004926330875605345\n",
      "Epoch: 5/5, Loss: 0.012083545327186584\n",
      "Epoch: 5/5, Loss: 0.041907891631126404\n",
      "Epoch: 5/5, Loss: 0.006802727468311787\n",
      "Epoch: 5/5, Loss: 0.04201427102088928\n",
      "Epoch: 5/5, Loss: 0.022073129191994667\n",
      "Epoch: 5/5, Loss: 0.05085913836956024\n",
      "Epoch: 5/5, Loss: 0.025531353428959846\n",
      "Epoch: 5/5, Loss: 0.05216744542121887\n",
      "Epoch: 5/5, Loss: 0.1161394789814949\n",
      "Epoch: 5/5, Loss: 0.019802425056695938\n",
      "Epoch: 5/5, Loss: 0.006371535826474428\n",
      "Epoch: 5/5, Loss: 0.0022631913889199495\n",
      "Epoch: 5/5, Loss: 0.029595322906970978\n",
      "Epoch: 5/5, Loss: 0.029874389991164207\n",
      "Epoch: 5/5, Loss: 0.05664455518126488\n",
      "Epoch: 5/5, Loss: 0.02374444529414177\n",
      "Epoch: 5/5, Loss: 0.033883243799209595\n",
      "Epoch: 5/5, Loss: 0.01235966943204403\n",
      "Epoch: 5/5, Loss: 0.025399304926395416\n",
      "Epoch: 5/5, Loss: 0.022263340651988983\n",
      "Epoch: 5/5, Loss: 0.02526029758155346\n",
      "Epoch: 5/5, Loss: 0.002591927768662572\n",
      "Epoch: 5/5, Loss: 0.009757524356245995\n",
      "Epoch: 5/5, Loss: 0.025911089032888412\n",
      "Epoch: 5/5, Loss: 0.00431239465251565\n",
      "Epoch: 5/5, Loss: 0.02012021094560623\n",
      "Epoch: 5/5, Loss: 0.04467114433646202\n",
      "Epoch: 5/5, Loss: 0.03455142676830292\n",
      "Epoch: 5/5, Loss: 0.005676385015249252\n",
      "Epoch: 5/5, Loss: 0.011602160520851612\n",
      "Epoch: 5/5, Loss: 0.00572943314909935\n",
      "Epoch: 5/5, Loss: 0.034992631524801254\n",
      "Epoch: 5/5, Loss: 0.018888486549258232\n",
      "Epoch: 5/5, Loss: 0.03807532787322998\n",
      "Epoch: 5/5, Loss: 0.004290116019546986\n",
      "Epoch: 5/5, Loss: 0.011498991400003433\n",
      "Epoch: 5/5, Loss: 0.007846779190003872\n",
      "Epoch: 5/5, Loss: 0.023955006152391434\n",
      "Epoch: 5/5, Loss: 0.015266276895999908\n",
      "Epoch: 5/5, Loss: 0.016982754692435265\n",
      "Epoch: 5/5, Loss: 0.013119841925799847\n",
      "Epoch: 5/5, Loss: 0.03436541184782982\n",
      "Epoch: 5/5, Loss: 0.03643878921866417\n",
      "Epoch: 5/5, Loss: 0.005696382839232683\n",
      "Epoch: 5/5, Loss: 0.027182478457689285\n",
      "Epoch: 5/5, Loss: 0.012747346423566341\n",
      "Epoch: 5/5, Loss: 0.02093273401260376\n",
      "Epoch: 5/5, Loss: 0.003698641899973154\n",
      "Epoch: 5/5, Loss: 0.036883290857076645\n",
      "Epoch: 5/5, Loss: 0.012512680143117905\n",
      "Epoch: 5/5, Loss: 0.004266743548214436\n",
      "Epoch: 5/5, Loss: 0.015115102753043175\n",
      "Epoch: 5/5, Loss: 0.009249056689441204\n",
      "Epoch: 5/5, Loss: 0.010010479018092155\n",
      "Epoch: 5/5, Loss: 0.017948931083083153\n",
      "Epoch: 5/5, Loss: 0.018100591376423836\n",
      "Epoch: 5/5, Loss: 0.016548410058021545\n",
      "Epoch: 5/5, Loss: 0.021680466830730438\n",
      "Epoch: 5/5, Loss: 0.018751390278339386\n",
      "Epoch: 5/5, Loss: 0.024623248726129532\n",
      "Epoch: 5/5, Loss: 0.07938773185014725\n",
      "Epoch: 5/5, Loss: 0.010069707408547401\n",
      "Epoch: 5/5, Loss: 0.014828468672931194\n",
      "Epoch: 5/5, Loss: 0.04671502858400345\n",
      "Epoch: 5/5, Loss: 0.03046727553009987\n",
      "Epoch: 5/5, Loss: 0.03265273571014404\n",
      "Epoch: 5/5, Loss: 0.03893469274044037\n",
      "Epoch: 5/5, Loss: 0.004096903372555971\n",
      "Epoch: 5/5, Loss: 0.046575747430324554\n",
      "Epoch: 5/5, Loss: 0.01270188670605421\n",
      "Epoch: 5/5, Loss: 0.022529875859618187\n",
      "Epoch: 5/5, Loss: 0.09426973760128021\n",
      "Epoch: 5/5, Loss: 0.023149710148572922\n",
      "Epoch: 5/5, Loss: 0.010985447093844414\n",
      "Epoch: 5/5, Loss: 0.017952926456928253\n",
      "Epoch: 5/5, Loss: 0.01778835989534855\n",
      "Epoch: 5/5, Loss: 0.03227493166923523\n",
      "Epoch: 5/5, Loss: 0.013311265967786312\n",
      "Epoch: 5/5, Loss: 0.1000969335436821\n",
      "Epoch: 5/5, Loss: 0.0542263425886631\n",
      "Epoch: 5/5, Loss: 0.019537165760993958\n",
      "Epoch: 5/5, Loss: 0.006341380067169666\n",
      "Epoch: 5/5, Loss: 0.012367542833089828\n",
      "Epoch: 5/5, Loss: 0.02419547736644745\n",
      "Epoch: 5/5, Loss: 0.018407823517918587\n",
      "Epoch: 5/5, Loss: 0.005832643248140812\n",
      "Epoch: 5/5, Loss: 0.022493191063404083\n",
      "Epoch: 5/5, Loss: 0.020422842353582382\n",
      "Epoch: 5/5, Loss: 0.025499481707811356\n",
      "Epoch: 5/5, Loss: 0.026373224332928658\n",
      "Epoch: 5/5, Loss: 0.015243086032569408\n",
      "Epoch: 5/5, Loss: 0.027767978608608246\n",
      "Epoch: 5/5, Loss: 0.05396014451980591\n",
      "Epoch: 5/5, Loss: 0.0983046144247055\n",
      "Epoch: 5/5, Loss: 0.02961057797074318\n",
      "Epoch: 5/5, Loss: 0.05875324457883835\n",
      "Epoch: 5/5, Loss: 0.02535775490105152\n",
      "Epoch: 5/5, Loss: 0.03923723101615906\n",
      "Epoch: 5/5, Loss: 0.011094012297689915\n",
      "Epoch: 5/5, Loss: 0.03178565949201584\n",
      "Epoch: 5/5, Loss: 0.033548109233379364\n",
      "Epoch: 5/5, Loss: 0.04776953160762787\n",
      "Epoch: 5/5, Loss: 0.02539750374853611\n",
      "Epoch: 5/5, Loss: 0.04052647203207016\n",
      "Epoch: 5/5, Loss: 0.09265775233507156\n",
      "Epoch: 5/5, Loss: 0.01261000894010067\n",
      "Epoch: 5/5, Loss: 0.012155404314398766\n",
      "Epoch: 5/5, Loss: 0.036332957446575165\n",
      "Epoch: 5/5, Loss: 0.02950497344136238\n",
      "Epoch: 5/5, Loss: 0.01926681399345398\n",
      "Epoch: 5/5, Loss: 0.009869279339909554\n",
      "Epoch: 5/5, Loss: 0.04701177030801773\n",
      "Epoch: 5/5, Loss: 0.010052653960883617\n",
      "Epoch: 5/5, Loss: 0.026601020246744156\n",
      "Epoch: 5/5, Loss: 0.03316234424710274\n",
      "Epoch: 5/5, Loss: 0.027679957449436188\n",
      "Epoch: 5/5, Loss: 0.03682500869035721\n",
      "Epoch: 5/5, Loss: 0.006639682687819004\n",
      "Epoch: 5/5, Loss: 0.05024596303701401\n",
      "Epoch: 5/5, Loss: 0.014246134087443352\n",
      "Epoch: 5/5, Loss: 0.012372730299830437\n",
      "Epoch: 5/5, Loss: 0.006537511944770813\n",
      "Epoch: 5/5, Loss: 0.0027458108961582184\n",
      "Epoch: 5/5, Loss: 0.0035898606292903423\n",
      "Epoch: 5/5, Loss: 0.032843273133039474\n",
      "Epoch: 5/5, Loss: 0.05449681729078293\n",
      "Epoch: 5/5, Loss: 0.00947073008865118\n",
      "Epoch: 5/5, Loss: 0.0108493035659194\n",
      "Epoch: 5/5, Loss: 0.018433790653944016\n",
      "Epoch: 5/5, Loss: 0.011751553043723106\n",
      "Epoch: 5/5, Loss: 0.0023297236766666174\n",
      "Epoch: 5/5, Loss: 0.040553100407123566\n",
      "Epoch: 5/5, Loss: 0.013604190200567245\n",
      "Epoch: 5/5, Loss: 0.03541519492864609\n",
      "Epoch: 5/5, Loss: 0.010085929185152054\n",
      "Epoch: 5/5, Loss: 0.016851700842380524\n",
      "Epoch: 5/5, Loss: 0.06284032762050629\n",
      "Epoch: 5/5, Loss: 0.014697430655360222\n",
      "Epoch: 5/5, Loss: 0.03630254417657852\n",
      "Epoch: 5/5, Loss: 0.0044646798633039\n",
      "Epoch: 5/5, Loss: 0.003173401113599539\n",
      "Epoch: 5/5, Loss: 0.009716587141156197\n",
      "Epoch: 5/5, Loss: 0.03715737536549568\n",
      "Epoch: 5/5, Loss: 0.008900079876184464\n",
      "Epoch: 5/5, Loss: 0.0278394166380167\n",
      "Epoch: 5/5, Loss: 0.004711349494755268\n",
      "Epoch: 5/5, Loss: 0.00860061589628458\n",
      "Epoch: 5/5, Loss: 0.012785807251930237\n",
      "Epoch: 5/5, Loss: 0.011392255313694477\n",
      "Epoch: 5/5, Loss: 0.007157973945140839\n",
      "Epoch: 5/5, Loss: 0.012942327186465263\n",
      "Epoch: 5/5, Loss: 0.016221478581428528\n",
      "Epoch: 5/5, Loss: 0.017712721601128578\n",
      "Epoch: 5/5, Loss: 0.024931974709033966\n",
      "Epoch: 5/5, Loss: 0.01849641278386116\n",
      "Epoch: 5/5, Loss: 0.0035390290431678295\n",
      "Epoch: 5/5, Loss: 0.007421832997351885\n",
      "Epoch: 5/5, Loss: 0.029457248747348785\n",
      "Epoch: 5/5, Loss: 0.013095931150019169\n",
      "Epoch: 5/5, Loss: 0.017867757007479668\n",
      "Epoch: 5/5, Loss: 0.01048702746629715\n",
      "Epoch: 5/5, Loss: 0.014725734479725361\n",
      "Epoch: 5/5, Loss: 0.043788909912109375\n",
      "Epoch: 5/5, Loss: 0.006307315081357956\n",
      "Epoch: 5/5, Loss: 0.04908866807818413\n",
      "Epoch: 5/5, Loss: 0.044033121317625046\n",
      "Epoch: 5/5, Loss: 0.024511858820915222\n",
      "Epoch: 5/5, Loss: 0.02375406213104725\n",
      "Epoch: 5/5, Loss: 0.025676600635051727\n",
      "Epoch: 5/5, Loss: 0.01767975278198719\n",
      "Epoch: 5/5, Loss: 0.030342258512973785\n",
      "Epoch: 5/5, Loss: 0.050369229167699814\n",
      "Epoch: 5/5, Loss: 0.023865124210715294\n",
      "Epoch: 5/5, Loss: 0.010141018778085709\n",
      "Epoch: 5/5, Loss: 0.014977519400417805\n",
      "Epoch: 5/5, Loss: 0.001918167108669877\n",
      "Epoch: 5/5, Loss: 0.004175626672804356\n",
      "Epoch: 5/5, Loss: 0.006787404417991638\n",
      "Epoch: 5/5, Loss: 0.042364075779914856\n",
      "Epoch: 5/5, Loss: 0.03736341744661331\n",
      "Epoch: 5/5, Loss: 0.010171704925596714\n",
      "Epoch: 5/5, Loss: 0.04600132256746292\n",
      "Epoch: 5/5, Loss: 0.02747422643005848\n",
      "Epoch: 5/5, Loss: 0.004532193765044212\n",
      "Epoch: 5/5, Loss: 0.0839642658829689\n",
      "Epoch: 5/5, Loss: 0.027165833860635757\n",
      "Epoch: 5/5, Loss: 0.03602262958884239\n",
      "Epoch: 5/5, Loss: 0.009863128885626793\n",
      "Epoch: 5/5, Loss: 0.05518272891640663\n",
      "Epoch: 5/5, Loss: 0.024395737797021866\n",
      "Epoch: 5/5, Loss: 0.03475596010684967\n",
      "Epoch: 5/5, Loss: 0.016519267112016678\n",
      "Epoch: 5/5, Loss: 0.013425526209175587\n",
      "Epoch: 5/5, Loss: 0.009077788330614567\n",
      "Epoch: 5/5, Loss: 0.055500566959381104\n",
      "Epoch: 5/5, Loss: 0.029475685209035873\n",
      "Epoch: 5/5, Loss: 0.017307929694652557\n",
      "Epoch: 5/5, Loss: 0.01950232684612274\n",
      "Epoch: 5/5, Loss: 0.038496918976306915\n",
      "Epoch: 5/5, Loss: 0.04390133544802666\n",
      "Epoch: 5/5, Loss: 0.02924661710858345\n",
      "Epoch: 5/5, Loss: 0.02864089049398899\n",
      "Epoch: 5/5, Loss: 0.03318556770682335\n",
      "Epoch: 5/5, Loss: 0.020919298753142357\n",
      "Epoch: 5/5, Loss: 0.02015468291938305\n",
      "Epoch: 5/5, Loss: 0.04497092217206955\n",
      "Epoch: 5/5, Loss: 0.020022690296173096\n",
      "Epoch: 5/5, Loss: 0.028897646814584732\n",
      "Epoch: 5/5, Loss: 0.07500799000263214\n",
      "Epoch: 5/5, Loss: 0.012814621441066265\n",
      "Epoch: 5/5, Loss: 0.032583512365818024\n",
      "Epoch: 5/5, Loss: 0.01601404696702957\n",
      "Epoch: 5/5, Loss: 0.020072126761078835\n",
      "Epoch: 5/5, Loss: 0.03373321518301964\n",
      "Epoch: 5/5, Loss: 0.021735163405537605\n",
      "Epoch: 5/5, Loss: 0.0034325250890105963\n",
      "Epoch: 5/5, Loss: 0.008692903444170952\n",
      "Epoch: 5/5, Loss: 0.0046381875872612\n",
      "Epoch: 5/5, Loss: 0.009640786796808243\n",
      "Epoch: 5/5, Loss: 0.01665038987994194\n",
      "Epoch: 5/5, Loss: 0.012082918547093868\n",
      "Epoch: 5/5, Loss: 0.025522282347083092\n",
      "Epoch: 5/5, Loss: 0.011626756750047207\n",
      "Epoch: 5/5, Loss: 0.015824900940060616\n",
      "Epoch: 5/5, Loss: 0.017361260950565338\n",
      "Epoch: 5/5, Loss: 0.02422504872083664\n",
      "Epoch: 5/5, Loss: 0.023431528359651566\n",
      "Epoch: 5/5, Loss: 0.021987726911902428\n",
      "Epoch: 5/5, Loss: 0.014610957354307175\n",
      "Epoch: 5/5, Loss: 0.0056753698736429214\n",
      "Epoch: 5/5, Loss: 0.010595115832984447\n",
      "Epoch: 5/5, Loss: 0.042932167649269104\n",
      "Epoch: 5/5, Loss: 0.004563203081488609\n",
      "Epoch: 5/5, Loss: 0.03311711177229881\n",
      "Epoch: 5/5, Loss: 0.023725885897874832\n",
      "Epoch: 5/5, Loss: 0.014604039490222931\n",
      "Epoch: 5/5, Loss: 0.03813761845231056\n",
      "Epoch: 5/5, Loss: 0.04678954556584358\n",
      "Epoch: 5/5, Loss: 0.015013855881989002\n",
      "Epoch: 5/5, Loss: 0.11032512038946152\n",
      "Epoch: 5/5, Loss: 0.003910914063453674\n",
      "Epoch: 5/5, Loss: 0.05610914155840874\n",
      "Epoch: 5/5, Loss: 0.009370632469654083\n",
      "Epoch: 5/5, Loss: 0.02906123921275139\n",
      "Epoch: 5/5, Loss: 0.04437591880559921\n",
      "Epoch: 5/5, Loss: 0.02088501676917076\n",
      "Epoch: 5/5, Loss: 0.010045998729765415\n",
      "Epoch: 5/5, Loss: 0.01994135230779648\n",
      "Epoch: 5/5, Loss: 0.011245698668062687\n",
      "Epoch: 5/5, Loss: 0.03443971648812294\n",
      "Epoch: 5/5, Loss: 0.003793874057009816\n",
      "Epoch: 5/5, Loss: 0.009661211632192135\n",
      "Epoch: 5/5, Loss: 0.04695851728320122\n",
      "Epoch: 5/5, Loss: 0.02680441178381443\n",
      "Epoch: 5/5, Loss: 0.040676165372133255\n",
      "Epoch: 5/5, Loss: 0.01855771243572235\n",
      "Epoch: 5/5, Loss: 0.019382266327738762\n",
      "Epoch: 5/5, Loss: 0.05849384143948555\n",
      "Epoch: 5/5, Loss: 0.044433414936065674\n",
      "Epoch: 5/5, Loss: 0.006743868812918663\n",
      "Epoch: 5/5, Loss: 0.02865011990070343\n",
      "Epoch: 5/5, Loss: 0.02000679448246956\n",
      "Epoch: 5/5, Loss: 0.023090269416570663\n",
      "Epoch: 5/5, Loss: 0.027745336294174194\n",
      "Epoch: 5/5, Loss: 0.04610586538910866\n",
      "Epoch: 5/5, Loss: 0.006993636954575777\n",
      "Epoch: 5/5, Loss: 0.028170321136713028\n",
      "Epoch: 5/5, Loss: 0.025610942393541336\n",
      "Epoch: 5/5, Loss: 0.025961536914110184\n",
      "Epoch: 5/5, Loss: 0.03216012939810753\n",
      "Epoch: 5/5, Loss: 0.04469159245491028\n",
      "Epoch: 5/5, Loss: 0.008060239255428314\n",
      "Epoch: 5/5, Loss: 0.0040129004046320915\n",
      "Epoch: 5/5, Loss: 0.0094612967222929\n",
      "Epoch: 5/5, Loss: 0.02931954152882099\n",
      "Epoch: 5/5, Loss: 0.0021700458601117134\n",
      "Epoch: 5/5, Loss: 0.018296118825674057\n",
      "Epoch: 5/5, Loss: 0.012688550166785717\n",
      "Epoch: 5/5, Loss: 0.031780291348695755\n",
      "Epoch: 5/5, Loss: 0.030167462304234505\n",
      "Epoch: 5/5, Loss: 0.0013755926629528403\n",
      "Epoch: 5/5, Loss: 0.011868476867675781\n",
      "Epoch: 5/5, Loss: 0.005077923648059368\n",
      "Epoch: 5/5, Loss: 0.010033436119556427\n",
      "Epoch: 5/5, Loss: 0.019235754385590553\n",
      "Epoch: 5/5, Loss: 0.02051641419529915\n",
      "Epoch: 5/5, Loss: 0.00686158100143075\n",
      "Epoch: 5/5, Loss: 0.018247142434120178\n",
      "Epoch: 5/5, Loss: 0.019235452637076378\n",
      "Epoch: 5/5, Loss: 0.015093721449375153\n",
      "Epoch: 5/5, Loss: 0.008151283487677574\n",
      "Epoch: 5/5, Loss: 0.027955999597907066\n",
      "Epoch: 5/5, Loss: 0.030450722202658653\n",
      "Epoch: 5/5, Loss: 0.08959551900625229\n",
      "Epoch: 5/5, Loss: 0.005966069642454386\n",
      "Epoch: 5/5, Loss: 0.018305813893675804\n",
      "Epoch: 5/5, Loss: 0.005481361877173185\n",
      "Epoch: 5/5, Loss: 0.018343795090913773\n",
      "Epoch: 5/5, Loss: 0.04957137629389763\n",
      "Epoch: 5/5, Loss: 0.05685562640428543\n",
      "Epoch: 5/5, Loss: 0.06714983284473419\n",
      "Epoch: 5/5, Loss: 0.004613710567355156\n",
      "Epoch: 5/5, Loss: 0.011832887306809425\n",
      "Epoch: 5/5, Loss: 0.024706900119781494\n",
      "Epoch: 5/5, Loss: 0.02494647167623043\n",
      "Epoch: 5/5, Loss: 0.005040642339736223\n",
      "Epoch: 5/5, Loss: 0.06388919055461884\n",
      "Epoch: 5/5, Loss: 0.009273596107959747\n",
      "Epoch: 5/5, Loss: 0.033509112894535065\n",
      "Epoch: 5/5, Loss: 0.044129516929388046\n",
      "Epoch: 5/5, Loss: 0.02413603849709034\n",
      "Epoch: 5/5, Loss: 0.016687311232089996\n",
      "Epoch: 5/5, Loss: 0.016193537041544914\n",
      "Epoch: 5/5, Loss: 0.02257518097758293\n",
      "Epoch: 5/5, Loss: 0.05238020047545433\n",
      "Epoch: 5/5, Loss: 0.02569311112165451\n",
      "Epoch: 5/5, Loss: 0.0171325895935297\n",
      "Epoch: 5/5, Loss: 0.027775932103395462\n",
      "Epoch: 5/5, Loss: 0.008751308545470238\n",
      "Epoch: 5/5, Loss: 0.005349765997380018\n",
      "Epoch: 5/5, Loss: 0.10526634007692337\n",
      "Epoch: 5/5, Loss: 0.037748873233795166\n",
      "Epoch: 5/5, Loss: 0.020776959136128426\n",
      "Epoch: 5/5, Loss: 0.04204973578453064\n",
      "Epoch: 5/5, Loss: 0.009655671194195747\n",
      "Epoch: 5/5, Loss: 0.018498826771974564\n",
      "Epoch: 5/5, Loss: 0.039189379662275314\n",
      "Epoch: 5/5, Loss: 0.015220160596072674\n",
      "Epoch: 5/5, Loss: 0.025202779099345207\n",
      "Epoch: 5/5, Loss: 0.031176576390862465\n",
      "Epoch: 5/5, Loss: 0.04558628425002098\n",
      "Epoch: 5/5, Loss: 0.014624026603996754\n",
      "Epoch: 5/5, Loss: 0.025199655443429947\n",
      "Epoch: 5/5, Loss: 0.048901963979005814\n",
      "Epoch: 5/5, Loss: 0.01741255633533001\n",
      "Epoch: 5/5, Loss: 0.007965571247041225\n",
      "Epoch: 5/5, Loss: 0.009714269079267979\n",
      "Epoch: 5/5, Loss: 0.019251549616456032\n",
      "Epoch: 5/5, Loss: 0.01490857359021902\n",
      "Epoch: 5/5, Loss: 0.005765290930867195\n",
      "Epoch: 5/5, Loss: 0.020800339058041573\n",
      "Epoch: 5/5, Loss: 0.008276003412902355\n",
      "Epoch: 5/5, Loss: 0.028237085789442062\n",
      "Epoch: 5/5, Loss: 0.009164899587631226\n",
      "Epoch: 5/5, Loss: 0.006687085144221783\n",
      "Epoch: 5/5, Loss: 0.022412018850445747\n",
      "Epoch: 5/5, Loss: 0.008788006380200386\n",
      "Epoch: 5/5, Loss: 0.05873638764023781\n",
      "Epoch: 5/5, Loss: 0.0263324324041605\n",
      "Epoch: 5/5, Loss: 0.005314926151186228\n",
      "Epoch: 5/5, Loss: 0.03621121123433113\n",
      "Epoch: 5/5, Loss: 0.0018628219841048121\n",
      "Epoch: 5/5, Loss: 0.012863121926784515\n",
      "Epoch: 5/5, Loss: 0.040479015558958054\n",
      "Epoch: 5/5, Loss: 0.04409440606832504\n",
      "Epoch: 5/5, Loss: 0.014093532226979733\n",
      "Epoch: 5/5, Loss: 0.06189398095011711\n",
      "Epoch: 5/5, Loss: 0.016852855682373047\n",
      "Epoch: 5/5, Loss: 0.00964929349720478\n",
      "Epoch: 5/5, Loss: 0.04102064296603203\n",
      "Epoch: 5/5, Loss: 0.006671539507806301\n",
      "Epoch: 5/5, Loss: 0.02832368202507496\n",
      "Epoch: 5/5, Loss: 0.010143931955099106\n",
      "Epoch: 5/5, Loss: 0.010397068224847317\n",
      "Epoch: 5/5, Loss: 0.05363137274980545\n",
      "Epoch: 5/5, Loss: 0.015265445224940777\n",
      "Epoch: 5/5, Loss: 0.013433328829705715\n",
      "Epoch: 5/5, Loss: 0.003567388281226158\n",
      "Epoch: 5/5, Loss: 0.05192645266652107\n",
      "Epoch: 5/5, Loss: 0.026166941970586777\n",
      "Epoch: 5/5, Loss: 0.01354843657463789\n",
      "Epoch: 5/5, Loss: 0.026981759816408157\n",
      "Epoch: 5/5, Loss: 0.010977059602737427\n",
      "Epoch: 5/5, Loss: 0.007910595275461674\n",
      "Epoch: 5/5, Loss: 0.04323049262166023\n",
      "Epoch: 5/5, Loss: 0.0166610274463892\n",
      "Epoch: 5/5, Loss: 0.004783648997545242\n",
      "Epoch: 5/5, Loss: 0.018517866730690002\n",
      "Epoch: 5/5, Loss: 0.024547651410102844\n",
      "Epoch: 5/5, Loss: 0.0043040732853114605\n",
      "Epoch: 5/5, Loss: 0.04239149019122124\n",
      "Epoch: 5/5, Loss: 0.0072847213596105576\n",
      "Epoch: 5/5, Loss: 0.043376389890909195\n",
      "Epoch: 5/5, Loss: 0.007610204163938761\n",
      "Epoch: 5/5, Loss: 0.110043466091156\n",
      "Epoch: 5/5, Loss: 0.014391614124178886\n",
      "Epoch: 5/5, Loss: 0.006807653699070215\n",
      "Epoch: 5/5, Loss: 0.010870498605072498\n",
      "Epoch: 5/5, Loss: 0.027099234983325005\n",
      "Epoch: 5/5, Loss: 0.01130843348801136\n",
      "Epoch: 5/5, Loss: 0.007593229413032532\n",
      "Epoch: 5/5, Loss: 0.024443920701742172\n",
      "Epoch: 5/5, Loss: 0.009366139769554138\n",
      "Epoch: 5/5, Loss: 0.021293025463819504\n",
      "Epoch: 5/5, Loss: 0.006597860716283321\n",
      "Epoch: 5/5, Loss: 0.009435462765395641\n",
      "Epoch: 5/5, Loss: 0.018108641728758812\n",
      "Epoch: 5/5, Loss: 0.025508683174848557\n",
      "Epoch: 5/5, Loss: 0.01657155156135559\n",
      "Epoch: 5/5, Loss: 0.006476879585534334\n",
      "Epoch: 5/5, Loss: 0.006571064703166485\n",
      "Epoch: 5/5, Loss: 0.022202931344509125\n",
      "Epoch: 5/5, Loss: 0.01058686338365078\n",
      "Epoch: 5/5, Loss: 0.07061692327260971\n",
      "Epoch: 5/5, Loss: 0.0178510881960392\n",
      "Epoch: 5/5, Loss: 0.01812979020178318\n",
      "Epoch: 5/5, Loss: 0.0034744637086987495\n",
      "Epoch: 5/5, Loss: 0.02151249535381794\n",
      "Epoch: 5/5, Loss: 0.02173561044037342\n",
      "Epoch: 5/5, Loss: 0.0531635656952858\n",
      "Epoch: 5/5, Loss: 0.04194044694304466\n",
      "Epoch: 5/5, Loss: 0.017337536439299583\n",
      "Epoch: 5/5, Loss: 0.01440480537712574\n",
      "Epoch: 5/5, Loss: 0.015965884551405907\n",
      "Epoch: 5/5, Loss: 0.008989839814603329\n",
      "Epoch: 5/5, Loss: 0.018452707678079605\n",
      "Epoch: 5/5, Loss: 0.10025069862604141\n",
      "Epoch: 5/5, Loss: 0.05296364426612854\n",
      "Epoch: 5/5, Loss: 0.02986510470509529\n",
      "Epoch: 5/5, Loss: 0.14585185050964355\n",
      "Epoch: 5/5, Loss: 0.013857142999768257\n",
      "Epoch: 5/5, Loss: 0.011749912984669209\n",
      "Epoch: 5/5, Loss: 0.021678507328033447\n",
      "Epoch: 5/5, Loss: 0.029744721949100494\n",
      "Epoch: 5/5, Loss: 0.02192726917564869\n",
      "Epoch: 5/5, Loss: 0.06642565876245499\n",
      "Epoch: 5/5, Loss: 0.011003588326275349\n",
      "Epoch: 5/5, Loss: 0.007812433876097202\n",
      "Epoch: 5/5, Loss: 0.02468627132475376\n",
      "Epoch: 5/5, Loss: 0.017901357263326645\n",
      "Epoch: 5/5, Loss: 0.022913148626685143\n",
      "Epoch: 5/5, Loss: 0.03151359036564827\n",
      "Epoch: 5/5, Loss: 0.011917613446712494\n",
      "Epoch: 5/5, Loss: 0.03540199622511864\n",
      "Epoch: 5/5, Loss: 0.02392899990081787\n",
      "Epoch: 5/5, Loss: 0.020653901621699333\n",
      "Epoch: 5/5, Loss: 0.00823160819709301\n",
      "Epoch: 5/5, Loss: 0.014489958062767982\n",
      "Epoch: 5/5, Loss: 0.023673634976148605\n",
      "Epoch: 5/5, Loss: 0.03666137158870697\n",
      "Epoch: 5/5, Loss: 0.009951390326023102\n",
      "Epoch: 5/5, Loss: 0.025328155606985092\n",
      "Epoch: 5/5, Loss: 0.017085455358028412\n",
      "Epoch: 5/5, Loss: 0.030791763216257095\n",
      "Epoch: 5/5, Loss: 0.005957486107945442\n",
      "Epoch: 5/5, Loss: 0.00907534547150135\n",
      "Epoch: 5/5, Loss: 0.025535857304930687\n",
      "Epoch: 5/5, Loss: 0.032393671572208405\n",
      "Epoch: 5/5, Loss: 0.02975921332836151\n",
      "Epoch: 5/5, Loss: 0.03339415043592453\n",
      "Epoch: 5/5, Loss: 0.03170990198850632\n",
      "Epoch: 5/5, Loss: 0.027796415612101555\n",
      "Epoch: 5/5, Loss: 0.002758102025836706\n",
      "Epoch: 5/5, Loss: 0.02399246208369732\n",
      "Epoch: 5/5, Loss: 0.016712388023734093\n",
      "Epoch: 5/5, Loss: 0.00445984210819006\n",
      "Epoch: 5/5, Loss: 0.009512083604931831\n",
      "Epoch: 5/5, Loss: 0.02793138101696968\n",
      "Epoch: 5/5, Loss: 0.035504914820194244\n",
      "Epoch: 5/5, Loss: 0.07725758850574493\n",
      "Epoch: 5/5, Loss: 0.018331145867705345\n",
      "Epoch: 5/5, Loss: 0.02059478498995304\n",
      "Epoch: 5/5, Loss: 0.017149511724710464\n",
      "Epoch: 5/5, Loss: 0.01931014098227024\n",
      "Epoch: 5/5, Loss: 0.005764252971857786\n",
      "Epoch: 5/5, Loss: 0.015609628520905972\n",
      "Epoch: 5/5, Loss: 0.027720380574464798\n",
      "Epoch: 5/5, Loss: 0.03653386980295181\n",
      "Epoch: 5/5, Loss: 0.0015834931982681155\n",
      "Epoch: 5/5, Loss: 0.017003418877720833\n",
      "Epoch: 5/5, Loss: 0.023719897493720055\n",
      "Epoch: 5/5, Loss: 0.05259536951780319\n",
      "Epoch: 5/5, Loss: 0.07837662845849991\n",
      "Epoch: 5/5, Loss: 0.02170824632048607\n",
      "Epoch: 5/5, Loss: 0.020541340112686157\n",
      "Epoch: 5/5, Loss: 0.024639049544930458\n",
      "Epoch: 5/5, Loss: 0.04738893359899521\n",
      "Epoch: 5/5, Loss: 0.01763737201690674\n",
      "Epoch: 5/5, Loss: 0.014645138755440712\n",
      "Epoch: 5/5, Loss: 0.037799324840307236\n",
      "Epoch: 5/5, Loss: 0.013219128362834454\n",
      "Epoch: 5/5, Loss: 0.01364089921116829\n",
      "Epoch: 5/5, Loss: 0.0314236544072628\n",
      "Epoch: 5/5, Loss: 0.022971132770180702\n",
      "Epoch: 5/5, Loss: 0.02834801748394966\n",
      "Epoch: 5/5, Loss: 0.018427494913339615\n",
      "Epoch: 5/5, Loss: 0.01009022444486618\n",
      "Epoch: 5/5, Loss: 0.023851871490478516\n",
      "Epoch: 5/5, Loss: 0.03214269131422043\n",
      "Epoch: 5/5, Loss: 0.006649416871368885\n",
      "Epoch: 5/5, Loss: 0.01205010712146759\n",
      "Epoch: 5/5, Loss: 0.004071329720318317\n",
      "Epoch: 5/5, Loss: 0.027265818789601326\n",
      "Epoch: 5/5, Loss: 0.03366570547223091\n",
      "Epoch: 5/5, Loss: 0.03903201222419739\n",
      "Epoch: 5/5, Loss: 0.04174701124429703\n",
      "Epoch: 5/5, Loss: 0.0049888077192008495\n",
      "Epoch: 5/5, Loss: 0.02180098369717598\n",
      "Epoch: 5/5, Loss: 0.011144048534333706\n",
      "Epoch: 5/5, Loss: 0.01596684753894806\n",
      "Epoch: 5/5, Loss: 0.03953822702169418\n",
      "Epoch: 5/5, Loss: 0.011307286098599434\n",
      "Epoch: 5/5, Loss: 0.005156411323696375\n",
      "Epoch: 5/5, Loss: 0.008607457391917706\n",
      "Epoch: 5/5, Loss: 0.008600893430411816\n",
      "Epoch: 5/5, Loss: 0.03228301554918289\n",
      "Epoch: 5/5, Loss: 0.04226449504494667\n",
      "Epoch: 5/5, Loss: 0.04878208413720131\n",
      "Epoch: 5/5, Loss: 0.027299510315060616\n",
      "Epoch: 5/5, Loss: 0.05018138885498047\n",
      "Epoch: 5/5, Loss: 0.005870759021490812\n",
      "Epoch: 5/5, Loss: 0.009332405403256416\n",
      "Epoch: 5/5, Loss: 0.04618282988667488\n",
      "Epoch: 5/5, Loss: 0.022453714162111282\n",
      "Epoch: 5/5, Loss: 0.004637939855456352\n",
      "Epoch: 5/5, Loss: 0.06065547466278076\n",
      "Epoch: 5/5, Loss: 0.012939606793224812\n",
      "Epoch: 5/5, Loss: 0.007050441578030586\n",
      "Epoch: 5/5, Loss: 0.013796823099255562\n",
      "Epoch: 5/5, Loss: 0.005614953115582466\n",
      "Epoch: 5/5, Loss: 0.0035331696271896362\n",
      "Epoch: 5/5, Loss: 0.044063907116651535\n",
      "Epoch: 5/5, Loss: 0.0157539751380682\n",
      "Epoch: 5/5, Loss: 0.03972121328115463\n",
      "Epoch: 5/5, Loss: 0.0068709817714989185\n",
      "Epoch: 5/5, Loss: 0.01620657369494438\n",
      "Epoch: 5/5, Loss: 0.030783608555793762\n",
      "Epoch: 5/5, Loss: 0.028425343334674835\n",
      "Epoch: 5/5, Loss: 0.021335914731025696\n",
      "Epoch: 5/5, Loss: 0.066952645778656\n",
      "Epoch: 5/5, Loss: 0.004171891137957573\n",
      "Epoch: 5/5, Loss: 0.013368475250899792\n",
      "Epoch: 5/5, Loss: 0.024584516882896423\n",
      "Epoch: 5/5, Loss: 0.01041041687130928\n",
      "Epoch: 5/5, Loss: 0.0010354076512157917\n",
      "Epoch: 5/5, Loss: 0.02058541402220726\n",
      "Epoch: 5/5, Loss: 0.02410762943327427\n",
      "Epoch: 5/5, Loss: 0.046194497495889664\n",
      "Epoch: 5/5, Loss: 0.006476273760199547\n",
      "Epoch: 5/5, Loss: 0.01965148001909256\n",
      "Epoch: 5/5, Loss: 0.005809888243675232\n",
      "Epoch: 5/5, Loss: 0.008499711751937866\n",
      "Epoch: 5/5, Loss: 0.01480838842689991\n",
      "Epoch: 5/5, Loss: 0.028734691441059113\n",
      "Epoch: 5/5, Loss: 0.017745260149240494\n",
      "Epoch: 5/5, Loss: 0.01959947869181633\n",
      "Epoch: 5/5, Loss: 0.031015753746032715\n",
      "Epoch: 5/5, Loss: 0.026509417220950127\n",
      "Epoch: 5/5, Loss: 0.015935754403471947\n",
      "Epoch: 5/5, Loss: 0.025494391098618507\n",
      "Epoch: 5/5, Loss: 0.008666684851050377\n",
      "Epoch: 5/5, Loss: 0.03764386102557182\n",
      "Epoch: 5/5, Loss: 0.06566302478313446\n",
      "Epoch: 5/5, Loss: 0.01761249266564846\n",
      "Epoch: 5/5, Loss: 0.014221111312508583\n",
      "Epoch: 5/5, Loss: 0.013150433078408241\n",
      "Epoch: 5/5, Loss: 0.031164612621068954\n",
      "Epoch: 5/5, Loss: 0.006444859318435192\n",
      "Epoch: 5/5, Loss: 0.03151321783661842\n",
      "Epoch: 5/5, Loss: 0.016221920028328896\n",
      "Epoch: 5/5, Loss: 0.010153871029615402\n",
      "Epoch: 5/5, Loss: 0.021602541208267212\n",
      "Epoch: 5/5, Loss: 0.005964653100818396\n",
      "Epoch: 5/5, Loss: 0.03612564504146576\n",
      "Epoch: 5/5, Loss: 0.03250548616051674\n",
      "Epoch: 5/5, Loss: 0.010076991282403469\n",
      "Epoch: 5/5, Loss: 0.009109565988183022\n",
      "Epoch: 5/5, Loss: 0.0200352780520916\n",
      "Epoch: 5/5, Loss: 0.07511162012815475\n",
      "Epoch: 5/5, Loss: 0.009115849621593952\n",
      "Epoch: 5/5, Loss: 0.008287498727440834\n",
      "Epoch: 5/5, Loss: 0.008712595328688622\n",
      "Epoch: 5/5, Loss: 0.012212784960865974\n",
      "Epoch: 5/5, Loss: 0.015324404463171959\n",
      "Epoch: 5/5, Loss: 0.0019488714169710875\n",
      "Epoch: 5/5, Loss: 0.060201749205589294\n",
      "Epoch: 5/5, Loss: 0.0015038260025903583\n",
      "Epoch: 5/5, Loss: 0.02813277579843998\n",
      "Epoch: 5/5, Loss: 0.021122325211763382\n",
      "Epoch: 5/5, Loss: 0.03935551643371582\n",
      "Epoch: 5/5, Loss: 0.04810374602675438\n",
      "Epoch: 5/5, Loss: 0.07336065173149109\n",
      "Epoch: 5/5, Loss: 0.018510159105062485\n",
      "Epoch: 5/5, Loss: 0.009219120256602764\n",
      "Epoch: 5/5, Loss: 0.011042146943509579\n",
      "Epoch: 5/5, Loss: 0.06482698768377304\n",
      "Epoch: 5/5, Loss: 0.015389294363558292\n",
      "Epoch: 5/5, Loss: 0.008685965090990067\n",
      "Epoch: 5/5, Loss: 0.01815977692604065\n",
      "Epoch: 5/5, Loss: 0.01480325497686863\n",
      "Epoch: 5/5, Loss: 0.013388123363256454\n",
      "Epoch: 5/5, Loss: 0.0011479274835437536\n",
      "Epoch: 5/5, Loss: 0.030723467469215393\n",
      "Epoch: 5/5, Loss: 0.021963825449347496\n",
      "Epoch: 5/5, Loss: 0.06187228858470917\n",
      "Epoch: 5/5, Loss: 0.022155985236167908\n",
      "Epoch: 5/5, Loss: 0.014321930706501007\n",
      "Epoch: 5/5, Loss: 0.017202217131853104\n",
      "Epoch: 5/5, Loss: 0.013593700714409351\n",
      "Epoch: 5/5, Loss: 0.0059596458449959755\n",
      "Epoch: 5/5, Loss: 0.022361675277352333\n",
      "Epoch: 5/5, Loss: 0.009515567682683468\n",
      "Epoch: 5/5, Loss: 0.010175926610827446\n",
      "Epoch: 5/5, Loss: 0.015138144604861736\n",
      "Epoch: 5/5, Loss: 0.019121425226330757\n",
      "Epoch: 5/5, Loss: 0.14214882254600525\n",
      "Epoch: 5/5, Loss: 0.03989805281162262\n",
      "Epoch: 5/5, Loss: 0.017584290355443954\n",
      "Epoch: 5/5, Loss: 0.004532028455287218\n",
      "Epoch: 5/5, Loss: 0.0049650962464511395\n",
      "Epoch: 5/5, Loss: 0.003107515862211585\n",
      "Epoch: 5/5, Loss: 0.009006675332784653\n",
      "Epoch: 5/5, Loss: 0.008751941844820976\n",
      "Epoch: 5/5, Loss: 0.006669172551482916\n",
      "Epoch: 5/5, Loss: 0.012828665785491467\n",
      "Epoch: 5/5, Loss: 0.06639999151229858\n",
      "Epoch: 5/5, Loss: 0.01331004872918129\n",
      "Epoch: 5/5, Loss: 0.013465862721204758\n",
      "Epoch: 5/5, Loss: 0.0034088832326233387\n",
      "Epoch: 5/5, Loss: 0.029413273558020592\n",
      "Epoch: 5/5, Loss: 0.01587090454995632\n",
      "Epoch: 5/5, Loss: 0.019209900870919228\n",
      "Epoch: 5/5, Loss: 0.014740829356014729\n",
      "Epoch: 5/5, Loss: 0.014218098483979702\n",
      "Epoch: 5/5, Loss: 0.02994358539581299\n",
      "Epoch: 5/5, Loss: 0.006550491787493229\n",
      "Epoch: 5/5, Loss: 0.018269920721650124\n",
      "Epoch: 5/5, Loss: 0.004177641123533249\n",
      "Epoch: 5/5, Loss: 0.030154652893543243\n",
      "Epoch: 5/5, Loss: 0.03273650258779526\n",
      "Epoch: 5/5, Loss: 0.016544707119464874\n",
      "Epoch: 5/5, Loss: 0.0037223841063678265\n",
      "Epoch: 5/5, Loss: 0.02673790417611599\n",
      "Epoch: 5/5, Loss: 0.005093632265925407\n",
      "Epoch: 5/5, Loss: 0.03379775583744049\n",
      "Epoch: 5/5, Loss: 0.0026930407620966434\n",
      "Epoch: 5/5, Loss: 0.02326141856610775\n",
      "Epoch: 5/5, Loss: 0.002382625127211213\n",
      "Epoch: 5/5, Loss: 0.020097196102142334\n",
      "Epoch: 5/5, Loss: 0.02229703590273857\n",
      "Epoch: 5/5, Loss: 0.022781407460570335\n",
      "Epoch: 5/5, Loss: 0.018296506255865097\n",
      "Epoch: 5/5, Loss: 0.05461142212152481\n",
      "Epoch: 5/5, Loss: 0.02477269619703293\n",
      "Epoch: 5/5, Loss: 0.02710883319377899\n",
      "Epoch: 5/5, Loss: 0.015100128017365932\n",
      "Epoch: 5/5, Loss: 0.011637585237622261\n",
      "Epoch: 5/5, Loss: 0.042727433145046234\n",
      "Epoch: 5/5, Loss: 0.025364629924297333\n",
      "Epoch: 5/5, Loss: 0.009579727426171303\n",
      "Epoch: 5/5, Loss: 0.006606794893741608\n",
      "Epoch: 5/5, Loss: 0.007901879027485847\n",
      "Epoch: 5/5, Loss: 0.015039569698274136\n",
      "Epoch: 5/5, Loss: 0.026285389438271523\n",
      "Epoch: 5/5, Loss: 0.015400511212646961\n",
      "Epoch: 5/5, Loss: 0.033349599689245224\n",
      "Epoch: 5/5, Loss: 0.03221037983894348\n",
      "Epoch: 5/5, Loss: 0.029710691422224045\n",
      "Epoch: 5/5, Loss: 0.017669737339019775\n",
      "Epoch: 5/5, Loss: 0.02167707309126854\n",
      "Epoch: 5/5, Loss: 0.009342510253190994\n",
      "Epoch: 5/5, Loss: 0.03822018951177597\n",
      "Epoch: 5/5, Loss: 0.03140350431203842\n",
      "Epoch: 5/5, Loss: 0.030196525156497955\n",
      "Epoch: 5/5, Loss: 0.02687675505876541\n",
      "Epoch: 5/5, Loss: 0.01675642654299736\n",
      "Epoch: 5/5, Loss: 0.011308740824460983\n",
      "Epoch: 5/5, Loss: 0.016664624214172363\n",
      "Epoch: 5/5, Loss: 0.0073818848468363285\n",
      "Epoch: 5/5, Loss: 0.017870165407657623\n",
      "Epoch: 5/5, Loss: 0.03633033484220505\n",
      "Epoch: 5/5, Loss: 0.014847870916128159\n",
      "Epoch: 5/5, Loss: 0.00630579749122262\n",
      "Epoch: 5/5, Loss: 0.01694769412279129\n",
      "Epoch: 5/5, Loss: 0.0009603395592421293\n",
      "Epoch: 5/5, Loss: 0.014383714646100998\n",
      "Epoch: 5/5, Loss: 0.012798779644072056\n",
      "Epoch: 5/5, Loss: 0.0070205326192080975\n",
      "Epoch: 5/5, Loss: 0.009826051071286201\n",
      "Epoch: 5/5, Loss: 0.04623816907405853\n",
      "Epoch: 5/5, Loss: 0.023078564554452896\n",
      "Epoch: 5/5, Loss: 0.0590316541492939\n",
      "Epoch: 5/5, Loss: 0.017794091254472733\n",
      "Epoch: 5/5, Loss: 0.12396001070737839\n",
      "Epoch: 5/5, Loss: 0.022369585931301117\n",
      "Epoch: 5/5, Loss: 0.06454036384820938\n",
      "Epoch: 5/5, Loss: 0.03333106264472008\n",
      "Epoch: 5/5, Loss: 0.03364894911646843\n",
      "Epoch: 5/5, Loss: 0.0028875237330794334\n",
      "Epoch: 5/5, Loss: 0.016630738973617554\n",
      "Epoch: 5/5, Loss: 0.002697158372029662\n",
      "Epoch: 5/5, Loss: 0.041799288243055344\n",
      "Epoch: 5/5, Loss: 0.022474927827715874\n",
      "Epoch: 5/5, Loss: 0.015091735869646072\n",
      "Epoch: 5/5, Loss: 0.03717668354511261\n",
      "Epoch: 5/5, Loss: 0.010779940523207188\n",
      "Epoch: 5/5, Loss: 0.021413682028651237\n",
      "Epoch: 5/5, Loss: 0.00742437643930316\n",
      "Epoch: 5/5, Loss: 0.003931834362447262\n",
      "Epoch: 5/5, Loss: 0.004680640529841185\n",
      "Epoch: 5/5, Loss: 0.016077786684036255\n",
      "Epoch: 5/5, Loss: 0.019805900752544403\n",
      "Epoch: 5/5, Loss: 0.028112169355154037\n",
      "Epoch: 5/5, Loss: 0.04595784842967987\n",
      "Epoch: 5/5, Loss: 0.011230433359742165\n",
      "Epoch: 5/5, Loss: 0.046508923172950745\n",
      "Epoch: 5/5, Loss: 0.006814715452492237\n",
      "Epoch: 5/5, Loss: 0.028556091710925102\n",
      "Epoch: 5/5, Loss: 0.07711712270975113\n",
      "Epoch: 5/5, Loss: 0.07073786109685898\n",
      "Epoch: 5/5, Loss: 0.0021687932312488556\n",
      "Epoch: 5/5, Loss: 0.03960093855857849\n",
      "Epoch: 5/5, Loss: 0.010682755149900913\n",
      "Epoch: 5/5, Loss: 0.031701117753982544\n",
      "Epoch: 5/5, Loss: 0.00901852734386921\n",
      "Epoch: 5/5, Loss: 0.0528155192732811\n",
      "Epoch: 5/5, Loss: 0.006945084780454636\n",
      "Epoch: 5/5, Loss: 0.013037901371717453\n",
      "Epoch: 5/5, Loss: 0.024002885445952415\n",
      "Epoch: 5/5, Loss: 0.024519512429833412\n",
      "Epoch: 5/5, Loss: 0.003355762455612421\n",
      "Epoch: 5/5, Loss: 0.011441337876021862\n",
      "Epoch: 5/5, Loss: 0.018696634098887444\n",
      "Epoch: 5/5, Loss: 0.005080219358205795\n",
      "Epoch: 5/5, Loss: 0.03414182737469673\n",
      "Epoch: 5/5, Loss: 0.021354882046580315\n",
      "Epoch: 5/5, Loss: 0.027615174651145935\n",
      "Epoch: 5/5, Loss: 0.010802196338772774\n",
      "Epoch: 5/5, Loss: 0.02207140251994133\n",
      "Epoch: 5/5, Loss: 0.025388382375240326\n",
      "Epoch: 5/5, Loss: 0.03759429603815079\n",
      "Epoch: 5/5, Loss: 0.011412614956498146\n",
      "Epoch: 5/5, Loss: 0.03774529695510864\n",
      "Epoch: 5/5, Loss: 0.02460368350148201\n",
      "Epoch: 5/5, Loss: 0.022942285984754562\n",
      "Epoch: 5/5, Loss: 0.011779948137700558\n",
      "Epoch: 5/5, Loss: 0.056112781167030334\n",
      "Epoch: 5/5, Loss: 0.007650457788258791\n",
      "Epoch: 5/5, Loss: 0.035132598131895065\n",
      "Epoch: 5/5, Loss: 0.0277375690639019\n",
      "Epoch: 5/5, Loss: 0.020001918077468872\n",
      "Epoch: 5/5, Loss: 0.019019216299057007\n",
      "Epoch: 5/5, Loss: 0.06930997967720032\n",
      "Epoch: 5/5, Loss: 0.047866176813840866\n",
      "Epoch: 5/5, Loss: 0.027280375361442566\n",
      "Epoch: 5/5, Loss: 0.016025280579924583\n",
      "Epoch: 5/5, Loss: 0.01132153533399105\n",
      "Epoch: 5/5, Loss: 0.036127809435129166\n",
      "Epoch: 5/5, Loss: 0.012502198107540607\n",
      "Epoch: 5/5, Loss: 0.10000474005937576\n",
      "Epoch: 5/5, Loss: 0.012912224978208542\n",
      "Epoch: 5/5, Loss: 0.013164844363927841\n",
      "Epoch: 5/5, Loss: 0.10889609903097153\n",
      "Epoch: 5/5, Loss: 0.010670837014913559\n",
      "Epoch: 5/5, Loss: 0.010886338539421558\n",
      "Epoch: 5/5, Loss: 0.006337396800518036\n",
      "Epoch: 5/5, Loss: 0.02885754033923149\n",
      "Epoch: 5/5, Loss: 0.0040471674874424934\n",
      "Epoch: 5/5, Loss: 0.00683357659727335\n",
      "Epoch: 5/5, Loss: 0.020908474922180176\n",
      "Epoch: 5/5, Loss: 0.005904152523726225\n",
      "Epoch: 5/5, Loss: 0.015390180051326752\n",
      "Epoch: 5/5, Loss: 0.010080662555992603\n",
      "Epoch: 5/5, Loss: 0.0388331301510334\n",
      "Epoch: 5/5, Loss: 0.020263485610485077\n",
      "Epoch: 5/5, Loss: 0.018316512927412987\n",
      "Epoch: 5/5, Loss: 0.0224339347332716\n",
      "Epoch: 5/5, Loss: 0.06391466408967972\n",
      "Epoch: 5/5, Loss: 0.01479157991707325\n",
      "Epoch: 5/5, Loss: 0.0014725442742928863\n",
      "Epoch: 5/5, Loss: 0.026834623888134956\n",
      "Epoch: 5/5, Loss: 0.024366047233343124\n",
      "Epoch: 5/5, Loss: 0.16921931505203247\n",
      "Epoch: 5/5, Loss: 0.018521923571825027\n",
      "Epoch: 5/5, Loss: 0.01871008612215519\n",
      "Epoch: 5/5, Loss: 0.02928594872355461\n",
      "Epoch: 5/5, Loss: 0.027406129986047745\n",
      "Epoch: 5/5, Loss: 0.012162880972027779\n",
      "Epoch: 5/5, Loss: 0.08178288489580154\n",
      "Epoch: 5/5, Loss: 0.03908633813261986\n",
      "Epoch: 5/5, Loss: 0.00920362863689661\n",
      "Epoch: 5/5, Loss: 0.016833551228046417\n",
      "Epoch: 5/5, Loss: 0.0040036775171756744\n",
      "Epoch: 5/5, Loss: 0.01924562081694603\n",
      "Epoch: 5/5, Loss: 0.0444648414850235\n",
      "Epoch: 5/5, Loss: 0.031746380031108856\n",
      "Epoch: 5/5, Loss: 0.03995416313409805\n",
      "Epoch: 5/5, Loss: 0.03709305077791214\n",
      "Epoch: 5/5, Loss: 0.019118985161185265\n",
      "Epoch: 5/5, Loss: 0.0043033757247030735\n",
      "Epoch: 5/5, Loss: 0.029591981321573257\n",
      "Epoch: 5/5, Loss: 0.06458572298288345\n",
      "Epoch: 5/5, Loss: 0.02019565738737583\n",
      "Epoch: 5/5, Loss: 0.027713268995285034\n",
      "Epoch: 5/5, Loss: 0.0982329249382019\n",
      "Epoch: 5/5, Loss: 0.004031565971672535\n",
      "Epoch: 5/5, Loss: 0.020497674122452736\n",
      "Epoch: 5/5, Loss: 0.058391109108924866\n",
      "Epoch: 5/5, Loss: 0.021772459149360657\n",
      "Epoch: 5/5, Loss: 0.015928441658616066\n",
      "Epoch: 5/5, Loss: 0.05102245882153511\n",
      "Epoch: 5/5, Loss: 0.009206065908074379\n",
      "Epoch: 5/5, Loss: 0.004166351165622473\n",
      "Epoch: 5/5, Loss: 0.02330280840396881\n",
      "Epoch: 5/5, Loss: 0.029369115829467773\n",
      "Epoch: 5/5, Loss: 0.013848714530467987\n",
      "Epoch: 5/5, Loss: 0.01444520615041256\n",
      "Epoch: 5/5, Loss: 0.039763156324625015\n",
      "Epoch: 5/5, Loss: 0.05470942333340645\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        ## setar os gradientes\n",
    "        optimizer.zero_grad()\n",
    "        ## pegando os pacotes separados nos lotes\n",
    "        features, target = data\n",
    "        ## calculando as preds\n",
    "        pred = model(features)\n",
    "        ## Computando as perdas e os gradientes\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "        ## Atualizando a etapa\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show_results(model, dataloader) ## depois que terminar o curso criar essa função para descrever o modelo pra mim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid function Limitações\n",
    "* É limitada entre 0 e 1\n",
    "* Segue uma destribuição normal (graficamente)\n",
    "\n",
    "### SoftMax function\n",
    "* Quando calculamos o gradiente das duas funções elas se aproxima de zero\n",
    "* Também satura.\n",
    "\n",
    "\n",
    "Obs: Saturação acontece quando calculamos o gradiente de uma função e idependente dos sua primeira ou enezima gradiente ela converge para zero.\n",
    "E isso impede que nosso modelo rode $n$ vezes, assim impedindo que o peso seja alterado ou atualizado. (gradiente de fulga)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function ReLU\n",
    "$$ReLU(x)= max(0, x)$$\n",
    "\n",
    "* Não possui limite superior \n",
    "* Os gradientes não convergem para zero o que supera o gradiente de fuga\n",
    "\n",
    "### Function Leaky ReLU\n",
    "* Onde a diferença e apenas que para valores negativos ela tem um fato de multiplicação de x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# Create a ReLU function with PyTorch\n",
    "relu_pytorch = nn.ReLU()\n",
    "\n",
    "# Apply your ReLU function on x, and calculate gradients\n",
    "x = torch.tensor(-1.0, requires_grad=True)\n",
    "y = relu_pytorch(x)\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient of the ReLU function for x\n",
    "gradient = x.grad\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1000)\n"
     ]
    }
   ],
   "source": [
    "# Create a leaky relu function in PyTorch\n",
    "leaky_relu_pytorch = nn.LeakyReLU(negative_slope=0.05)\n",
    "\n",
    "x = torch.tensor(-2.0)\n",
    "# Call the above function on the tensor x\n",
    "output = leaky_relu_pytorch(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitetura de modelos\n",
    "Lembre-se que quando cada neuronio da camada está conectada a cada neuronio da camada anterior chamamos de camadas completamente conectadas. \n",
    "Cada neuronio de uma camada linear calculará um operação linear usando todos os neuronios da camada anterior.\n",
    "\n",
    "Ou seja cada neuronio tem $n+1$ que  e o parametro que pode ser aprendido mais um para o vies.\n",
    "\n",
    "**Redes Neurais Totalmente Conectadas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 8\n",
    "n_classes = 2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 4),\n",
    "    nn.Linear(4, 2),\n",
    ")\n",
    "\n",
    "## Temos duas camadas ocultas nesse modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "total = 0 \n",
    "for parameter in model.parameters():\n",
    "    total += parameter.numel()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_capacity(model):\n",
    "    total = 0\n",
    "    for p in model.parameters():\n",
    "        total += p.numel()\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimizador impactando no treinamento\n",
    "O que controla a inercia do otimizador e o momentum\n",
    "* Encontrar bons valores para a taxa de aprendizado e o impulso e fundamental para diminuir o tempo de treinamento do modelo ou mau desempenho.\n",
    "* Um dos maiores desafios e tentar encontrar o minimo de uma função não convexa e ficar preso em um minimo local.\n",
    "\n",
    "**Resumo**\n",
    "* Momento: Controla a inercia do otimizador, sem impulso o otimizador pode ficar preso em um otimo local. Ele varia de $0.85$ a $0.99$\n",
    "* Taxa de aprendizado: lr Tamanho da taxa do peso executado pelo otimizador variam $10^{-2}$ a $10^{-4}$ se a essa taxa for muito alta o otimizador podera nunca conseguir minimizar a função perda. E se tiver muito baixo o trinamento pode demorar mais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1250, grad_fn=<MinBackward1>)\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Linear(64, 128)\n",
    "\n",
    "print(layer.weight.max())\n",
    "print(layer.weight.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obs\n",
    "Engenheiros de machine learning nunca se baseam por pesos ja inicializados, geralmente utilizam um conceito chamado aprendizado por transferência.\n",
    "* O conceito se consiste em pegar um modelo treinado em uma tarefa e reutiliza-lo para a segunda tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Linear(64, 128)\n",
    "torch.save(layer, \"layer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_layer = torch.load(\"layer.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Podemos treinar uma parte so da rede neural\n",
    "* As camadas iniciais não precisão ser treinadas\n",
    "* Então podemos optar por congelar elas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(64, 128),\n",
    "    nn.Linear(128,256)\n",
    ")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name == \"0.weight\":\n",
    "        param.requires_grad = False ## definimos aqui como falso caso quera não carregar o gradiente 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ou podemos usar como\n",
    "for name, param in model.named_parameters():\n",
    "    # Check if the parameters belong to the first layer\n",
    "    if name == \"0.weight\" or name == \"0.bias\":\n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Check if the parameters belong to the second layer\n",
    "    if name == \"1.weight\" or name == \"1.bias\":\n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.9862, 0.7974, 0.2262,  ..., 0.4242, 0.3383, 0.7653],\n",
       "        [0.7035, 0.8719, 0.7898,  ..., 0.5655, 0.4785, 0.8840],\n",
       "        [0.3541, 0.3229, 0.3210,  ..., 0.4788, 0.0443, 0.1420],\n",
       "        ...,\n",
       "        [0.6155, 0.3711, 0.6028,  ..., 0.7323, 0.3947, 0.8518],\n",
       "        [0.7579, 0.9891, 0.1630,  ..., 0.0581, 0.6442, 0.8467],\n",
       "        [0.7310, 0.6758, 0.5004,  ..., 0.7823, 0.2196, 0.3256]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.uniform_(layer.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/zoo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal_name</th>\n",
       "      <th>hair</th>\n",
       "      <th>feathers</th>\n",
       "      <th>eggs</th>\n",
       "      <th>milk</th>\n",
       "      <th>airborne</th>\n",
       "      <th>aquatic</th>\n",
       "      <th>predator</th>\n",
       "      <th>toothed</th>\n",
       "      <th>backbone</th>\n",
       "      <th>breathes</th>\n",
       "      <th>venomous</th>\n",
       "      <th>fins</th>\n",
       "      <th>legs</th>\n",
       "      <th>tail</th>\n",
       "      <th>domestic</th>\n",
       "      <th>catsize</th>\n",
       "      <th>class_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antelope</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bass</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animal_name  hair  feathers  eggs  milk  airborne  aquatic  predator  \\\n",
       "0    aardvark     1         0     0     1         0        0         1   \n",
       "1    antelope     1         0     0     1         0        0         0   \n",
       "2        bass     0         0     1     0         0        1         1   \n",
       "3        bear     1         0     0     1         0        0         1   \n",
       "4        boar     1         0     0     1         0        0         1   \n",
       "\n",
       "   toothed  backbone  breathes  venomous  fins  legs  tail  domestic  catsize  \\\n",
       "0        1         1         1         0     0     4     0         0        1   \n",
       "1        1         1         1         0     0     4     1         0        1   \n",
       "2        1         1         0         0     1     0     1         0        0   \n",
       "3        1         1         1         0     0     4     0         0        1   \n",
       "4        1         1         1         0     0     4     1         0        1   \n",
       "\n",
       "   class_type  \n",
       "0           1  \n",
       "1           1  \n",
       "2           4  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"animal_name\", \"hair\", \"feathers\", \"eggs\", \"milk\", \"predator\", \"fins\", \"legs\", \"tail\", \"class_type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 1. 1. 0. 4. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 0.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 0.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 4. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 6. 0.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [0. 0. 0. 1. 1. 1. 0. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 6. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 4. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 4. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 2. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 2. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 6. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 2. 0.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 6. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 6. 0.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 6. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 6. 0.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 6. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 8. 0.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 0. 0. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 8. 1.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 0. 1. 1. 1. 0. 0.]\n",
      " [1. 0. 0. 1. 1. 1. 2. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 5. 0.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 6. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 4. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 2. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 4. 1.]\n",
      " [0. 1. 1. 0. 1. 0. 2. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 2. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 6. 0.]\n",
      " [1. 0. 0. 1. 1. 0. 4. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 2. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "features = df[df.columns[1:-1]]\n",
    "X = np.array(features).astype(float)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 4. 1. 1. 1. 1. 4. 4. 1. 1. 2. 4. 7. 7. 7. 2. 1. 4. 1. 2. 2. 1. 2.\n",
      " 6. 5. 5. 1. 1. 1. 6. 1. 1. 2. 4. 1. 1. 2. 4. 6. 6. 2. 6. 2. 1. 1. 7. 1.\n",
      " 1. 1. 1. 6. 5. 7. 1. 1. 2. 2. 2. 2. 4. 4. 3. 1. 1. 1. 1. 1. 1. 1. 1. 2.\n",
      " 7. 4. 1. 1. 3. 7. 2. 2. 3. 7. 4. 2. 1. 7. 4. 2. 6. 5. 3. 3. 4. 1. 1. 2.\n",
      " 1. 6. 1. 7. 2.]\n"
     ]
    }
   ],
   "source": [
    "target = df[df.columns[-1]]\n",
    "y = np.array(target).astype(float)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.tensor(X).float(), torch.tensor(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sample tensor([1., 0., 0., 1., 1., 0., 4., 0.])\n",
      "label_sample tensor(1., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[0]\n",
    "input_sample, label_sample = sample\n",
    "print(\"input sample\", input_sample)\n",
    "print(\"label_sample\", label_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2 ## tamanho do lote ## determina o quantas amostras retiramos do conjunto de dados por interação\n",
    "shuffle = True ## embaralha os dados em cada interação\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch input tensor([[0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 4., 1.]])\n",
      "batch labels tensor([7., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 0., 0., 2., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 4., 0.]])\n",
      "batch labels tensor([2., 5.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 1.],\n",
      "        [1., 0., 1., 0., 0., 0., 6., 0.]])\n",
      "batch labels tensor([1., 6.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 1., 0., 0., 0., 6., 0.],\n",
      "        [1., 0., 1., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([6., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 0., 0., 6., 0.],\n",
      "        [0., 1., 1., 0., 1., 0., 2., 1.]])\n",
      "batch labels tensor([6., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 0., 6., 0.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([6., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 2., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 2., 1.]])\n",
      "batch labels tensor([1., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 2., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 5., 0.]])\n",
      "batch labels tensor([1., 7.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 4., 1.]])\n",
      "batch labels tensor([7., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 0., 0., 6., 0.],\n",
      "        [0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "batch labels tensor([6., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 1., 0., 2., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([2., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 4., 1.],\n",
      "        [0., 1., 1., 0., 0., 0., 2., 1.]])\n",
      "batch labels tensor([1., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 4., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([1., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 1., 0., 2., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "batch labels tensor([2., 7.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 0., 1., 1., 1., 0., 1.],\n",
      "        [0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "batch labels tensor([1., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 4., 0.],\n",
      "        [0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "batch labels tensor([1., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 4., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 4., 1.]])\n",
      "batch labels tensor([1., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 0., 1., 1., 1., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([1., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 1.]])\n",
      "batch labels tensor([1., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 2., 0.]])\n",
      "batch labels tensor([4., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 0., 0., 2., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 6., 0.]])\n",
      "batch labels tensor([2., 6.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 1., 0., 2., 1.],\n",
      "        [0., 1., 1., 0., 0., 0., 2., 1.]])\n",
      "batch labels tensor([2., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 1., 0., 2., 1.],\n",
      "        [0., 1., 1., 0., 0., 0., 2., 1.]])\n",
      "batch labels tensor([2., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 2., 1.],\n",
      "        [0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "batch labels tensor([1., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 0., 6., 0.],\n",
      "        [1., 0., 0., 1., 1., 1., 0., 0.]])\n",
      "batch labels tensor([7., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 2., 1.],\n",
      "        [0., 1., 1., 0., 0., 0., 2., 1.]])\n",
      "batch labels tensor([1., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 1., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([4., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([1., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 0., 0., 1., 0., 8., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 1.]])\n",
      "batch labels tensor([7., 3.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 1., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([4., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 1., 2., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 1.]])\n",
      "batch labels tensor([1., 3.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 1.],\n",
      "        [0., 1., 1., 0., 1., 0., 2., 1.]])\n",
      "batch labels tensor([1., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 1., 0., 2., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 4., 1.]])\n",
      "batch labels tensor([2., 3.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 8., 0.]])\n",
      "batch labels tensor([7., 7.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 1., 0., 0., 0., 6., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 4., 1.]])\n",
      "batch labels tensor([6., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 4., 1.]])\n",
      "batch labels tensor([1., 5.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 1., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 4., 1.]])\n",
      "batch labels tensor([4., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 1.],\n",
      "        [0., 1., 1., 0., 0., 0., 2., 1.]])\n",
      "batch labels tensor([1., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 2., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 1.]])\n",
      "batch labels tensor([1., 3.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 4., 1.],\n",
      "        [0., 1., 1., 0., 0., 0., 2., 1.]])\n",
      "batch labels tensor([1., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 0., 0., 4., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 4., 0.]])\n",
      "batch labels tensor([1., 5.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 4., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 4., 1.]])\n",
      "batch labels tensor([1., 3.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 0., 1., 0., 1.],\n",
      "        [0., 1., 1., 0., 0., 0., 2., 1.]])\n",
      "batch labels tensor([4., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 1., 0., 2., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 4., 1.]])\n",
      "batch labels tensor([2., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 0., 4., 0.],\n",
      "        [0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "batch labels tensor([7., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 0., 0., 6., 0.]])\n",
      "batch labels tensor([4., 6.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 4., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 4., 1.]])\n",
      "batch labels tensor([1., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[1., 0., 0., 1., 1., 0., 4., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 1.]])\n",
      "batch labels tensor([1., 4.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 0., 6., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 4., 1.]])\n",
      "batch labels tensor([7., 1.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 0., 1., 0., 1., 0., 4., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 2., 1.]])\n",
      "batch labels tensor([5., 2.], dtype=torch.float64)\n",
      "--------------------\n",
      "batch input tensor([[0., 1., 1., 0., 1., 0., 2., 1.]])\n",
      "batch labels tensor([2.], dtype=torch.float64)\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for batch_inputs, batch_labels in dataloader:\n",
    "    print(\"batch input\", batch_inputs)\n",
    "    print(\"batch labels\", batch_labels)\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 0., 0., 0., 2., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor([2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(dataloader)) ## nao sabia\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de avaliação dos modelos\n",
    "* Como no aprendizado de máquina, o conjunto de dados de teste é usado apenas uma vez para calcular as métricas finais\n",
    "* Tranig - 80 - 90 % -> Usado para ajustar os parametros do modelo\n",
    "* Validation 10 - 20 % -> tunar os hyperparametros\n",
    "* Testing 5 - 10 % -> usado para calcular as metricas finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando a perda no treinamento\n",
    "* Calculada somando a perda em cada interação do dataloader\n",
    "* Ao final de cada epoca calculamos o valor médio de perda de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainig_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(trainsloader):\n",
    "    ##....\n",
    "    \n",
    "    \n",
    "    loss = criterion(output, labels)\n",
    "    trainig_loss += loss.item()\n",
    "\n",
    "epoch_loss = trainig_loss / len(trainsloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_loss = 0.0\n",
    "model.eval() ## metodo de avaliacao da classe\n",
    "## por que  algumas camadas nos modelos de pytorch se comportam de maneira diferentes nos estagios de treinamento e validacao\n",
    "with torch.no_grad(): ## Indicando que nao vamos fazer calculos de gradientes nessa epoca\n",
    "    for i, data in enumerate(validationloader, 0):\n",
    "        ## Run the forward pass  \n",
    "        ##...\n",
    "        #..\n",
    "        #.\n",
    "        loss = criterion(outputs, labels)\n",
    "        validation_loss += loss.item()\n",
    "\n",
    "epoch_loss = validation_loss / len(validationloader) \n",
    "model.train() ## indica que colocamos o modelo de volta no modo de treino "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OBS\n",
    "* Assim podemos avaliar se o modelo esta tendo overfitting\n",
    "\n",
    "**Overfitting**: ocorre quando o modelo para de generalizar o desempenho no conjunto de dados e a validação diminui (ou seja ambas tem que estar andando juntas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
